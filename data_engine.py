# -*- coding: utf-8 -*-
"""
data_engine.py
==============
å…¨æ¯æ•°æ®å¼•æ“Ž (Commercial Pro V12.1 - æŽ¥å£ä¿®å¤ç‰ˆ)

ã€ä¿®å¤æ—¥å¿—ã€‘
1. **ä¿®å¤ AttributeError**: è¡¥å›ž `get_market_hot_spots` æŽ¥å£ï¼Œè§£å†³â€œå¯åŠ¨å®è§‚æ·±æœâ€æŠ¥é”™ã€‚
2. **å¤šå‘¨æœŸKçº¿**: ä¿æŒ freq å‚æ•°ï¼Œæ”¯æŒ D(æ—¥)/W(å‘¨)/M(æœˆ) Kçº¿æ•°æ®èŽ·å–ã€‚
3. **æ•°æ®åŠ å›º**: é’ˆå¯¹ NaN å€¼è¿›è¡Œæ›´ä¸¥æ ¼çš„æ¸…æ´—ã€‚
"""

from __future__ import annotations
import datetime as _dt
import re
import time
import json
import logging
import sys
import os
import requests
from typing import Dict, Any, Optional, List

# ç¡®ä¿ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿ site-packagesï¼Œé¿å…æœ¬åœ° Windows ç‰ˆä¾èµ–æ±¡æŸ“
site_paths = [p for p in sys.path if "site-packages" in p]
other_paths = [p for p in sys.path if p not in site_paths and p != ""]
sys.path = site_paths + other_paths + [""]

PD_IMPORT_ERROR: Optional[str] = None
NP_IMPORT_ERROR: Optional[str] = None

try:
    import pandas as pd  # type: ignore
except (MemoryError, ImportError) as exc:  # noqa: PIE786
    PD_IMPORT_ERROR = f"{exc.__class__.__name__}: {exc}"
    pd = None  # type: ignore[assignment]
else:
    PD_IMPORT_ERROR = None

try:
    import numpy as np  # type: ignore
except Exception as exc:  # noqa: BLE001
    NP_IMPORT_ERROR = f"{exc.__class__.__name__}: {exc}"
    np = None  # type: ignore[assignment]

from logging_utils import get_data_logger, make_result, build_error, FetchResult
from data_sources.provider_registry import ProviderRegistry, run_providers_parallel, ProviderResult
from data_sources.identity import canonical_identity
from data_sources import (
    quote_tushare,
    kline_tushare,
    financial_tushare,
    news_tushare,
    moneyflow_tushare,
)
from data_sources.quote_eastmoney import fetch as fetch_quote_eastmoney
from data_sources.quote_sina import fetch as fetch_quote_sina
from data_sources.kline_tencent import fetch as fetch_kline_tencent
from data_sources.kline_baostock import fetch as fetch_kline_baostock
from data_sources.financial_eastmoney import fetch as fetch_financial_eastmoney
from data_sources.financial_em_basic import fetch as fetch_financial_em_basic
from data_sources.financial_baostock import fetch as fetch_financial_baostock
from data_sources.moneyflow_eastmoney import fetch as fetch_moneyflow_eastmoney
from data_sources.identity_eastmoney import fetch_identity_em
from data_sources.news_announcements_eastmoney import fetch as fetch_news_announcements
from data_sources.news_reports_eastmoney import fetch as fetch_news_reports
from data_sources.news_hot_eastmoney import fetch as fetch_news_hot
from data_sources.news_sina import fetch as fetch_news_sina
from data_sources.kline_eastmoney import fetch as fetch_kline_eastmoney
from data_sources.announcement_eastmoney import (
    fetch_announcements_em,
    fetch_announcements_tencent,
    sample_announcements,
)
from data_sources.announcements_exchange import fetch as fetch_announcements_exchange
from data_sources.announcements_fallback import fetch as fetch_announcements_fallback
from data_sources.report_eastmoney import (
    fetch_research_reports_em,
    fetch_research_reports_alt,
    sample_reports,
)
from data_sources.hot_eastmoney import fetch_hot_topics_em, fetch_hot_topics_ak, sample_hot_topics
from data_sources.quote_sina_live import infer_prefix
from data_sources import quote_sina_live, quote_tencent_live, kline_tencent_v2, news_sina_stock
from data_sources import quote_legacy, kline_legacy
from data_sources import kline_sohu
from data_sources import cninfo_client
from data_sources.sample_payloads import (
    sample_announcements,
    sample_financial,
    sample_kline,
    sample_price,
)

try:
    import akshare as ak
except ImportError:
    ak = None

from universe_cache import UniverseCache

try:
    from alternative_data import AlternativeDataEngine
except ImportError:
    AlternativeDataEngine = None

try:
    from fundamental_engine import FundamentalEngine
except ImportError:
    FundamentalEngine = None

try:
    from capital_engine import CapitalEngine
except ImportError:
    CapitalEngine = None


def _now_str() -> str:
    return _dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def normalize_code(code: str) -> str:
    return canonical_identity(code).symbol


# Backward-compatible alias
standardize_code = normalize_code


def normalize_single_stock_payload(payload: Dict[str, Any]) -> Dict[str, Any]:
    """Flatten single_stock output into UI-friendly keys.

    The Streamlit layer expects direct fields (price, pct, etc.) instead of
    nested {data, meta} blobs. This helper preserves originals while exposing
    normalized accessors so the UI never renders blanks when data exists.
    """

    def _as_dict(obj: Any) -> Dict[str, Any]:
        return obj if isinstance(obj, dict) else {}

    res = payload or {}
    meta_map = _as_dict(res.get("_meta"))

    quote_obj = _as_dict(res.get("quote"))
    quote_data = _as_dict(quote_obj.get("data"))
    quote_meta = _as_dict(quote_obj.get("meta")) or _as_dict(meta_map.get("quote"))

    kline_obj = _as_dict(res.get("kline"))
    kline_meta = _as_dict(kline_obj.get("meta")) or _as_dict(meta_map.get("kline"))
    kline_daily = kline_obj.get("daily") or _as_dict(kline_obj.get("data")).get("series") or []

    pd_available = pd is not None
    kline_df = None
    if kline_daily and pd_available:
        try:
            tmp = pd.DataFrame(kline_daily)
            col_map = {col.lower(): col for col in tmp.columns}
            for src, tgt in [("time", "date"), ("tradedate", "date"), ("vol", "volume")]:
                if src in col_map and tgt not in tmp.columns:
                    tmp[tgt] = tmp[col_map[src]]
            numeric_cols = [c for c in ["open", "high", "low", "close", "volume"] if c in tmp.columns]
            for c in numeric_cols:
                tmp[c] = pd.to_numeric(tmp[c], errors="coerce")
            if "date" in tmp.columns:
                try:
                    tmp = tmp.sort_values("date")
                except Exception:
                    pass
            kline_df = tmp
            kline_meta.setdefault("filled_metrics", len(tmp))
        except Exception:
            kline_df = None

    fin_obj = _as_dict(res.get("financial"))
    fin_meta = _as_dict(fin_obj.get("meta")) or _as_dict(meta_map.get("financial"))
    fin_data = _as_dict(fin_obj.get("data"))
    statements = fin_data.get("statements") or fin_data.get("reports") or []
    fin_flat: Dict[str, Any] = {}
    if isinstance(statements, list) and statements:
        first = statements[0]
        if isinstance(first, dict):
            fin_flat = first
    elif fin_data:
        fin_flat = {k: v for k, v in fin_data.items() if not isinstance(v, (list, dict))}

    ann_obj = _as_dict(res.get("announcements"))
    ann_meta = _as_dict(ann_obj.get("meta")) or _as_dict(meta_map.get("announcements"))
    ann_data = _as_dict(ann_obj.get("data"))
    ann_list = ann_data.get("announcements") or ann_obj.get("announcements") or []

    provider_trace = _as_dict(res.get("provider_trace"))

    normalized = {
        **res,
        "market_data": quote_data,
        "quote_meta": quote_meta,
        "kline_daily": kline_daily,
        "kline_daily_df": kline_df,
        "kline_meta": kline_meta,
        "financials": fin_flat,
        "financial_meta": fin_meta,
        "announcements": ann_list,
        "announcements_meta": ann_meta,
        "provider_trace": provider_trace,
        "_meta": {
            **meta_map,
            "quote": quote_meta,
            "kline": kline_meta,
            "financial": fin_meta,
            "announcements": ann_meta,
        },
    }
    return normalized


def to_tushare_ts_code(raw_code: str) -> str:
    ident = canonical_identity(raw_code)
    return ident.symbol


def to_tencent_symbol(code: str) -> str:
    ident = canonical_identity(code)
    return ident.prefixed


def to_eastmoney_secid(code: str) -> str:
    ident = canonical_identity(code)
    return ident.secid

def _safe_float(x: Any, default: float = 0.0) -> float:
    if x is None: return default
    try:
        s = str(x).strip().replace(",", "").replace("%", "")
        if s in ("", "--", "nan", "None", "NaN"): return default
        factor = 1.0
        if "äº¿" in s: 
            factor = 1e8; s = s.replace("äº¿", "")
        elif "ä¸‡" in s: 
            factor = 1e4; s = s.replace("ä¸‡", "")
        return float(s) * factor
    except: return default


def _to_float_or_none(x: Any) -> Optional[float]:
    try:
        default_val = np.nan if np is not None else None
        val = _safe_float(x, default=default_val) if default_val is not None else _safe_float(x, default=0.0)
        if np is not None and pd is not None:
            try:
                if pd.isna(val):
                    return None
            except Exception:
                pass
        return float(val)
    except Exception:
        return None


def _retry(func, max_retries: int = 3, base_delay: float = 0.6):
    last_err = None
    for i in range(max_retries):
        try:
            return func()
        except Exception as e:
            last_err = e
            time.sleep(base_delay * (2 ** i))
    if last_err:
        raise last_err

class DataEngine:
    _instance = None
    _printed_logo = False

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(DataEngine, cls).__new__(cls)
        return cls._instance

    def __init__(self, cache: Optional[UniverseCache] = None):
        if hasattr(self, "_initialized"): return
        self._initialized = True
        self.logger = get_data_logger("superquant.data_engine")
        self.cache = cache or UniverseCache()
        self.alt_engine = AlternativeDataEngine(cache=self.cache) if AlternativeDataEngine else None
        # Step5: è´¢æŠ¥/è¿è¥ + èµ„æœ¬è¿ä½œ æƒ…æŠ¥å¼•æ“Ž
        self.fund_engine = FundamentalEngine(cache=self.cache) if FundamentalEngine else None
        self.capital_engine = CapitalEngine() if CapitalEngine else None
        self.provider_registry = ProviderRegistry()
        self._register_default_providers()

        self.sector_map = {}
        # è¡Œæƒ…å¿«ç…§çŠ¶æ€ï¼ˆç”¨äºŽ UI/è°ƒåº¦è‡ªæ£€ï¼‰
        self.spot_source = ""
        self.spot_is_stale = False
        self.spot_age_sec = None
        if not DataEngine._printed_logo:
            DataEngine._printed_logo = True
            print(f"ðŸš€ [DataEngine V12.1] å¼•æ“Žå°±ç»ª (çƒ­ç‚¹æŽ¥å£å·²ä¿®å¤)...")

    def _cache_age(self, key: str) -> Optional[float]:
        meta_path = self.cache._meta_path(key)  # type: ignore[attr-defined]
        try:
            if meta_path.exists():
                meta = json.loads(meta_path.read_text(encoding="utf-8"))
                ts = float(meta.get("ts", 0))
                return time.time() - ts
        except Exception:
            return None
        return None

    def test_tushare(self, token: str | None) -> tuple[bool, str]:
        if not token:
            return False, "ç¼ºå°‘ TuShare Token"
        try:
            import tushare as ts  # type: ignore

            pro = ts.pro_api(token)
            _ = pro.trade_cal(limit=1)
            return True, "TuShare è¿žæŽ¥æ­£å¸¸"
        except Exception as exc:  # noqa: BLE001
            return False, f"TuShare æµ‹è¯•å¤±è´¥: {exc}" 

    @staticmethod
    def _json_safe(value: Any) -> Any:
        """Recursively convert values into JSON-serializable primitives."""

        if isinstance(value, (str, int, float, bool)) or value is None:
            return value
        if pd is not None and value is getattr(pd, "NaT", None):
            return None
        if isinstance(value, (_dt.date, _dt.datetime)):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
        if pd is not None and isinstance(value, getattr(pd, "Timestamp", ())):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
        if np is not None and isinstance(value, (np.generic,)):
            try:
                return value.item()
            except Exception:
                return value.tolist() if hasattr(value, "tolist") else str(value)
        if np is not None and isinstance(value, np.ndarray):
            try:
                return [DataEngine._json_safe(v) for v in value.tolist()]
            except Exception:
                return str(value)
        if isinstance(value, dict):
            return {k: DataEngine._json_safe(v) for k, v in value.items()}
        if isinstance(value, (list, tuple, set)):
            return [DataEngine._json_safe(v) for v in value]
        try:
            return float(value)
        except Exception:
            try:
                return str(value)
            except Exception:
                return None

    def _register_default_providers(self) -> None:
        # Quote providers
        self.provider_registry.register(
            "quote",
            "quote_sina",
            lambda code, **kwargs: self._provider_quote_module(code, fetch_quote_sina),
            priority=20,
        )
        self.provider_registry.register(
            "quote",
            "quote_eastmoney",
            lambda code, **kwargs: self._provider_quote_module(code, fetch_quote_eastmoney),
            priority=10,
        )
        self.provider_registry.register(
            "quote",
            "quote_tencent",
            lambda code, **kwargs: self._provider_quote_from_func(code, self._fetch_quote_tencent, "tencent"),
            priority=7,
        )
        self.provider_registry.register(
            "quote",
            "quote_akshare",
            lambda code, **kwargs: self._provider_quote_from_func(code, self._fetch_quote_akshare, "akshare"),
            priority=5,
        )

        # Financial & money flow providers
        self.provider_registry.register(
            "kline",
            "kline_tencent",
            lambda code, **kwargs: fetch_kline_tencent(code, limit=kwargs.get("limit", 400)),
            priority=20,
        )
        self.provider_registry.register(
            "kline",
            "kline_eastmoney",
            lambda code, **kwargs: fetch_kline_eastmoney(code, limit=kwargs.get("limit", 400)),
            priority=10,
        )

        self.provider_registry.register(
            "financial",
            "financial_em_basic",
            lambda code, **kwargs: fetch_financial_em_basic(code),
            priority=20,
        )
        self.provider_registry.register(
            "financial",
            "financial_eastmoney",
            lambda code, **kwargs: fetch_financial_eastmoney(code),
            priority=10,
        )
        self.provider_registry.register(
            "financial", "legacy_financial", lambda code, **kwargs: self._provider_financial(code), priority=5
        )
        self.provider_registry.register(
            "money_flow",
            "moneyflow_eastmoney",
            lambda code, **kwargs: fetch_moneyflow_eastmoney(code),
            priority=10,
        )
        self.provider_registry.register(
            "money_flow", "legacy_money_flow", lambda code, **kwargs: self._provider_money_flow(code), priority=5
        )

        # News bundle
        self.provider_registry.register(
            "news_bundle",
            "news_bundle_eastmoney",
            lambda code, **kwargs: self._provider_news_bundle_eastmoney(code),
            priority=10,
        )
        self.provider_registry.register("news_bundle", "legacy_news_bundle", lambda code, **kwargs: self._provider_news_bundle(code), priority=5)

    @staticmethod
    def _count_filled_fields(payload: Dict[str, Any]) -> int:
        if not isinstance(payload, dict):
            return 0
        return sum(1 for _, v in payload.items() if v not in (None, "", "--"))

    @staticmethod
    def _sanitize_stub_data(payload: Dict[str, Any]) -> Tuple[Dict[str, Any], List[Dict[str, str]]]:
        errors: List[Dict[str, str]] = []
        if not isinstance(payload, dict):
            return {}, errors
        text_blob = json.dumps(payload, ensure_ascii=False, default=str)
        if "example.com" in text_blob or "sample_cache" in text_blob or "offline_stub" in text_blob:
            errors.append(build_error("validator", "stub_blocked", "è¿‡æ»¤å ä½æ•°æ®"))
            return {}, errors
        return payload, errors

    def _fetchresult_to_provider_payload(self, fr: FetchResult, label: str) -> Dict[str, Any]:
        data = fr.data
        if hasattr(data, "to_dict") and not isinstance(data, dict):
            try:
                data = data.to_dict()  # type: ignore[assignment]
            except Exception:
                data = {}
        if not isinstance(data, dict):
            data = {}
        data, blocked_errors = self._sanitize_stub_data(data)
        errors = list(fr.errors or []) + blocked_errors
        if (fr.source or "").startswith("sample") or (fr.source or "") in {"offline_stub", "sample_cache"}:
            errors.append(build_error(fr.source or label, "disabled", "é»˜è®¤ç¦ç”¨æ ·æœ¬æ•°æ®"))
            data = {}
        meta = {
            "source": fr.source or label,
            "retrieved_at": time.time(),
            "cache_hit": fr.cache_hit,
            "cache_age": fr.cache_age,
            "ttl_sec": None,
            "fallback_used": fr.fallback_used or bool(blocked_errors),
            "errors": errors,
            "filled_metrics": self._count_filled_fields(data),
        }
        if isinstance(getattr(fr, "meta", None), dict):
            meta.update(fr.meta)  # type: ignore[arg-type]
            meta["filled_metrics"] = meta.get("filled_metrics", self._count_filled_fields(data))
        return {"data": data, "meta": meta}

    def _provider_quote_from_func(self, code: str, fetcher, source: str) -> Dict[str, Any]:
        code_std = standardize_code(code)
        data = self._standardize_quote(fetcher(code_std), code_std, source)
        meta = {
            "source": source,
            "retrieved_at": time.time(),
            "errors": [],
            "fallback_used": False,
            "cache_hit": False,
            "ttl_sec": None,
            "filled_metrics": self._count_filled_fields(data),
        }
        if not data:
            meta["errors"].append(build_error(source, "empty", f"{source} è¡Œæƒ…è¿”å›žç©º"))
        return {"data": data, "meta": meta}

    def _provider_quote_module(self, code: str, provider_func) -> Dict[str, Any]:
        payload = provider_func(code)
        payload = payload or {}
        data = payload.get("data", {}) if isinstance(payload, dict) else {}
        meta = payload.get("meta", {}) if isinstance(payload, dict) else {}
        meta.setdefault("source", "quote_eastmoney")
        meta.setdefault("retrieved_at", time.time())
        meta.setdefault("errors", [])
        meta.setdefault("fallback_used", False)
        meta.setdefault("cache_hit", False)
        meta.setdefault("filled_metrics", self._count_filled_fields(data))
        if not data:
            meta["errors"].append(build_error(meta["source"], "empty", "è¡Œæƒ…æ•°æ®ä¸ºç©º"))
        return {"data": data, "meta": meta}

    def _provider_financial(self, code: str) -> Dict[str, Any]:
        res = self.get_financial_features_structured(code)
        payload = self._fetchresult_to_provider_payload(res, "financial")
        rp = payload["data"].get("report_period") or payload["data"].get("report_date")
        if rp:
            payload["meta"]["report_period"] = rp
        return payload

    def _provider_money_flow(self, code: str) -> Dict[str, Any]:
        res = self.get_money_flow_structured(code)
        return self._fetchresult_to_provider_payload(res, "money_flow")

    def _provider_news_bundle_eastmoney(self, code: str) -> Dict[str, Any]:
        code_std = standardize_code(code)
        meta_errors: List[Dict[str, str]] = []
        data = {"announcements": [], "reports": [], "hot_events": []}

        providers = [
            (fetch_announcements_cninfo, "announcements"),
            (fetch_news_sina, "hot_events"),
            (fetch_news_announcements, "announcements"),
            (fetch_news_reports, "reports"),
            (fetch_news_hot, "hot_events"),
        ]

        for fetcher, key in providers:
            try:
                payload = fetcher(code_std)
                section = payload.get("data", {}).get(key, []) if isinstance(payload, dict) else []
                if section and not data.get(key):
                    data[key] = section
                meta_errors.extend(payload.get("meta", {}).get("errors", []) if isinstance(payload, dict) else [])
            except Exception as exc:  # noqa: BLE001
                meta_errors.append(build_error(key, "exception", str(exc)))

        coverage = sum(1 for v in data.values() if v)
        if coverage == 0:
            meta_errors.append(build_error("news_bundle", "insufficient", "æ–°é—»ã€å…¬å‘Šã€çƒ­ç‚¹å‡ä¸ºç©º"))
        elif coverage == 1:
            meta_errors.append(build_error("news_bundle", "partial", "ä»…ä¸€ç±»èµ„è®¯å¯ç”¨ï¼Œä¿¡å¿ƒè¾ƒä½Ž"))

        meta = {
            "source": "news_bundle_eastmoney",
            "retrieved_at": time.time(),
            "errors": meta_errors,
            "errors_count": len(meta_errors),
            "fallback_used": False,
            "cache_hit": False,
            "filled_metrics": sum(len(v) for v in data.values()),
        }
        return {"data": data, "meta": meta}

    def _provider_news_bundle(self, code: str) -> Dict[str, Any]:
        res = self.get_news_bundle_structured(code)
        return self._fetchresult_to_provider_payload(res, "news_bundle")

    def _market_prefix(self, code: str) -> str:
        code = normalize_code(code)
        if code.startswith('6'): return 'sh'
        if code.startswith(('0','3')): return 'sz'
        if code.startswith(('8','4')): return 'bj'
        return 'sz'

    def _fetch_quote_tencent(self, code: str) -> Dict[str, Any]:
        """è…¾è®¯è¡Œæƒ…å…œåº•ï¼Œè¿”å›žåŽŸå§‹å­—æ®µã€‚"""
        code = normalize_code(code)
        try:
            px = self._market_prefix(code)
            q = f's_{px}{code}'
            url = f'https://qt.gtimg.cn/q={q}'
            r = requests.get(url, timeout=8)
            txt = (r.text or '').strip()
            if '~' not in txt:
                return {}
            m = re.search(r'"(.*)"', txt)
            payload = m.group(1) if m else txt
            parts = payload.split('~')
            if len(parts) < 30:
                return {}
            name = parts[1].strip()
            price = parts[3].strip()
            pct = parts[5].strip()
            open_px = parts[4].strip()
            preclose = parts[33].strip() if len(parts) > 33 else ""
            high = parts[41].strip() if len(parts) > 41 else ""
            low = parts[42].strip() if len(parts) > 42 else ""
            vol = parts[6].strip()
            amount = parts[37].strip() if len(parts) > 37 else ""
            return {
                'code': code,
                'name': name,
                'price': price,
                'pct_chg': pct,
                'open': open_px,
                'preclose': preclose,
                'high': high,
                'low': low,
                'vol': vol,
                'amount': amount,
                'source': 'tencent'
            }
        except Exception as e:
            self.logger.warning("è…¾è®¯è¡Œæƒ…å…œåº•å¼‚å¸¸: %s", e)
            return {}

    def _fetch_quote_akshare(self, code_std: str) -> Dict[str, Any]:
        if ak is None:
            return {}
        plain = normalize_code(code_std)
        if hasattr(ak, "stock_zh_a_spot_em"):
            df = self._retry_call(lambda: ak.stock_zh_a_spot_em())
            if df is not None and not df.empty:
                df = df.rename(columns={"ä»£ç ": "code"})
                row = df[df["code"].astype(str).str.strip() == plain]
                if not row.empty:
                    r = row.iloc[0].to_dict()
                    r["source"] = "akshare"
                    return r
        return {}

    def _fetch_quote_eastmoney(self, code_std: str) -> Dict[str, Any]:
        secid = to_eastmoney_secid(code_std)
        url = "https://push2.eastmoney.com/api/qt/stock/get"
        params = {
            "secid": secid,
            # å¢žåŠ ä¼°å€¼/å¸‚å€¼å­—æ®µï¼Œä¾¿äºŽè´¢åŠ¡å…œåº•
            "fields": "f43,f44,f45,f46,f47,f48,f57,f58,f59,f60,f170,f71,f84,f162,f167,f116,f117",
        }
        try:
            r = requests.get(url, params=params, timeout=10)
            data = (r.json() or {}).get("data") or {}
            if not data:
                return {}
            def _price(v: Any) -> Optional[float]:
                if v in (None, "", "--"):
                    return None
                try:
                    return float(v) / 100.0
                except Exception:
                    return None
            def _pct(v: Any) -> Optional[float]:
                if v in (None, "", "--"):
                    return None
                try:
                    return float(v) / 100.0
                except Exception:
                    return None
            def _to_num(v: Any) -> Optional[float]:
                try:
                    if v in (None, "", "--"):
                        return None
                    return float(v)
                except Exception:
                    return None
            vol_raw = _to_num(data.get("f47"))  # å•ä½ï¼šæ‰‹
            amount_raw = _to_num(data.get("f48"))  # å•ä½ï¼šå…ƒ
            return {
                "code": normalize_code(code_std),
                "name": data.get("f58", ""),
                "price": _price(data.get("f43")),
                "open": _price(data.get("f46")),
                "high": _price(data.get("f44")),
                "low": _price(data.get("f45")),
                "preclose": _price(data.get("f60")),
                "pct_chg": _pct(data.get("f170")),
                "vol": vol_raw * 100 if vol_raw is not None else None,  # è½¬æ¢ä¸ºè‚¡
                "amount": amount_raw,
                "turnover": _pct(data.get("f84")),
                "pe_ttm": data.get("f162"),
                "pb": data.get("f167"),
                "total_mv": _to_num(data.get("f116")),
                "float_mv": _to_num(data.get("f117")),
                "quote_date": data.get("f71"),
                "source": "eastmoney_push2",
            }
        except Exception as e:
            self.logger.warning("ä¸œè´¢è¡Œæƒ…å…œåº•å¼‚å¸¸: %s", e)
            return {}

    def _standardize_quote(self, payload: Dict[str, Any], code_std: str, source: str) -> Dict[str, Any]:
        if not isinstance(payload, dict):
            return {}
        pick = lambda *keys: next((payload.get(k) for k in keys if payload.get(k) not in (None, "", "--")), None)
        price = _to_float_or_none(pick("price", "close", "æœ€æ–°ä»·", "çŽ°ä»·"))
        pct = _to_float_or_none(pick("pct", "pct_chg", "æ¶¨è·Œå¹…"))
        total_mv = _to_float_or_none(pick("total_mv", "æ€»å¸‚å€¼", "market_cap"))
        out = {
            "code": code_std,
            "name": pick("name", "åç§°", "è‚¡ç¥¨åç§°") or payload.get("code", ""),
            "price": price,
            "pct_chg": pct,
            "vol": _to_float_or_none(pick("vol", "volume", "æˆäº¤é‡")),
            "amount": _to_float_or_none(pick("amount", "æˆäº¤é¢")),
            "turnover": _to_float_or_none(pick("turnover", "æ¢æ‰‹çŽ‡")),
            "high": _to_float_or_none(pick("high", "æœ€é«˜")),
            "low": _to_float_or_none(pick("low", "æœ€ä½Ž")),
            "open": _to_float_or_none(pick("open", "å¼€ç›˜")),
            "preclose": _to_float_or_none(pick("preclose", "æ˜¨æ”¶", "æ˜¨æ”¶ä»·", "å‰æ”¶ç›˜")),
            "pe_ttm": _to_float_or_none(pick("pe_ttm", "petm", "pe")),
            "pb": _to_float_or_none(pick("pb", "å¸‚å‡€çŽ‡")),
            "total_mv": total_mv,
            "float_mv": _to_float_or_none(pick("float_mv", "flow_mv", "æµé€šå¸‚å€¼")),
            "source": source,
        }
        if out.get("total_mv"):
            try:
                out["market_cap"] = round(float(out["total_mv"]) / 1e8, 2)
            except Exception:
                out["market_cap"] = None
        else:
            out["market_cap"] = None
        # è‹¥ä»·æ ¼ä¸ºç©ºåˆ™è§†ä¸ºæ— æ•ˆ
        if out.get("price") is None:
            return {}
        return out

    def _quote_sample(self, code_std: str) -> Optional[Dict[str, Any]]:
        samples = {
            "600519.SH": {
                "code": "600519.SH",
                "name": "è´µå·žèŒ…å°",
                "price": 1600.0,
                "pct_chg": 0.0,
                "vol": 1.0,
                "amount": 1.0,
                "turnover": 0.0,
                "high": 1605.0,
                "low": 1595.0,
                "open": 1600.0,
                "preclose": 1600.0,
                "pe_ttm": 30.0,
                "pb": 10.5,
                "total_mv": 2.0e12,
                "float_mv": 2.0e12,
            },
            "000001.SZ": {
                "code": "000001.SZ",
                "name": "å¹³å®‰é“¶è¡Œ",
                "price": 10.0,
                "pct_chg": 0.0,
                "vol": 5.2e7,
                "amount": 5.5e8,
                "turnover": 0.9,
                "high": 10.1,
                "low": 9.9,
                "open": 10.0,
                "preclose": 10.0,
                "pe_ttm": 5.5,
                "pb": 0.6,
                "total_mv": 2.0e11,
                "float_mv": 2.0e11,
            },
            "601872.SH": {
                "code": "601872.SH",
                "name": "æ‹›å•†æ¸¯å£",
                "price": 8.52,
                "pct_chg": -0.6,
                "vol": 1.3e7,
                "amount": 1.1e8,
                "turnover": 0.4,
                "high": 8.66,
                "low": 8.43,
                "open": 8.60,
                "preclose": 8.57,
                "pe_ttm": 12.0,
                "pb": 1.2,
                "total_mv": 8.9e10,
                "float_mv": 6.5e10,
            },
        }
        return samples.get(code_std)

    def _retry_call(self, func, *args, max_retries=2, **kwargs):
        for i in range(max_retries):
            try: return func(*args, **kwargs)
            except: time.sleep(0.5)
        return None

    def _ensure_sector_map(self):
        if self.sector_map: return
        ck = "sector_map_v1"
        cached = self.cache.get(ck, ttl=24*3600*7)
        if cached: self.sector_map = cached
        else: self.sector_map = {} 

    # -------------------------------------
    # 1. å¸‚åœºçƒ­ç‚¹æ„ŸçŸ¥ (ä¿®å¤å…³é”®ç‚¹)
    # -------------------------------------
    def get_market_hot_spots(self) -> List[str]:
        """
        èŽ·å–å…¨ç½‘å¸‚åœºçƒ­ç‚¹ (ç”¨äºŽ DeepSearch ç´ æ)
        æ¥æºï¼šä¸œè´¢äººæ°”æ¦œã€èµ„é‡‘æµå‘æ¦œ
        """
        hot_list = []
        if not ak: return ["Akshare æœªå®‰è£…ï¼Œæ— æ³•èŽ·å–çƒ­ç‚¹"]

        try:
            # 1. ä¸ªè‚¡äººæ°”æ¦œ (Top 5)
            df_pop = self._retry_call(lambda: ak.stock_hot_rank_em())
            if df_pop is not None and not df_pop.empty:
                top_stocks = df_pop.head(5)['symbol'].tolist()
                hot_list.append(f"ðŸ”¥ äººæ°”é£™å‡è‚¡: {', '.join(top_stocks)}")

            # 2. è¡Œä¸šèµ„é‡‘æµ (Top 3)
            df_sec = self._retry_call(lambda: ak.stock_sector_fund_flow_rank(indicator="ä»Šæ—¥", sector_type="è¡Œä¸šèµ„é‡‘æµ"))
            if df_sec is not None and not df_sec.empty:
                if 'åç§°' in df_sec.columns:
                    top_sectors = df_sec.head(3)['åç§°'].tolist()
                    hot_list.append(f"ðŸ’° èµ„é‡‘ä¸»æ”»æ–¹å‘: {', '.join(top_sectors)}")

            # 3. æ¦‚å¿µæ¶¨å¹…æ¦œ (Top 3)
            df_con = self._retry_call(lambda: ak.stock_board_concept_name_em())
            if df_con is not None and not df_con.empty:
                if 'æ¿å—åç§°' in df_con.columns:
                    top_concepts = df_con.head(3)['æ¿å—åç§°'].tolist()
                    hot_list.append(f"ðŸš€ é¢†æ¶¨æ¦‚å¿µ: {', '.join(top_concepts)}")

        except Exception as e:
            logging.warning(f"Fetch hot spots failed: {e}")
            
        return hot_list

    # -------------------------------------
    # 2. åŸºç¡€è¡Œæƒ…
    # -------------------------------------
    def _fetch_spot_snapshot_eastmoney(self) -> pd.DataFrame:
        """å¤‡ç”¨é€šé“ï¼šç›´æŽ¥è°ƒç”¨ä¸œè´¢ push2 æŽ¥å£èŽ·å–å…¨å¸‚åœºå¿«ç…§ã€‚
        ç›®æ ‡ï¼šå½“ AkShare å¤±æ•ˆ/é™æµæ—¶ï¼Œç³»ç»Ÿä¾æ—§èƒ½æ‹¿åˆ°â€œçŽ°ä»·/æ¶¨è·Œå¹…/å¸‚å€¼â€ç­‰æ ¸å¿ƒå­—æ®µã€‚
        """
        url = "https://push2.eastmoney.com/api/qt/clist/get"
        params = {
            "pn": 1,
            "pz": 8000,
            "po": 1,
            "np": 1,
            "ut": "bd1d9ddb04089700cf9c27f6f7426281",
            "fltt": 2,
            "invt": 2,
            "fid": "f3",
            "fs": "m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23",
            "fields": "f12,f14,f2,f3,f20,f9,f5,f8,f10,f23,f62",
        }
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Accept": "application/json,text/plain,*/*",
            "Referer": "https://quote.eastmoney.com/",
        }
        r = requests.get(url, params=params, headers=headers, timeout=12)
        if r.status_code != 200:
            return pd.DataFrame()
        try:
            data = r.json() or {}
        except Exception:
            return pd.DataFrame()
        diff = (data.get("data") or {}).get("diff") or []
        if not diff:
            return pd.DataFrame()
        rows = []
        for it in diff:
            # f12 code, f14 name, f2 close, f3 pct, f20 market cap, f9 pe, f5 volume, f8 turnover, f10 vol_ratio, f23 pb, f62 main inflow
            rows.append({
                "code": str(it.get("f12", "")).strip(),
                "name": str(it.get("f14", "")).strip(),
                "close": float(it.get("f2") or 0.0),
                "pct": float(it.get("f3") or 0.0),
                "market_cap": float(it.get("f20") or 0.0),
                "pe": float(it.get("f9") or 0.0),
                "volume": float(it.get("f5") or 0.0),
                "turnover": float(it.get("f8") or 0.0),
                "vol_ratio": float(it.get("f10") or 0.0),
                "pb": float(it.get("f23") or 0.0),
                "main_net_inflow": float(it.get("f62") or 0.0),
            })
        df = pd.DataFrame(rows)
        df = df[df["code"].str.len() > 0]
        return df

    def get_spot_snapshot(self, ttl_seconds: int = 60) -> pd.DataFrame:
        """
        å…¨å¸‚åœºå¿«ç…§ï¼ˆæ ¸å¿ƒä¾èµ–ï¼Œå•†ç”¨çº§é™çº§ç­–ç•¥ï¼‰
        1) TTL å†…ä¼˜å…ˆç¼“å­˜
        2) AkShare å¤šå‡½æ•°å°è¯•
        3) ä¸œè´¢ push2 ç›´è¿žå…œåº•
        4) è‹¥ä»å¤±è´¥ï¼Œè¿”å›žâ€œåŽ†å²ç¼“å­˜â€ï¼ˆstaleï¼‰ï¼Œä¿è¯ UI ä¸ç©ºç™½
        """
        self.spot_is_stale = False
        self.spot_source = ""
        self.spot_age_sec = None

        # 1) TTL ç¼“å­˜ï¼ˆä¼˜å…ˆï¼‰
        cached = self.cache.get_spot_snapshot(ttl_seconds=ttl_seconds)
        if cached is not None and not cached.empty:
            self.spot_source = "cache"
            return cached

        # å·¥å…·ç¼ºå¤±
        if ak is None and requests is None:
            return pd.DataFrame()

        def _normalize(df: pd.DataFrame) -> pd.DataFrame:
            if df is None or df.empty:
                return pd.DataFrame()
            rename_map = {
                "ä»£ç ": "code", "åç§°": "name", "æœ€æ–°ä»·": "close",
                "æ¶¨è·Œå¹…": "pct", "æ€»å¸‚å€¼": "market_cap", "å¸‚ç›ˆçŽ‡-åŠ¨æ€": "pe",
                "æˆäº¤é‡": "volume", "æ¢æ‰‹çŽ‡": "turnover", "é‡æ¯”": "vol_ratio",
                "å¸‚å‡€çŽ‡": "pb", "ä¸»åŠ›å‡€æµå…¥": "main_net_inflow"
            }
            df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})
            # å…œåº•åˆ—
            for c in ["code", "name", "close", "pct", "market_cap", "pe", "volume", "turnover", "vol_ratio", "pb", "main_net_inflow"]:
                if c not in df.columns:
                    df[c] = 0.0 if c != "name" and c != "code" else ""
            df["code"] = df["code"].astype(str).str.strip()
            df = df[df["code"].str.len() > 0]
            # æ•°å€¼åˆ—æ¸…æ´—
            num_cols = ["close", "pct", "market_cap", "pe", "volume", "turnover", "vol_ratio", "pb", "main_net_inflow"]
            for c in num_cols:
                df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
            return df

        # 2) AkShare å¤šå‡½æ•°å°è¯•
        if ak is not None:
            providers = []
            if hasattr(ak, "stock_zh_a_spot_em"):
                providers.append(("akshare_em", lambda: ak.stock_zh_a_spot_em()))
            if hasattr(ak, "stock_zh_a_spot"):
                providers.append(("akshare", lambda: ak.stock_zh_a_spot()))
            for name, fn in providers:
                df_raw = self._retry_call(fn, max_retries=2)
                df_norm = _normalize(df_raw)
                if df_norm is not None and not df_norm.empty:
                    self.cache.set_spot_snapshot(df_norm)
                    self.spot_source = name
                    self.logger.info("spot snapshot loaded from %s", name)
                    return df_norm
                else:
                    self.logger.warning("spot snapshot empty via %s", name)

        # 3) ä¸œè´¢ push2 å…œåº•
        try:
            df_em = self._retry_call(self._fetch_spot_snapshot_eastmoney, max_retries=2)
            df_em = _normalize(df_em)
            if df_em is not None and not df_em.empty:
                self.cache.set_spot_snapshot(df_em)
                self.spot_source = "eastmoney_push2"
                self.logger.info("spot snapshot loaded from eastmoney push2 fallback")
                return df_em
        except Exception:
            self.logger.exception("eastmoney push2 snapshot failed")

        # 4) åŽ†å²ç¼“å­˜å…œåº•ï¼ˆæ—  TTLï¼‰
        stale = self.cache.get_df("spot_snapshot", ttl=None)
        if stale is not None and not stale.empty:
            self.spot_is_stale = True
            self.spot_source = "stale_cache"
            self.logger.warning("using stale cache for spot snapshot")
            return stale

        self.logger.error("spot snapshot unavailable after all providers")
        return pd.DataFrame()

    def get_spot_row_structured(self, code: str, force_refresh: bool = False) -> FetchResult:
        ident = canonical_identity(code)
        code_std = ident.symbol
        cache_key = self.cache.key("quote_v1", {"code": code_std})
        errors: List[Dict[str, str]] = []
        cache_age = self._cache_age(cache_key)

        if not force_refresh:
            cached = self.cache.get(cache_key, ttl=30)
            if isinstance(cached, dict) and cached:
                return make_result(cached, source=cached.get("source", "cache"), cache_hit=True, cache_age=cache_age)

        payload, _ = run_providers_parallel(
            self.provider_registry.get_providers("quote"),
            code_std,
            timeout=8.0,
            retries=1,
            identity=ident.to_dict(),
            force_refresh=force_refresh,
        )

        if payload:
            data = payload.get("data", {}) if isinstance(payload, dict) else {}
            meta = payload.get("meta", {}) if isinstance(payload, dict) else {}
            if data:
                self.cache.set(cache_key, data)
            return make_result(
                data,
                source=meta.get("source", "quote"),
                fallback_used=meta.get("fallback_used", False),
                errors=meta.get("errors", []),
                cache_hit=False,
                cache_age=None,
                meta=meta,
            )

        if not force_refresh:
            stale = self.cache.get(cache_key, ttl=None)
            if isinstance(stale, dict) and stale:
                errors.append(build_error("quote", "stale_cache", "ä½¿ç”¨åŽ†å²ç¼“å­˜ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
                return make_result(stale, source=stale.get("source", "cache_stale"), fallback_used=True, errors=errors, cache_hit=True, cache_age=cache_age)

        sample = self._quote_sample(code_std)
        if sample:
            errors.append(build_error("quote", "offline_sample", "å®žæ—¶è¡Œæƒ…ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¦»çº¿æ ·æœ¬ï¼ˆæ•°æ®å¯èƒ½è¿‡æœŸï¼‰"))
            sample["source"] = "offline_sample"
            return make_result(sample, source="offline_sample", fallback_used=True, errors=errors, cache_hit=False)

        errors.append(build_error("quote", "unavailable", "æœªèƒ½èŽ·å–åˆ°å•åªè‚¡ç¥¨å¿«ç…§"))
        return make_result({}, source="quote", fallback_used=True, errors=errors)

    def get_spot_row(self, code: str) -> Dict[str, Any]:
        return self.get_spot_row_structured(code).data

    # -------------------------------------
    # 3. èº«ä»½ä¸Žè¡Œä¸š
    # -------------------------------------
    def get_stock_identity_structured(self, code: str) -> FetchResult:
        code_std = standardize_code(code)
        ck = self.cache.key("identity_v12", {"s": code_std})
        cache_age = self._cache_age(ck)
        cached = self.cache.get(ck, ttl=7 * 24 * 3600)
        if isinstance(cached, dict) and cached:
            return make_result(cached, source="cache", cache_hit=True, cache_age=cache_age)

        errors: List[Dict[str, str]] = []
        data = {"code": code_std, "name": "æœªçŸ¥", "sector": "", "concepts": []}

        try:
            spot = self.get_spot_row_structured(code_std)
            if spot.ok and isinstance(spot.data, dict):
                data["name"] = spot.data.get("name", data["name"])
            else:
                errors.extend(spot.errors)
        except Exception as e:
            errors.append(build_error("spot", "exception", str(e)))

        def _ak_identity() -> Dict[str, Any]:
            if ak is None:
                return {}
            try:
                df_info = self._retry_call(lambda: ak.stock_individual_info_em(symbol=code_std))
                if df_info is not None and not df_info.empty:
                    info_dict = dict(zip(df_info.iloc[:, 0], df_info.iloc[:, 1]))
                    sector = str(info_dict.get("è¡Œä¸š", "")).strip()
                    concept_str = str(info_dict.get("æ¦‚å¿µ", "")).strip()
                    concepts = [c for c in re.split(r"[ï¼Œ,\s]+", concept_str) if c]
                    if sector or concepts:
                        return {"sector": sector, "concepts": concepts, "source": "akshare_info"}
                errors.append(build_error("akshare", "empty", "è¡Œä¸š/æ¦‚å¿µæŽ¥å£è¿”å›žç©º"))
            except Exception as e:
                errors.append(build_error("akshare", "exception", str(e)))
            return {}

        def _offline_identity() -> Dict[str, Any]:
            samples = {
                "600519.SH": {"sector": "ç™½é…’", "concepts": ["æ¶ˆè´¹", "è´µå·žå›½èµ„"], "source": "offline_sample"},
                "000001.SZ": {"sector": "é“¶è¡Œ", "concepts": ["é‡‘èž", "æ·±è‚¡é€š"], "source": "offline_sample"},
                "601872.SH": {"sector": "æ¸¯å£èˆªè¿", "concepts": ["å¤®ä¼å›½èµ„", "äº¤é€šè¿è¾“"], "source": "offline_sample"},
            }
            return samples.get(code_std, {})

        providers = [
            ("eastmoney", lambda: fetch_identity_em(code_std)),
        ]
        if ak is not None:
            providers.append(("akshare", _ak_identity))
        else:
            errors.append(build_error("akshare", "skip", "AkShare æœªå®‰è£…/ä¸å¯ç”¨ï¼Œè·³è¿‡è¡Œä¸š/æ¦‚å¿µæº"))
        providers.append(("offline_sample", _offline_identity))

        for idx, (name, fn) in enumerate(providers):
            try:
                res = fn()
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue

            if isinstance(res, dict) and (res.get("sector") or res.get("concepts")):
                data["sector"] = res.get("sector") or data.get("sector", "")
                data["concepts"] = res.get("concepts") or data.get("concepts", [])
                data["name"] = res.get("name") or data.get("name", "æœªçŸ¥")
                source = res.get("source", name)
                if source == "offline_sample":
                    errors.append(build_error("identity", "offline_sample", "å®žæ—¶èº«ä»½æŽ¥å£ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¦»çº¿æ ·æœ¬ï¼ˆå¯èƒ½è¿‡æœŸï¼‰"))
                self.cache.set(ck, data)
                return make_result(
                    data=data,
                    source=source,
                    fallback_used=idx > 0,
                    errors=errors,
                )

            errors.append(build_error(name, "empty", f"{name} è¡Œä¸š/æ¦‚å¿µä¸ºç©º"))

        errors.append(build_error("identity", "empty", "è¡Œä¸š/æ¦‚å¿µå‡ä¸ºç©ºï¼Œèº«ä»½ä¿¡æ¯ä¸å¯ç”¨"))
        return make_result({}, source="identity", fallback_used=True, errors=errors)

    def get_stock_identity(self, code: str) -> Dict[str, Any]:
        return self.get_stock_identity_structured(code).data

    # -------------------------------------
    # 4. Kçº¿æ•°æ® (å¤šå‘¨æœŸ)
    # -------------------------------------
    def _fetch_kline_akshare(
        self,
        code_plain: str,
        freq: str,
        limit: Optional[int],
        start_date: Optional[str],
        end_date: Optional[str],
    ) -> pd.DataFrame:
        period_map = {"daily": "daily", "weekly": "weekly", "monthly": "monthly"}
        p = period_map.get(freq, "daily")

        kwargs = {"symbol": code_plain, "period": p, "adjust": "qfq"}
        if start_date:
            kwargs["start_date"] = str(start_date)
        if end_date:
            kwargs["end_date"] = str(end_date)

        df = ak.stock_zh_a_hist(**kwargs)
        if df is None or df.empty:
            return pd.DataFrame()

        df = df.rename(columns={"æ—¥æœŸ": "date", "å¼€ç›˜": "open", "æ”¶ç›˜": "close", "æœ€é«˜": "high", "æœ€ä½Ž": "low", "æˆäº¤é‡": "volume"})
        df["date"] = pd.to_datetime(df["date"])
        for col in ["open", "close", "high", "low", "volume"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        if limit is not None:
            try:
                df = df.tail(int(limit))
            except Exception:
                pass
        return df

    def _fetch_kline_eastmoney(
        self,
        code_std: str,
        freq: str,
        limit: Optional[int],
    ) -> pd.DataFrame:
        klt_map = {"daily": "101", "weekly": "102", "monthly": "103"}
        klt = klt_map.get(freq, "101")
        secid = to_eastmoney_secid(code_std)
        url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
        params = {
            "secid": secid,
            "klt": klt,
            "fqt": "1",
            "lmt": int(limit) if limit else 1000,
            "fields1": "f1,f2,f3,f4,f5,f6",
            "fields2": "f51,f52,f53,f54,f55,f56,f57,f58",
        }
        delay = 1.0
        last_err: Optional[Exception] = None
        for i in range(3):
            try:
                resp = requests.get(url, params=params, timeout=10)
                resp.raise_for_status()
                payload = resp.json()
                klines = payload.get("data", {}).get("klines", []) if isinstance(payload, dict) else []
                if not klines:
                    last_err = Exception("empty kline data")
                    continue
                records = []
                for line in klines:
                    parts = str(line).split(",")
                    if len(parts) < 6:
                        continue
                    records.append({
                        "date": pd.to_datetime(parts[0]),
                        "open": _safe_float(parts[1]),
                        "close": _safe_float(parts[2]),
                        "high": _safe_float(parts[3]),
                        "low": _safe_float(parts[4]),
                        "volume": _safe_float(parts[5]),
                    })
                df = pd.DataFrame(records)
                if limit is not None and not df.empty:
                    df = df.tail(int(limit))
                return df
            except Exception as e:
                last_err = e
                time.sleep(delay)
                delay *= 2
        # best-effort: never raise, just return empty on failures
        return pd.DataFrame()

    def _offline_stub_kline(self, limit: Optional[int], freq: str) -> pd.DataFrame:
        steps = int(limit) if limit else 60
        if steps < 30:
            steps = 30
        dates = pd.date_range(end=_dt.datetime.today(), periods=steps, freq="B")
        base = np.linspace(80, 95, steps)
        noise = np.random.normal(0, 0.5, steps)
        close = base + noise
        open_px = close - np.random.uniform(0.3, 0.8, steps)
        high = np.maximum(open_px, close) + np.random.uniform(0.1, 0.6, steps)
        low = np.minimum(open_px, close) - np.random.uniform(0.1, 0.6, steps)
        volume = np.random.randint(1e6, 5e6, steps)
        df = pd.DataFrame({
            "date": dates,
            "open": open_px,
            "close": close,
            "high": high,
            "low": low,
            "volume": volume,
        })
        return df.tail(int(limit)) if limit else df

    def get_kline(
        self,
        code: str,
        freq: str = "daily",
        limit: Optional[int] = 250,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> pd.DataFrame:
        res = self.get_kline_structured(code, freq=freq, limit=limit, start_date=start_date, end_date=end_date)
        if hasattr(res.data, "empty"):
            return res.data
        return pd.DataFrame()

    def get_kline_structured(
        self,
        code: str,
        freq: str = "daily",
        limit: Optional[int] = 250,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> FetchResult:
        code_std = standardize_code(code)
        code_plain = normalize_code(code)
        cache_key = f"kline:{code_std}:{freq}"
        errors: List[Dict[str, str]] = []

        if pd is None or np is None:
            if PD_IMPORT_ERROR:
                errors.append(build_error("pandas", "import_error", PD_IMPORT_ERROR))
            if NP_IMPORT_ERROR:
                errors.append(build_error("numpy", "import_error", NP_IMPORT_ERROR))
            return make_result([], source="unavailable", fallback_used=True, errors=errors)

        cached = self.cache.get_df(cache_key, ttl=3600)
        if cached is not None and not cached.empty:
            return make_result(cached, source="cache", cache_hit=True, cache_age=self._cache_age(cache_key))

        if ak is None:
            errors.append(build_error("akshare", "missing", "AkShare æœªå®‰è£…"))
        else:
            try:
                df = self._retry_call(lambda: self._fetch_kline_akshare(code_plain, freq, limit, start_date, end_date), max_retries=2)
                if df is not None and not df.empty:
                    self.cache.set_df(cache_key, df)
                    return make_result(df, source="akshare", errors=errors)
                errors.append(build_error("akshare", "empty", "Kçº¿æ•°æ®ä¸ºç©º"))
            except Exception as e:
                errors.append(build_error("akshare", "exception", str(e)))

        fallback_used = True

        try:
            df_em = self._fetch_kline_eastmoney(code_std, freq, limit)
            if df_em is not None and not df_em.empty:
                self.cache.set_df(cache_key, df_em)
                return make_result(df_em, source="eastmoney", fallback_used=True, errors=errors)
            errors.append(build_error("eastmoney", "empty", "ä¸œè´¢Kçº¿ä¸ºç©º"))
        except Exception as e:
            errors.append(build_error("eastmoney", "exception", str(e)))

        stale = self.cache.get_df(cache_key, ttl=None)
        if stale is not None and not stale.empty:
            errors.append(build_error("cache", "stale", "å®žæ—¶æºå¤±è´¥ï¼Œä½¿ç”¨åŽ†å²ç¼“å­˜ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
            return make_result(stale, source="stale_cache", fallback_used=True, errors=errors, cache_hit=True, cache_age=self._cache_age(cache_key))

        try:
            stub = self._offline_stub_kline(limit or 60, freq)
            if stub is not None and not stub.empty:
                errors.append(build_error("offline_stub", "used", "å®žæ—¶æºä¸å¯ç”¨ï¼Œä½¿ç”¨å†…ç½®ç¤ºä¾‹Kçº¿ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
                return make_result(stub, source="offline_stub", fallback_used=True, errors=errors)
        except Exception as e:
            errors.append(build_error("offline_stub", "exception", str(e)))

        errors.append(build_error("kline", "unavailable", "æ‰€æœ‰æ•°æ®æºå‡å¤±è´¥"))
        return make_result(pd.DataFrame(), source="unavailable", fallback_used=fallback_used, errors=errors)

    def get_kline_with_meta(
        self,
        code: str,
        freq: str = "daily",
        limit: Optional[int] = 250,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
    ) -> pd.DataFrame:
        """å…¼å®¹æ—§æŽ¥å£ï¼Œè¿”å›ž DataFrameã€‚"""
        return self.get_kline_structured(code, freq, limit, start_date, end_date).data
    # -------------------------------------
    # 5. æ·±åº¦è´¢åŠ¡
    # -------------------------------------
    def get_financial_features_structured(self, code: str) -> FetchResult:
        """è´¢æŠ¥/è¿è¥ç±»ç‰¹å¾ï¼ˆç»“æž„åŒ–è¾“å‡ºï¼‰ï¼Œä¿è¯é”™è¯¯å¯è§ä¸”å¤šæºå…œåº•ã€‚"""

        code_std = standardize_code(code)
        ck = f"fin:{code_std}"
        cached = self.cache.get(ck, ttl=3600 * 12)
        if cached is not None:
            return FetchResult(data=cached, ok=True, source="cache", cache_hit=True, cache_age=self._cache_age(ck), meta={"filled_metrics": len([v for v in cached.values() if v not in (None, "", "--")])})

        errors: List[Dict[str, str]] = []
        source_chain: List[str] = []
        fallback_used = False
        fin: Dict[str, Any] = {}
        allow_samples = os.environ.get("ALLOW_SAMPLE_CACHE", "").lower() in {"1", "true", "yes", "on"} or os.environ.get("ALLOW_OFFLINE_SAMPLES", "").lower() in {"1", "true", "yes", "on"}

        # 1) ä¸œè´¢ä¸»è·¯å¾„
        em_errors: List[Dict[str, str]] = []
        fin_em = self._fetch_financial_from_eastmoney(code_std, em_errors)
        errors.extend(em_errors)
        if fin_em:
            fin.update(fin_em)
            source_chain.append("eastmoney")
        else:
            fallback_used = True

        # 2) AkShare å…¼å®¹å…œåº•ï¼ˆè¡¥è¶³ç¼ºå¤±å­—æ®µï¼‰
        ak_errors: List[Dict[str, str]] = []
        fin_ak = self._fetch_financial_from_ak(code_std, ak_errors)
        errors.extend(ak_errors)
        if fin_ak:
            for k, v in fin_ak.items():
                if fin.get(k) in (None, "", "--") and v not in (None, "", "--"):
                    fin[k] = v
            if not source_chain:
                source_chain.append("akshare")
            else:
                fallback_used = True

        # 3) è¡Œæƒ…ä¼°å€¼å…œåº•ï¼ˆå¡«è¡¥ pe/pb ç­‰å¿…å¡«ï¼‰
        quote_errors: List[Dict[str, str]] = []
        quote_fin = self._financial_from_quote(code_std, quote_errors)
        errors.extend(quote_errors)
        if quote_fin:
            for k, v in quote_fin.items():
                if fin.get(k) in (None, "", "--") and v not in (None, "", "--"):
                    fin[k] = v
            if not source_chain:
                source_chain.append(quote_fin.get("source", "quote"))
                fallback_used = True

        # 4) ç¦»çº¿æ ·æœ¬è¡¥é½å¿…å¡«å­—æ®µ
        required_keys = ["pe_ttm", "pb", "roe", "revenue_yoy", "profit_yoy", "gross_margin"]
        filled_required = [k for k in required_keys if fin.get(k) not in (None, "", "--")]
        if len(filled_required) < 4 and allow_samples:
            stub = self._financial_offline_stub(code_std) or {}
            if stub:
                for k, v in stub.items():
                    if fin.get(k) in (None, "", "--") and v not in (None, "", "--"):
                        fin[k] = v
                if "offline_stub" not in source_chain:
                    source_chain.append("offline_stub")
                errors.append(build_error("offline_stub", "used", "å®žæ—¶æºä¸å¯ç”¨ï¼Œä½¿ç”¨å†…ç½®ç¤ºä¾‹è´¢åŠ¡æ•°æ®ï¼Œå¯èƒ½è¿‡æœŸ"))
                fallback_used = True
        elif len(filled_required) < 4 and not allow_samples:
            errors.append(build_error("offline_stub", "disabled", "æœªå¯ç”¨æ ·æœ¬æ¨¡å¼ï¼Œç¼ºå°‘å¿…å¡«è´¢åŠ¡å­—æ®µ"))

        # 4) ç¼“å­˜å…œåº•ï¼ˆä¸å¼•å…¥å‡æ•°æ®ï¼‰
        if not fin:
            stale = self.cache.get(ck, ttl=None)
            if stale:
                errors.append(build_error("cache", "stale", "å®žæ—¶æºå¤±è´¥ï¼Œä½¿ç”¨åŽ†å²ç¼“å­˜ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
                filled_stale = len([v for v in stale.values() if v not in (None, "", "--")])
                return FetchResult(
                    data=stale,
                    ok=True,
                    source="stale_cache",
                    fallback_used=True,
                    errors=errors,
                    cache_hit=True,
                    cache_age=self._cache_age(ck),
                    meta={"filled_metrics": filled_stale},
                )

        # 5) ç¦»çº¿å…œåº•ï¼ˆæ˜¾å¼æ ‡æ³¨ fallbackï¼‰
        if not fin and allow_samples:
            fallback_used = True
            fin = self._financial_offline_stub(code_std) or {}
            if fin:
                errors.append(build_error("offline_stub", "used", "å®žæ—¶æºä¸å¯ç”¨ï¼Œä½¿ç”¨å†…ç½®ç¤ºä¾‹è´¢åŠ¡æ•°æ®ï¼Œå¯èƒ½è¿‡æœŸ"))
                source_chain.append("offline_stub")
            else:
                errors.append(build_error("financial", "unavailable", "æ‰€æœ‰è´¢åŠ¡æ•°æ®æºå‡å¤±è´¥"))
        elif not fin:
            errors.append(build_error("financial", "unavailable", "æ‰€æœ‰è´¢åŠ¡æ•°æ®æºå‡å¤±è´¥ä¸”ç¦ç”¨æ ·æœ¬"))

        if not fin:
            return FetchResult(data={}, ok=False, source="unavailable", fallback_used=True, errors=errors)

        # å­—æ®µè¡¥é½
        fin = self._enrich_financial_scores(fin)
        fin["report_period"] = fin.get("report_date") or fin.get("report_period")
        required_keys = ["pe_ttm", "pb", "roe", "revenue_yoy", "profit_yoy", "gross_margin"]
        metric_keys = [
            "revenue",
            "net_profit",
            "gross_margin",
            "net_margin",
            "roe",
            "roa",
            "debt_ratio",
            "op_cashflow",
        ]
        valuation_keys = ["pe_ttm", "pb", "total_mv", "float_mv", "market_cap"]
        filled_keys = [k for k in metric_keys + valuation_keys if fin.get(k) not in (None, "", "--")]
        filled_required = [k for k in required_keys if fin.get(k) not in (None, "", "--")]

        ok_flag = len(filled_required) >= 4
        if ok_flag:
            self.cache.set(ck, fin)
        return FetchResult(
            data=fin,
            ok=ok_flag,
            source=source_chain[0] if source_chain else "unknown",
            fallback_used=fallback_used,
            errors=errors,
            cache_age=self._cache_age(ck),
            meta={
                "filled_metrics": len(filled_keys),
                "filled_required": len(filled_required),
                "report_period": fin.get("report_period"),
                "sources": source_chain,
            },
        )

    def get_financial_features(self, code: str) -> Dict[str, Any]:
        return self.get_financial_features_structured(code).data

    def _map_financial_row(self, row: Dict[str, Any]) -> Dict[str, Any]:
        mapping = {
            "report_date": ["æŠ¥å‘ŠæœŸ", "æŠ¥å‘Šæ—¥æœŸ", "reportdate", "fdate", "REPORT_DATE"],
            "revenue": ["è¥ä¸šæ”¶å…¥", "è¥ä¸šæ€»æ”¶å…¥(å…ƒ)", "totaloperatereve", "è¥ä¸šæ€»æ”¶å…¥", "biz_income"],
            "net_profit": ["å‡€åˆ©æ¶¦", "netprofit", "å½’å±žäºŽæ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦", "netprofit_parent_comp", "å½’æ¯å‡€åˆ©æ¶¦"],
            "gross_margin": ["é”€å”®æ¯›åˆ©çŽ‡(%)", "æ¯›åˆ©çŽ‡(%)", "æ¯›åˆ©çŽ‡", "grossprofit_margin", "GROSS_MARGIN"],
            "net_margin": ["é”€å”®å‡€åˆ©çŽ‡(%)", "å‡€åˆ©çŽ‡(%)", "å‡€åˆ©çŽ‡", "netprofit_margin"],
            "roe": ["å‡€èµ„äº§æ”¶ç›ŠçŽ‡(%)", "ROE(%)", "å‡€èµ„äº§æ”¶ç›ŠçŽ‡", "weightedroe", "roe"],
            "roa": ["æ€»èµ„äº§æŠ¥é…¬çŽ‡(%)", "èµ„äº§æŠ¥é…¬çŽ‡(%)", "èµ„äº§æŠ¥é…¬çŽ‡", "roa2_weighted", "roa"],
            "debt_ratio": ["èµ„äº§è´Ÿå€ºçŽ‡(%)", "èµ„äº§è´Ÿå€ºçŽ‡", "debtratio", "èµ„äº§è´Ÿå€ºçŽ‡\r"],
            "op_cashflow": ["ç»è¥æ´»åŠ¨äº§ç”Ÿçš„çŽ°é‡‘æµé‡å‡€é¢", "ç»è¥çŽ°é‡‘æµé‡å‡€é¢", "ç»è¥æ´»åŠ¨çŽ°é‡‘æµé‡å‡€é¢", "ç»è¥çŽ°é‡‘æµ", "ocfps"],
            "profit_yoy": ["å‡€åˆ©æ¶¦å¢žé•¿çŽ‡(%)", "å‡€åˆ©æ¶¦åŒæ¯”å¢žé•¿çŽ‡(%)", "å‡€åˆ©æ¶¦å¢žé•¿çŽ‡", "netprofit_yoy"],
            "revenue_yoy": ["è¥ä¸šæ”¶å…¥å¢žé•¿çŽ‡(%)", "è¥ä¸šæ”¶å…¥åŒæ¯”å¢žé•¿çŽ‡(%)", "è¥ä¸šæ”¶å…¥å¢žé•¿çŽ‡", "ystz"],
            "eps": ["æ¯è‚¡æ”¶ç›Š(å…ƒ)", "eps", "basiceps", "åŸºæœ¬æ¯è‚¡æ”¶ç›Š"],
        }

        out: Dict[str, Any] = {k: None for k in [
            "report_date",
            "revenue",
            "net_profit",
            "gross_margin",
            "net_margin",
            "roe",
            "roa",
            "debt_ratio",
            "op_cashflow",
            "profit_yoy",
            "revenue_yoy",
            "eps",
        ]}

        def pick(keys: List[str]) -> Any:
            for k in keys:
                if k in row and row[k] not in (None, "", "--"):
                    return row[k]
            return None

        for target, keys in mapping.items():
            out[target] = _to_float_or_none(pick(keys)) if target != "report_date" else pick(keys)

        if not out.get("net_margin") and out.get("net_profit") and out.get("revenue"):
            try:
                out["net_margin"] = float(out["net_profit"]) / float(out["revenue"]) * 100.0
            except Exception:
                pass
        return out

    def _fetch_financial_from_ak(self, code_std: str, errors: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        if ak is None:
            errors.append(build_error("akshare", "missing", "AkShare æœªå®‰è£…"))
            return None
        df = None
        try:
            df = self._retry_call(lambda: ak.stock_financial_analysis_indicator(symbol=code_std))
        except Exception as e:
            errors.append(build_error("akshare", "exception", str(e)))

        if df is None or df.empty:
            try:
                df = self._retry_call(lambda: ak.stock_financial_analysis_indicator_em(symbol=code_std))
            except Exception as e:
                errors.append(build_error("akshare_em", "exception", str(e)))

        if df is not None and not df.empty:
            try:
                row = df.iloc[-1].to_dict()
                return self._map_financial_row(row)
            except Exception as e:
                errors.append(build_error("akshare", "parse", str(e)))
        else:
            errors.append(build_error("akshare", "empty", "è´¢åŠ¡æŒ‡æ ‡è¿”å›žç©º"))
        return None

    def _fetch_financial_from_eastmoney(self, code_std: str, errors: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        try:
            payload = fetch_financial_eastmoney(code_std)
            data = payload.get("data", {}) if isinstance(payload, dict) else {}
            if data:
                return data
            errors.append(build_error("eastmoney", "empty", "ä¸œè´¢è´¢åŠ¡æŒ‡æ ‡ä¸ºç©º"))
        except Exception as e:
            errors.append(build_error("eastmoney", "exception", str(e)))
        return None

    def _financial_from_quote(self, code_std: str, errors: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """ä»Žè¡Œæƒ…ä¼°å€¼å­—æ®µå…œåº•ï¼Œè‡³å°‘å¡«å…… 3 ä¸ªæŒ‡æ ‡ã€‚"""

        quote_res = self.get_spot_row_structured(code_std)
        quote = quote_res.data if isinstance(quote_res.data, dict) else {}
        if not quote:
            errors.append(build_error("quote", "empty", "è¡Œæƒ…ä¼°å€¼å­—æ®µä¸ºç©ºï¼Œæ— æ³•å…œåº•è´¢åŠ¡"))
            return None

        valuation_fields = {
            "pe_ttm": quote.get("pe_ttm"),
            "pb": quote.get("pb"),
            "total_mv": quote.get("total_mv"),
            "float_mv": quote.get("float_mv"),
            "market_cap": quote.get("market_cap"),
        }

        filled = {k: v for k, v in valuation_fields.items() if v not in (None, "", "--")}
        if len(filled) < 3:
            errors.append(build_error("quote", "insufficient", "è¡Œæƒ…ä¼°å€¼å­—æ®µä¸è¶³ 3 é¡¹"))
            errors.extend(quote_res.errors)
            return None

        if quote_res.errors:
            errors.extend(quote_res.errors)

        filled["report_date"] = quote.get("quote_date") or quote.get("ts")
        filled["source"] = f"quote:{quote_res.source or 'unknown'}"
        return filled

    def _financial_offline_stub(self, code_std: str) -> Optional[Dict[str, Any]]:
        samples = {
            "600519.SH": {
                "report_date": "2024-09-30",
                "revenue": 1067.5 * 1e8,
                "net_profit": 527.0 * 1e8,
                "gross_margin": 91.0,
                "net_margin": 49.0,
                "roe": 25.0,
                "roa": 18.0,
                "debt_ratio": 36.0,
                "op_cashflow": 550.0 * 1e8,
                "profit_yoy": 15.0,
                "revenue_yoy": 17.0,
                "eps": 40.0,
                "pe_ttm": 25.0,
                "pb": 6.5,
            },
            "000001.SZ": {
                "report_date": "2024-09-30",
                "revenue": 1500.0 * 1e8,
                "net_profit": 120.0 * 1e8,
                "gross_margin": 28.0,
                "net_margin": 12.0,
                "roe": 11.5,
                "roa": 0.9,
                "debt_ratio": 86.0,
                "op_cashflow": 300.0 * 1e8,
                "profit_yoy": 6.0,
                "revenue_yoy": 5.0,
                "eps": 1.8,
                "pe_ttm": 7.5,
                "pb": 0.9,
            },
            "601872.SH": {
                "report_date": "2024-09-30",
                "revenue": 170.2 * 1e8,
                "net_profit": 22.4 * 1e8,
                "gross_margin": 32.5,
                "net_margin": 13.2,
                "roe": 8.7,
                "roa": 5.1,
                "debt_ratio": 55.0,
                "op_cashflow": 30.0 * 1e8,
                "profit_yoy": 9.5,
                "revenue_yoy": 7.8,
                "eps": 0.86,
                "pe_ttm": 15.0,
                "pb": 1.5,
            },
        }
        return samples.get(code_std)

    def _enrich_financial_scores(self, fin: Dict[str, Any]) -> Dict[str, Any]:
        def _clip(x: float) -> float:
            return max(0.0, min(1.0, float(x)))

        roe_score = _clip(((_safe_float(fin.get("roe"), 0.0)) / 15.0 + 1) / 2)
        gm_score = _clip(_safe_float(fin.get("gross_margin"), 0.0) / 50.0)
        debt_score = _clip(1.0 - _safe_float(fin.get("debt_ratio"), 0.0) / 80.0)
        prof_score = _clip((_safe_float(fin.get("profit_yoy"), 0.0) / 40.0 + 1) / 2)
        rev_score = _clip((_safe_float(fin.get("revenue_yoy"), 0.0) / 30.0 + 1) / 2)

        fin["fundamental_quality"] = _clip(0.40 * roe_score + 0.30 * gm_score + 0.20 * debt_score + 0.10 * _clip(_safe_float(fin.get("net_margin"), 0.0) / 30.0))
        fin["fundamental_growth"] = _clip(0.60 * prof_score + 0.40 * rev_score)
        cf_bonus = 0.05 if _safe_float(fin.get("op_cashflow"), 0.0) > 0 else 0.0
        fin["ops_momentum"] = _clip(0.50 + 0.40 * (fin["fundamental_growth"] - 0.50) + 0.10 * (fin["fundamental_quality"] - 0.50) + cf_bonus)
        return fin

    def get_money_flow_structured(self, code: str) -> FetchResult:
        """èµ„é‡‘æµä¿¡æ¯ï¼Œå¸¦é”™è¯¯åŽŸå› ã€‚"""
        code_std = standardize_code(code)
        errors: List[Dict[str, str]] = []
        out: Dict[str, Any] = {}
        fallback_used = False
        source = "money_flow"
        meta: Dict[str, Any] = {}

        try:
            if self.capital_engine is not None:
                cap = self.capital_engine.get_capital_features_structured(code_std)
                if isinstance(cap.data, dict):
                    out.update(cap.data)
                errors.extend(cap.errors)
                fallback_used = fallback_used or cap.fallback_used
                source = cap.source or source
                meta = cap.meta if isinstance(getattr(cap, "meta", None), dict) else {}
            else:
                errors.append(build_error("capital_engine", "missing", "æœªåˆå§‹åŒ–"))
        except Exception as e:  # noqa: BLE001
            errors.append(build_error("capital_engine", "exception", str(e)))

        if not out:
            errors.append(build_error("money_flow", "empty", "èµ„é‡‘æµä¸ºç©º"))
        filled_keys = [
            "main_net_inflow",
            "super_large_net_inflow",
            "large_net_inflow",
            "medium_net_inflow",
            "small_net_inflow",
            "northbound_net_inflow",
        ]
        filled_metrics = sum(1 for k in filled_keys if out.get(k) not in (None, "", "--"))
        meta = meta if isinstance(locals().get("meta", {}), dict) else {}
        meta.update({"filled_metrics": filled_metrics, "retrieved_at": time.time()})

        return make_result(
            out,
            source=source,
            errors=errors,
            fallback_used=fallback_used or bool(errors),
            meta=meta,
        )

    def get_money_flow(self, code: str) -> Dict[str, Any]:
        return self.get_money_flow_structured(code).data


    # -------------------------------------
    # 5.4 å…¬å‘Š / ç ”æŠ¥ / çƒ­ç‚¹è¦äº‹
    # -------------------------------------
    def get_news_bundle_structured(self, code: str, limit: int = 8) -> FetchResult:
        """èšåˆå…¬å‘Š/ç ”æŠ¥/çƒ­ç‚¹/è®ºå›/è§‚ç‚¹ï¼Œä¼˜å…ˆä½¿ç”¨æƒ…æŠ¥å¼•æ“Žç»Ÿä¸€ schemaã€‚"""

        code_std = standardize_code(code)
        if self.alt_engine and hasattr(self.alt_engine, "get_news_bundle_structured"):
            try:
                return self.alt_engine.get_news_bundle_structured(code_std)
            except Exception as e:  # noqa: BLE001
                err = build_error("alternative", "exception", str(e))
                errors = [err]
        else:
            errors = [build_error("alternative", "missing", "æƒ…æŠ¥å¼•æ“Žæœªåˆå§‹åŒ–")]

        # ä¿åº•ï¼šä½¿ç”¨æœ¬åœ°èšåˆï¼Œå­—æ®µä¿æŒä¸€è‡´
        bundle: Dict[str, Any] = {
            "announcements": [],
            "reports": [],
            "hot_events": [],
            "forums": [],
            "opinions": [],
        }
        sources: Dict[str, str] = {}
        fallback_used = False

        ann = self.get_announcements_structured(code_std, limit=limit)
        bundle["announcements"] = ann.data if isinstance(ann.data, list) else []
        sources["announcements"] = ann.source
        errors.extend(ann.errors)
        if ann.fallback_used:
            fallback_used = True

        rep = self.get_research_reports_structured(code_std, limit=limit)
        bundle["reports"] = rep.data if isinstance(rep.data, list) else []
        sources["reports"] = rep.source
        errors.extend(rep.errors)
        if rep.fallback_used:
            fallback_used = True

        hot = self.get_hot_topics_structured(limit=limit)
        bundle["hot_events"] = hot.data if isinstance(hot.data, list) else []
        sources["hot_events"] = hot.source
        errors.extend(hot.errors)
        if hot.fallback_used:
            fallback_used = True

        coverage = sum(1 for k in ["announcements", "reports", "hot_events"] if bundle.get(k))
        if coverage == 0:
            errors.append(build_error("news_bundle", "insufficient", "å…¬å‘Šã€ç ”æŠ¥ã€çƒ­ç‚¹å‡ä¸ºç©º"))
            fallback_used = True
        elif coverage == 1:
            errors.append(build_error("news_bundle", "partial", "èµ„è®¯æ¥æºåªæœ‰ä¸€ç±»ï¼Œè°¨æ…Žå‚è€ƒ"))
        meta = {"sources": sources, "filled_sections": coverage, "retrieved_at": _now_str(), "filled_metrics": coverage}
        return make_result(bundle, source="news_bundle", errors=errors, fallback_used=fallback_used, meta=meta)

    def get_announcements_structured(self, code: str, limit: int = 12) -> FetchResult:
        code_std = standardize_code(code)
        errors: List[Dict[str, str]] = []
        chosen: List[Dict[str, Any]] = []
        source = ""
        providers = [
            ("eastmoney", lambda: fetch_announcements_em(code_std, limit=limit)),
            ("tencent", lambda: fetch_announcements_tencent(code_std, limit=limit)),
        ]

        for name, fn in providers:
            try:
                data = self._retry_call(fn, max_retries=2)
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            payload_items = data.get("items", []) if isinstance(data, dict) else data
            errors.extend(data.get("errors", []) if isinstance(data, dict) else [])
            if payload_items:
                chosen = payload_items
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} å…¬å‘Šä¸ºç©º"))

        if not chosen:
            errors.append(build_error("sample", "fallback", "å¯ç”¨ç¦»çº¿å…¬å‘Šæ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
            chosen = sample_announcements(code_std, limit=limit)
            source = "sample_cache"

        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)

    def get_research_reports_structured(self, code: str, limit: int = 12) -> FetchResult:
        code_std = standardize_code(code)
        errors: List[Dict[str, str]] = []
        chosen: List[Dict[str, Any]] = []
        source = ""
        providers = [
            ("eastmoney", lambda: fetch_research_reports_em(code_std, limit=limit)),
            ("alt", lambda: fetch_research_reports_alt(code_std, limit=limit)),
        ]

        for name, fn in providers:
            try:
                data = self._retry_call(fn, max_retries=2)
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            payload_items = data.get("items", []) if isinstance(data, dict) else data
            errors.extend(data.get("errors", []) if isinstance(data, dict) else [])
            if payload_items:
                chosen = payload_items
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} ç ”æŠ¥ä¸ºç©º"))

        if not chosen:
            errors.append(build_error("sample", "fallback", "å¯ç”¨ç¦»çº¿ç ”æŠ¥æ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
            chosen = sample_reports(code_std, limit=limit)
            source = "sample_cache"

        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)

    def get_hot_topics_structured(self, limit: int = 8) -> FetchResult:
        errors: List[Dict[str, str]] = []
        chosen: List[Dict[str, Any]] = []
        source = ""
        providers = [
            ("eastmoney", lambda: fetch_hot_topics_em(limit=limit)),
            ("akshare", lambda: fetch_hot_topics_ak(limit=limit)),
        ]

        for name, fn in providers:
            try:
                data = self._retry_call(fn, max_retries=2)
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            payload_items = data.get("items", []) if isinstance(data, dict) else data
            errors.extend(data.get("errors", []) if isinstance(data, dict) else [])
            if payload_items:
                chosen = payload_items
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} çƒ­ç‚¹ä¸ºç©º"))

        if not chosen:
            errors.append(build_error("sample", "fallback", "å¯ç”¨ç¦»çº¿çƒ­ç‚¹æ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
            chosen = sample_hot_topics(limit=limit)
            source = "sample_cache"

        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)


    # -------------------------------------
    # 5.5  å¥åº·æ£€æŸ¥ï¼ˆå•†ç”¨å¯è§‚æµ‹æ€§ï¼‰
    # -------------------------------------
    def health_check(self) -> Dict[str, Any]:
        """
        ç”¨äºŽ UI/è°ƒåº¦çš„å¿«é€Ÿè‡ªæ£€ï¼š
        - AkShare æ˜¯å¦å¯ç”¨
        - ä¸œè´¢ push2 æ˜¯å¦å¯ç”¨
        - spot å¿«ç…§æ˜¯å¦å‘½ä¸­ç¼“å­˜/æ˜¯å¦é™ˆæ—§
        """
        report: Dict[str, Any] = {
            "akshare_available": bool(ak),
            "spot_source": "",
            "spot_is_stale": False,
            "spot_rows": 0,
            "hint": "",
        }
        try:
            df = self.get_spot_snapshot(ttl_seconds=10)
            report["spot_source"] = self.spot_source or ""
            report["spot_is_stale"] = bool(self.spot_is_stale)
            report["spot_rows"] = int(len(df)) if df is not None else 0
            if report["spot_rows"] == 0:
                report["hint"] = "è¡Œæƒ…å¿«ç…§èŽ·å–å¤±è´¥ï¼šå»ºè®®æ£€æŸ¥ç½‘ç»œ/é™æµï¼Œæˆ–ç¨åŽé‡è¯•ã€‚"
            elif report["spot_is_stale"]:
                report["hint"] = "æ­£åœ¨ä½¿ç”¨åŽ†å²ç¼“å­˜å¿«ç…§ï¼ˆå¯èƒ½è¾ƒæ—§ï¼‰ã€‚å»ºè®®æ¢å¤æ•°æ®æºåŽåˆ·æ–°ã€‚"
        except Exception as e:
            report["hint"] = f"å¥åº·æ£€æŸ¥å¼‚å¸¸ï¼š{e}"
        return report

    # -------------------------------------
    # 6. å…¨æ¯æ‰“åŒ…
    # -------------------------------------

    def single_stock(
        self,
        code: str,
        sample_mode: bool = False,
        offline_mode: bool = False,
        force_refresh: bool = False,
    ) -> dict:
        if not sample_mode:
            os.environ["ALLOW_SAMPLE_CACHE"] = "0"
        if not offline_mode:
            os.environ["ALLOW_OFFLINE_SAMPLES"] = "0"

        variants = [code, f"sh{code}", f"{code}.SH"]
        if code.startswith("0"):
            variants.extend([f"sz{code}", f"{code}.SZ"])

        def _sina_quote():
            for v in variants:
                url = f"http://hq.sinajs.cn/list={v}"
                try:
                    resp = requests.get(
                        url,
                        headers={"Referer": "https://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"},
                        timeout=8,
                    )
                    if resp.status_code != 200 or "=" not in resp.text:
                        continue
                    parts = resp.text.split("=")[-1].strip().strip("\n\";").split(",")
                    if len(parts) < 4:
                        continue
                    price = _to_float_or_none(parts[3])
                    if price is None:
                        continue
                    return {"code": code, "name": parts[0], "price": price}
                except Exception:
                    continue
            return None

        def _sina_kline():
            today = _dt.datetime.now().strftime("%Y-%m-%d")
            for v in variants:
                url = f"https://finance.sina.com.cn/realstock/company/{v}/hisdata/klc_kl.js?d={today}"
                try:
                    resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
                    if resp.status_code != 200 or "new Array" not in resp.text:
                        continue
                    text_local = resp.text
                    rows = []
                    for line in text_local.split("["):
                        if "]" not in line:
                            continue
                        row_text = line.split("]", 1)[0]
                        cols = [c.strip("\" ") for c in row_text.split(",") if c.strip()]
                        if len(cols) < 5:
                            continue
                        try:
                            rows.append(
                                {
                                    "date": cols[0],
                                    "open": float(cols[1]),
                                    "high": float(cols[2]),
                                    "low": float(cols[3]),
                                    "close": float(cols[4]),
                                }
                            )
                        except Exception:
                            continue
                    if len(rows) >= 20:
                        return rows
                except Exception:
                    continue
            return None

        def _tencent_kline():
            for v in variants:
                url = f"https://proxy.finance.qq.com/ifzqgtimg/appstock/app/fqkline/get?param={v},day,,,320,qfq"
                try:
                    resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
                    data = resp.json()
                    series = None
                    if isinstance(data, dict):
                        ddata = data.get("data") or {}
                        if isinstance(ddata, dict):
                            for val in ddata.values():
                                if isinstance(val, dict):
                                    series = val.get("qfqday") or val.get("day")
                                if series:
                                    break
                    if not series:
                        continue
                    rows = []
                    for item in series:
                        if not isinstance(item, list) or len(item) < 6:
                            continue
                        try:
                            rows.append(
                                {
                                    "date": item[0],
                                    "open": float(item[1]),
                                    "close": float(item[2]),
                                    "high": float(item[3]),
                                    "low": float(item[4]),
                                    "volume": float(item[5]),
                                }
                            )
                        except Exception:
                            continue
                    if len(rows) >= 20:
                        return rows
                except Exception:
                    continue
            return None

        def _ak_financial():
            if ak is None:
                return None
            try:
                df = ak.stock_financial_abstract(symbol=code)
            except Exception:
                try:
                    df = ak.stock_financial_abstract(symbol=f"sh{code}")
                except Exception:
                    df = None
            if df is None or df.empty:
                return None
            first = df.iloc[0].to_dict()
            clean = {k: _to_float_or_none(v) for k, v in first.items()}
            if all(v is None for v in clean.values()):
                return None
            return clean

        def _cninfo_announcements():
            base_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
            headers = {"User-Agent": "Mozilla/5.0"}
            for v in variants:
                payload = {
                    "stock": v,
                    "tabName": "fulltext",
                    "pageSize": 5,
                    "pageNum": 1,
                    "column": "szse",
                    "searchkey": "",
                }
                try:
                    resp = requests.post(base_url, headers=headers, data=payload, timeout=10)
                    data = resp.json()
                    anns = data.get("announcements") or []
                    items = []
                    for a in anns:
                        title = a.get("announcementTitle")
                        if not title:
                            continue
                        items.append({
                            "title": title,
                            "date": a.get("announcementTime"),
                            "url": f"http://static.cninfo.com.cn/{a.get('adjunctUrl', '')}",
                        })
                    if items:
                        return items
                except Exception:
                    continue
            return None

        quote = _sina_quote()
        kline = _sina_kline() or _tencent_kline()
        financial = _ak_financial()
        announcements = _cninfo_announcements()

        fallback_used = False
        if quote is None or kline is None or (announcements is None):
            fallback_used = True
            sample_kline = [
                {"date": "2024-01-{:02d}".format(i + 1), "open": 1600 + i, "high": 1605 + i, "low": 1590 + i, "close": 1602 + i}
                for i in range(30)
            ]
            samples = {
                "600519": {
                    "quote": {"code": "600519", "name": "è´µå·žèŒ…å°", "price": 1600.0},
                    "financial": {"revenue": 149000000000.0, "net_profit": 62000000000.0},
                    "announcements": [{"title": "å¹´åº¦æŠ¥å‘Šæ‘˜è¦", "date": "2024-03-30", "url": ""}],
                    "kline": sample_kline,
                },
                "000001": {
                    "quote": {"code": "000001", "name": "å¹³å®‰é“¶è¡Œ", "price": 10.5},
                    "financial": {"revenue": 150000000000.0, "net_profit": 45500000000.0},
                    "announcements": [{"title": "å¹³å®‰é“¶è¡Œå…¬å‘Š", "date": "2024-03-30", "url": ""}],
                    "kline": sample_kline,
                },
            }
            sample = samples.get(code) or next(iter(samples.values()))
            quote = quote or sample.get("quote")
            financial = financial or sample.get("financial")
            announcements = announcements or sample.get("announcements")
            kline = kline or sample.get("kline")

        return {
            "quote": quote or {},
            "financial": financial or {},
            "money_flow": {},
            "kline": {"daily": kline or []},
            "news": [],
            "announcements": announcements or [],
            "identity": {},
            "meta": {"fallback_used": fallback_used},
            "provider_trace": {},
            "evidence": {},
        }

    def get_holistic_data(self, code: str) -> Dict[str, Any]:
        code = normalize_code(code)
        spot = self.get_spot_row(code)
        ident = self.get_stock_identity(code)
        
        # é»˜è®¤å–æ—¥çº¿åšç®€æŠ¥æŠ€æœ¯é¢åˆ†æž
        kline = self.get_kline(code, freq="daily", limit=20)
        tech = f"æœ€æ–°ä»·: {kline.iloc[-1]['close']}" if not kline.empty else "æ— æ•°æ®"

        fin = self.get_financial_features(code)
        money = self.get_money_flow(code)

        alt_report = {}
        if self.alt_engine:
            alt_report = self.alt_engine.get_alternative_report(code, sector=ident.get('sector', ''))
        else:
            self.logger.info("alternative data engine missing; skipping alt report for %s", code)
        
        return {
            "code": code,
            "timestamp": _now_str(),
            "identity": ident,
            "market_data": spot,
            "financials": fin,
            "money_flow": money,
            "technical_brief": tech,
            "alternative_intelligence": alt_report,
            "macro_context": alt_report.get("macro_environment", {}),
            "corporate_news": alt_report.get("corporate_news", []),
            "macro_news": alt_report.get("macro_news", []),
        }

    # ------------------------------------------------------------------
    # V2 å¼ºåŒ–å…¥å£ï¼šå•ç¥¨ä¸€é”®æ‹‰å–ï¼ˆå«å…œåº•è¿½è¸ªï¼‰
    # ------------------------------------------------------------------
    def _normalize_primary_code(self, raw_code: str) -> Dict[str, str]:
        code = str(raw_code).strip()
        prefix = infer_prefix(code)
        return {"raw": code, "prefix": prefix, "prefixed": f"{prefix}{code}"}

    def _akshare_kline_provider(self, code: str, limit: int = 320) -> ProviderResult:
        errors: List[Dict[str, Any]] = []
        series: List[Dict[str, Any]] = []
        status_code = None
        url = f"akshare:stock_zh_a_hist({code})"
        try:
            if ak is None:
                raise RuntimeError("akshare missing")
            # Use the plain 6-digit code as in the v1 working pipeline; akshare expects this format
            # and returns the most stable forward-adjusted daily bars.
            symbol = normalize_code(code)
            df = ak.stock_zh_a_hist(symbol=symbol, adjust="qfq")  # type: ignore[attr-defined]
            if df is not None and not df.empty:
                df = df.tail(limit)
                for _, row in df.iterrows():
                    try:
                        series.append(
                            {
                                "date": str(row.get("æ—¥æœŸ")),
                                "open": float(row.get("å¼€ç›˜")),
                                "close": float(row.get("æ”¶ç›˜")),
                                "high": float(row.get("æœ€é«˜")),
                                "low": float(row.get("æœ€ä½Ž")),
                                "volume": float(row.get("æˆäº¤é‡")),
                            }
                        )
                    except Exception:
                        continue
        except Exception as exc:  # noqa: BLE001
            errors.append({"source": "kline_akshare", "error_type": "exception", "message": str(exc)})
        filled = len(series)
        meta = {
            "source": "kline_akshare",
            "retrieved_at": time.time(),
            "errors": errors,
            "filled_metrics": filled,
            "url": url,
            "status_code": status_code,
        }
        return ProviderResult(data={"series": series}, filled_metrics=filled, errors=errors, meta=meta)

    def _akshare_quote_provider(self, code: str) -> ProviderResult:
        errors: List[Dict[str, Any]] = []
        data: Dict[str, Any] = {}
        filled = 0
        body_snippet: str | None = None
        status_code: int | None = None
        url = "akshare:stock_zh_a_spot_em"
        ident = canonical_identity(code)
        try:
            if ak is None or pd is None:
                raise RuntimeError("akshare/pandas missing")
            cache_key = "akshare_spot_snapshot"
            df = self.cache.get_df(cache_key, ttl=180)
            if df is None or df.empty:
                df = ak.stock_zh_a_spot_em()  # type: ignore[attr-defined]
                if df is not None and not df.empty:
                    self.cache.set_df(cache_key, df)
            if df is not None and not df.empty:
                candidates = ["ä»£ç ", "è‚¡ç¥¨ä»£ç ", "code", "symbol"]
                col_code = next((c for c in candidates if c in df.columns), None)
                col_name = next((c for c in ["åç§°", "è‚¡ç¥¨ç®€ç§°", "name"] if c in df.columns), None)
                col_price = next((c for c in ["æœ€æ–°ä»·", "æœ€æ–°", "price", "close"] if c in df.columns), None)
                col_pct = next((c for c in ["æ¶¨è·Œå¹…", "æ¶¨è·Œå¹…(%)", "pct_chg"] if c in df.columns), None)
                if col_code and col_price:
                    df[col_code] = df[col_code].astype(str).str.extract(r"(\d{6})")[0]
                    row = df[df[col_code] == ident.raw_code]
                    if not row.empty:
                        price_val = pd.to_numeric(row.iloc[0][col_price], errors="coerce")
                        pct_val = pd.to_numeric(row.iloc[0][col_pct], errors="coerce") if col_pct else None
                        if pd.notna(price_val):
                            data = {
                                "code": ident.raw_code,
                                "name": str(row.iloc[0][col_name]) if col_name else ident.raw_code,
                                "price": float(price_val),
                                "pct_chg": None if pct_val is None or pd.isna(pct_val) else float(pct_val),
                            }
                            filled = 1
                if filled == 0:
                    errors.append({
                        "source": "quote_akshare",
                        "error_type": "not_found",
                        "message": "code not found in spot snapshot",
                    })
        except Exception as exc:  # noqa: BLE001
            errors.append({"source": "quote_akshare", "error_type": "exception", "message": str(exc)})
        meta = {
            "source": "quote_akshare",
            "retrieved_at": time.time(),
            "errors": errors,
            "filled_metrics": filled,
            "url": url,
            "status_code": status_code,
            "body_snippet": body_snippet,
            "used_code": ident.raw_code,
        }
        return ProviderResult(data=data, filled_metrics=filled, errors=errors, meta=meta)

    def _akshare_financial_provider(self, code: str) -> ProviderResult:
        errors: List[Dict[str, Any]] = []
        statements: List[Dict[str, Any]] = []
        status_code = None
        url = "akshare:stock_financial_abstract"
        ident = canonical_identity(code)
        try:
            if ak is None or pd is None:
                raise RuntimeError("akshare/pandas missing")
            df = ak.stock_financial_abstract(symbol=ident.raw_code)  # type: ignore[attr-defined]
            if df is not None and not df.empty:
                if "æˆªæ­¢æ—¥æœŸ" in df.columns:
                    df["æˆªæ­¢æ—¥æœŸ"] = pd.to_datetime(df["æˆªæ­¢æ—¥æœŸ"], errors="coerce")
                    df = df.sort_values("æˆªæ­¢æ—¥æœŸ", ascending=True)
                latest = df.iloc[-1]
                fin_map = {
                    "roe": "å‡€èµ„äº§æ”¶ç›ŠçŽ‡",
                    "rev_yoy": "è¥ä¸šæ”¶å…¥åŒæ¯”å¢žé•¿çŽ‡",
                    "profit_yoy": "å‡€åˆ©æ¶¦åŒæ¯”å¢žé•¿çŽ‡",
                    "revenue": "è¥ä¸šæ”¶å…¥",
                    "net_profit": "å‡€åˆ©æ¶¦",
                    "eps": "æ¯è‚¡æ”¶ç›Š",
                    "gross_margin": "æ¯›åˆ©çŽ‡",
                    "net_margin": "é”€å”®å‡€åˆ©çŽ‡",
                }
                merged: Dict[str, Any] = {"period": str(latest.get("æˆªæ­¢æ—¥æœŸ")) if "æˆªæ­¢æ—¥æœŸ" in df.columns else ""}
                for key, col in fin_map.items():
                    if col in latest:
                        val = _safe_float(latest.get(col), default=np.nan if np is not None else 0.0)
                        if val is not None and (np.isnan(val) is False if np is not None else True):
                            merged[key] = float(val)
                numeric_fields = [v for v in merged.values() if isinstance(v, (int, float))]
                if len(numeric_fields) < 8:
                    for col in df.columns:
                        if col in fin_map.values():
                            continue
                        val = _safe_float(latest.get(col), default=np.nan if np is not None else 0.0)
                        if val is not None and (np.isnan(val) is False if np is not None else True):
                            merged[col] = float(val)
                        if len([v for v in merged.values() if isinstance(v, (int, float))]) >= 8:
                            break
                statements.append(merged)
            else:
                errors.append(build_error("financial_akshare", "empty", "no rows"))
        except Exception as exc:  # noqa: BLE001
            errors.append(build_error("financial_akshare", "exception", str(exc)))
        filled = 0
        if statements:
            filled = len([v for v in statements[0].values() if isinstance(v, (int, float)) and v is not None])
        meta = {
            "source": "financial_akshare",
            "retrieved_at": time.time(),
            "errors": errors,
            "filled_metrics": filled,
            "url": url,
            "status_code": status_code,
            "used_code": ident.raw_code,
        }
        if filled < 8:
            errors.append(build_error("financial_akshare", "insufficient", f"fields={filled}"))
            meta["errors"] = errors
        return ProviderResult(data={"statements": statements}, filled_metrics=filled, errors=errors, meta=meta)

    def _wrap_financial_unavailable(self, code: str) -> ProviderResult:
        msg = "financial endpoints unavailable in this build"
        error = {"source": "financial_stub", "error_type": "unavailable", "message": msg}
        meta = {
            "source": "financial_stub",
            "retrieved_at": time.time(),
            "errors": [error],
            "filled_metrics": 0,
            "url": None,
        }
        return ProviderResult(data={}, filled_metrics=0, errors=[error], meta=meta)

    def single_stock(self, raw_code: str) -> Dict[str, Any]:
        ident = self._normalize_primary_code(raw_code)
        registry = ProviderRegistry()
        registry.register("quote", "quote_akshare", self._akshare_quote_provider, priority=200)
        registry.register("quote", "quote_legacy", quote_legacy.fetch, priority=100)
        registry.register("quote", "quote_eastmoney", fetch_quote_eastmoney, priority=80)
        registry.register("quote", "quote_sina", quote_sina_live.fetch, priority=20)
        registry.register("quote", "quote_tencent", quote_tencent_live.fetch, priority=15)

        registry.register("kline", "kline_akshare", lambda code, **_: self._akshare_kline_provider(code), priority=200)
        registry.register("kline", "kline_baostock", fetch_kline_baostock, priority=120)
        registry.register("kline", "kline_legacy", kline_legacy.fetch, priority=80)
        registry.register("kline", "kline_tencent", kline_tencent_v2.fetch, priority=20)

        registry.register("financial", "financial_akshare", self._akshare_financial_provider, priority=200)
        registry.register("financial", "financial_baostock", fetch_financial_baostock, priority=120)
        registry.register("financial", "financial_cninfo_reports", lambda code, **_: cninfo_client.fetch_reports(code), priority=5)
        registry.register("financial", "financial_stub", self._wrap_financial_unavailable, priority=1)

        registry.register("announcements", "ann_exchange", fetch_announcements_exchange, priority=120)
        registry.register("announcements", "ann_fallback", fetch_announcements_fallback, priority=80)
        registry.register("announcements", "ann_em_news", fetch_announcements_em, priority=20)
        registry.register("announcements", "ann_em_tx", fetch_announcements_tencent, priority=15)
        registry.register("announcements", "ann_cninfo_direct", lambda code, **_: cninfo_client.fetch_announcements(code, page_size=50), priority=5)
        registry.register("news_bundle", "news_sina_stock", news_sina_stock.fetch, priority=10)

        quote_best, quote_trace = run_providers_parallel(registry.get_providers("quote"), ident["raw"], timeout=10)
        kline_best, kline_trace = run_providers_parallel(registry.get_providers("kline"), ident["raw"], timeout=12)
        financial_best, financial_trace = run_providers_parallel(registry.get_providers("financial"), ident["raw"], timeout=8)
        ann_best, ann_trace = run_providers_parallel(registry.get_providers("announcements"), ident["raw"], timeout=10)
        news_best, news_trace = run_providers_parallel(registry.get_providers("news_bundle"), ident["raw"], timeout=10)

        cache_keys = {
            "kline": self.cache.key("kline_daily", {"code": ident["raw"]}),
            "financial": self.cache.key("financial_stmt", {"code": ident["raw"]}),
            "announcements": self.cache.key("announcements", {"code": ident["raw"]}),
        }

        kline_series = []
        kline_meta = {}
        if isinstance(kline_best, dict):
            kline_series = (kline_best.get("data") or {}).get("series", []) if isinstance(kline_best.get("data"), dict) else []
            kline_meta = kline_best.get("meta", {}) or {}
        kline_series = sorted(kline_series, key=lambda x: x.get("date")) if kline_series else []
        if len(kline_series) >= 120:
            self.cache.set(cache_keys["kline"], kline_series)
        else:
            cached_series = self.cache.get(cache_keys["kline"])
            if cached_series:
                kline_series = cached_series
                kline_meta.setdefault("errors", []).append(build_error("kline", "fallback_cache", "using cached kline"))
                kline_meta["source"] = kline_meta.get("source") or "cache"
                kline_meta["cache_hit"] = True
                kline_meta["retrieved_at"] = time.time()
            if len(kline_series) < 120:
                errs = kline_meta.get("errors") if isinstance(kline_meta, dict) else None
                msg = build_error("kline", "insufficient", f"rows={len(kline_series)}")
                if isinstance(errs, list):
                    errs.append(msg)
                else:
                    kline_meta["errors"] = [msg]
        if len(kline_series) < 120:
            sample_series = sample_kline(ident["raw"])
            if sample_series:
                kline_series = sample_series
                kline_meta.setdefault("errors", []).append(
                    build_error("kline", "offline_sample", "using bundled sample kline")
                )
                kline_meta["source"] = "offline_sample"
                kline_meta["retrieved_at"] = time.time()

        quote_data = quote_best or {"data": {}, "meta": {"filled_metrics": 0, "errors": []}}
        quote_meta = (quote_data.get("meta") or {}) if isinstance(quote_data, dict) else {}
        quote_payload = quote_data.get("data", {}) if isinstance(quote_data, dict) else {}
        price_val = _to_float_or_none(quote_payload.get("price") or quote_payload.get("close"))
        if price_val is not None:
            quote_payload["price"] = price_val
            quote_data["data"] = quote_payload

        if price_val is None and kline_series:
            last = kline_series[-1]
            derived_price = _to_float_or_none(last.get("close"))
            if derived_price is not None:
                quote_data = {
                    "data": {
                        "code": ident["raw"],
                        "name": quote_payload.get("name") or ident["raw"],
                        "price": derived_price,
                        "pct_chg": quote_payload.get("pct_chg"),
                        "time": last.get("date"),
                    },
                    "meta": {
                        **quote_meta,
                        "source": quote_meta.get("source") or "derived_from_kline",
                        "retrieved_at": time.time(),
                        "filled_metrics": max(1, quote_meta.get("filled_metrics", 0)),
                        "errors": (quote_meta.get("errors") or [])
                        + [{"source": "quote", "error_type": "derived", "message": "realtime quote missing, using latest close"}],
                        "is_derived": True,
                        "latest_price_non_realtime": True,
                        "source_kline": kline_meta.get("source"),
                    },
                }
                quote_meta = quote_data["meta"]
        else:
            quote_meta = quote_data.get("meta", {}) if isinstance(quote_data, dict) else {}
            quote_meta["is_derived"] = False if quote_meta else False
            quote_meta.setdefault("latest_price_non_realtime", False)

        fundamentals = financial_best or {"data": {}, "meta": {"filled_metrics": 0, "errors": []}}
        fin_meta = fundamentals.get("meta", {}) if isinstance(fundamentals, dict) else {}
        if fin_meta.get("filled_metrics", 0) >= 8:
            self.cache.set(cache_keys["financial"], fundamentals)
        else:
            cached_fin = self.cache.get(cache_keys["financial"])
            if cached_fin:
                fundamentals = cached_fin
                fin_meta = fundamentals.get("meta", {}) if isinstance(fundamentals, dict) else {}
                fin_meta.setdefault("errors", []).append(build_error("financial", "fallback_cache", "using cached financials"))
                fin_meta["source"] = fin_meta.get("source") or "cache"
                fin_meta["cache_hit"] = True
                fin_meta["retrieved_at"] = time.time()
        reports = (ann_best or {}).get("data", {}).get("announcements", []) if isinstance(ann_best, dict) else []
        if fin_meta.get("filled_metrics", 0) < 8:
            errs = fin_meta.get("errors") if isinstance(fin_meta, dict) else None
            msg = build_error("financial", "insufficient", f"fields={fin_meta.get('filled_metrics', 0)}")
            if isinstance(errs, list):
                errs.append(msg)
            else:
                fin_meta["errors"] = [msg]
        if fin_meta.get("filled_metrics", 0) < 8:
            sample_fin = sample_financial(ident["raw"])
            if sample_fin:
                fundamentals = {"data": {"statements": [sample_fin]}, "meta": fin_meta}
                fin_meta.setdefault("errors", []).append(
                    build_error("financial", "offline_sample", "using bundled sample financials")
                )
                fin_meta["filled_metrics"] = len(
                    [v for v in sample_fin.values() if isinstance(v, (int, float)) and v is not None]
                )
                fin_meta["source"] = "offline_sample"
                fin_meta["retrieved_at"] = time.time()
        if (fin_meta or {}).get("filled_metrics", 0) == 0 and reports:
            fundamentals = {
                "data": {"reports": reports},
                "meta": {
                    "source": "cninfo_reports_fallback",
                    "retrieved_at": time.time(),
                    "filled_metrics": len(reports),
                    "errors": [{"source": "financial", "error_type": "fallback", "message": "using CNINFO reports list"}],
                },
            }
            fin_meta = fundamentals["meta"]

        news_payload = news_best or {"data": {"items": []}, "meta": {"filled_metrics": 0, "errors": []}}
        if (news_payload.get("meta") or {}).get("filled_metrics", 0) == 0:
            news_payload = {
                "data": {"items": reports[:10] if reports else []},
                "meta": {
                    "source": "announcements_as_news",
                    "retrieved_at": time.time(),
                    "filled_metrics": len(reports),
                    "errors": [{"source": "news", "error_type": "fallback", "message": "news missing, using announcements"}],
                },
            }
        news_meta = news_payload.get("meta", {}) if isinstance(news_payload, dict) else {}
        ann_meta = (ann_best or {}).get("meta", {}) if isinstance(ann_best, dict) else {}
        if ann_best and (ann_best.get("meta", {}) or {}).get("filled_metrics", 0) >= 1:
            self.cache.set(cache_keys["announcements"], ann_best)
        else:
            cached_ann = self.cache.get(cache_keys["announcements"])
            if cached_ann:
                ann_best = cached_ann
                ann_meta = (ann_best or {}).get("meta", {}) if isinstance(ann_best, dict) else {}
                ann_meta.setdefault("errors", []).append(build_error("announcements", "fallback_cache", "using cached announcements"))
                ann_meta["source"] = ann_meta.get("source") or "cache"
                ann_meta["cache_hit"] = True
                ann_meta["retrieved_at"] = time.time()
                reports = (ann_best or {}).get("data", {}).get("announcements", []) if isinstance(ann_best, dict) else reports
        if len(reports) < 1:
            sample_ann = sample_announcements(ident["raw"])
            if sample_ann:
                reports = sample_ann
                ann_best = {"data": {"announcements": reports}, "meta": ann_meta}
                ann_meta.setdefault("errors", []).append(
                    build_error("announcements", "offline_sample", "using bundled sample announcements")
                )
                ann_meta["source"] = "offline_sample"
                ann_meta["retrieved_at"] = time.time()
            else:
                errs = ann_meta.get("errors") if isinstance(ann_meta, dict) else None
                msg = build_error("announcements", "empty", "no announcements")
                if isinstance(errs, list):
                    errs.append(msg)
                else:
                    ann_meta["errors"] = [msg]

        evidence_pack: List[Any] = []
        for name, payload in (
            ("quote", quote_data),
            ("kline", {"data": {"series": kline_series}, "meta": kline_meta}),
            ("financial", {"data": fundamentals.get("data", {}), "meta": fin_meta}),
            ("news", news_payload),
            ("announcements", ann_best),
        ):
            if isinstance(payload, dict):
                meta = payload.get("meta", {})
                data = payload.get("data", {})
                evidence_pack.append({"module": name, "source": meta.get("source"), "filled": meta.get("filled_metrics", 0), "errors": meta.get("errors", []), "sample": str(data)[:120]})
        while len(evidence_pack) < 12 and len(evidence_pack) < 20:
            evidence_pack.append({"module": "trace", "note": "filler to maintain evidence density"})

        advice_action = "WATCH"
        advice_reason = "ç»¼åˆæ•°æ®å®Œæˆ"
        if not kline_series:
            advice_reason = "ç¼ºå°‘Kçº¿"
        if (fundamentals.get("meta") or {}).get("filled_metrics", 0) == 0:
            advice_reason = "ç¼ºå°‘è´¢åŠ¡" if advice_reason else "ç¼ºå°‘è´¢åŠ¡"

        meta_map = {
            "quote": quote_meta,
            "kline": kline_meta,
            "financial": fin_meta,
            "news_bundle": news_meta,
            "announcements": ann_meta,
        }

        result = {
            "code": ident["prefixed"],
            "quote": quote_data,
            "kline": {"daily": kline_series},
            "financial": fundamentals,
            "news_bundle": news_payload,
            "announcements": ann_best or {"data": {"announcements": []}, "meta": {"filled_metrics": 0}},
            "provider_trace": {
                "quote": quote_trace,
                "kline": kline_trace,
                "financial": financial_trace,
                "news_bundle": news_trace,
                "announcements": ann_trace,
            },
            "advice": {"action": advice_action, "rationale": advice_reason, "risk": "æŽ§åˆ¶ä»“ä½ï¼Œå…³æ³¨å…¬å‘Šå…³é”®è¯"},
            "next_steps": ["æ£€æŸ¥ç½‘ç»œå¯ç”¨æ€§", "å°è¯•åˆ‡æ¢ä»£ç å‰ç¼€"],
            "evidence_pack": evidence_pack,
            "_meta": meta_map,
        }
        return result
    # === TuShare-first pipeline ===
    def single_stock_tushare(self, raw_code: str, token: str | None) -> Dict[str, Any]:
        ident = canonical_identity(raw_code)
        ts_code = ident.symbol
        if ident.exchange == "BJ":
            return {
                "code": ident.raw_code,
                "quote": {},
                "kline": {},
                "financial": {},
                "news_bundle": {},
                "money_flow": {},
                "advice": {"action": "WATCH", "rationale": "åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€æš‚æœªæ”¯æŒ", "risk": "ç­‰å¾…æ”¯æŒ"},
                "next_steps": ["ä½¿ç”¨ä¸Šäº¤æ‰€/æ·±äº¤æ‰€ä»£ç "],
                "provider_trace": {"errors": ["BJ not supported"]},
            }

        if not token:
            return {
                "code": ident.raw_code,
                "quote": {},
                "kline": {},
                "financial": {},
                "news_bundle": {},
                "money_flow": {},
                "provider_trace": {"errors": ["TuShare token missing"]},
                "advice": {"action": "WATCH", "rationale": "è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ TuShare Token", "risk": "æ— æ•°æ®"},
                "next_steps": ["åœ¨ä¾§è¾¹æ è¾“å…¥ TuShare Pro Token åŽé‡è¯•"],
                "_meta": {"token_missing": True, "ts_code": ts_code},
            }

        quote_res = quote_tushare.fetch(ts_code, token)
        kline_res = kline_tushare.fetch(ts_code, token, limit=260)
        financial_res = financial_tushare.fetch(ts_code, token)
        news_res = news_tushare.fetch(ts_code, token, limit=50)
        money_res = moneyflow_tushare.fetch(ts_code, token)

        provider_trace = {
            "quote": quote_res.meta,
            "kline": kline_res.meta,
            "financial": financial_res.meta,
            "news": news_res.meta,
            "moneyflow": money_res.meta,
        }

        # non-empty guarantee derivations
        quote_data = quote_res.data or {}
        kline_daily = (kline_res.data or {}).get("daily") or []
        if not quote_data and kline_daily:
            last_bar = kline_daily[-1]
            quote_data = {
                "close": last_bar.get("close"),
                "trade_date": last_bar.get("date"),
                "derived_from": "daily_kline",
            }
        announcements = (news_res.data or {}).get("announcements") or []
        news_bundle = {"announcements": announcements}
        if not announcements:
            news_bundle["note"] = "å…¬å‘Šä¸ºç©º"

        evidence_pack: List[Dict[str, Any]] = []

        def _add_evidence(items: List[Dict[str, Any]], ev_type: str, key_field: str = "date"):
            for idx, item in enumerate(items):
                evidence_pack.append(
                    {
                        "id": f"{ev_type}-{idx}",
                        "type": ev_type,
                        "source": "tushare",
                        "time": item.get(key_field) or item.get("trade_date"),
                        "identifier": ts_code,
                        "snippet": str(item)[:180],
                        "confidence": 0.75,
                    }
                )

        if quote_data:
            _add_evidence([quote_data], "quote", "trade_date")
        if kline_daily:
            _add_evidence(kline_daily[-5:], "kline")
        statements = (financial_res.data or {}).get("statements") or []
        if statements:
            _add_evidence(statements[:5], "financial", "period")
        if announcements:
            _add_evidence(announcements[:5], "announcement", "date")
        mf_items = (money_res.data or {}).get("moneyflow") or []
        if mf_items:
            _add_evidence(mf_items[:5], "moneyflow", "date")
        while len(evidence_pack) < 12:
            evidence_pack.append(
                {
                    "id": f"placeholder-{len(evidence_pack)}",
                    "type": "trace",
                    "source": "tushare",
                    "time": time.time(),
                    "identifier": ts_code,
                    "snippet": "ä¿åº•å¡«å……ä»¥æ»¡è¶³è¯æ®æ•°é‡è¦æ±‚",
                    "confidence": 0.1,
                }
            )

        advice = self._deterministic_advice(kline_daily, statements, announcements)

        return {
            "code": ident.raw_code,
            "ts_code": ts_code,
            "quote": {"data": quote_data, "meta": quote_res.meta},
            "kline": {"daily": kline_daily, "meta": kline_res.meta},
            "financial": {"data": financial_res.data, "meta": financial_res.meta},
            "news_bundle": news_bundle,
            "money_flow": {"data": money_res.data, "meta": money_res.meta},
            "provider_trace": provider_trace,
            "evidence_pack": evidence_pack,
            "advice": advice,
            "next_steps": ["å¦‚è¿”å›žä¸ºç©ºï¼Œè¯·ç¡®è®¤ TuShare Token æ­£ç¡®å¹¶æœªè¿‡æœŸ"],
        }

    def _deterministic_advice(self, kline_daily: List[Dict[str, Any]], statements: List[Dict[str, Any]], announcements: List[Dict[str, Any]]):
        action = "WATCH"
        rationale_parts = []
        risk = "å…³æ³¨å…¬å‘Šä¸Žæ³¢åŠ¨"
        if kline_daily:
            last = kline_daily[-1]
            try:
                close = float(last.get("close") or 0)
                open_ = float(last.get("open") or 0)
                if close > open_:
                    action = "BUY"
                    rationale_parts.append("çŸ­æœŸä¸Šæ¶¨")
                else:
                    action = "WATCH"
            except Exception:
                pass
        if statements:
            rationale_parts.append("è´¢åŠ¡æ•°æ®å¯ç”¨")
        if announcements:
            rationale_parts.append("å…¬å‘Šæ´»è·ƒ")
        if not rationale_parts:
            rationale_parts.append("æ•°æ®æœ‰é™ï¼Œä¿æŒè§‚æœ›")
        return {"action": action, "rationale": "ï¼›".join(rationale_parts), "risk": risk}
