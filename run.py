# -*- coding: utf-8 -*-
"""
======
äº”ç»´è¶…è„‘Â·å¤©ç½‘æŒ‡æŒ¥å° (Commercial Pro V12.0 - ç»ˆæå…¨èƒ½ç‰ˆ)

ã€ç‰ˆæœ¬ç‰¹æ€§ã€‘
1. **å…¨èƒ½è§†å›¾**: Kçº¿(æ—¥/å‘¨/æœˆ)ã€å› å­é›·è¾¾ã€æ·±åº¦ç ”æŠ¥ã€è´¢åŠ¡æ•°æ®ä¸€ç«™å¼å±•ç¤ºã€‚
2. **å¤šé‡äººæ ¼**: å®Œç¾æ¸²æŸ“ AI çš„â€œå•†ä¸šæ‹†è§£+å®è§‚ç­–ç•¥+æ¸¸èµ„åšå¼ˆâ€å¤šç»´åˆ†æã€‚
3. **å…¨åŸŸè¦†ç›–**: æ”¯æŒå…¨Aè‚¡åŠå„å¤§ç»†åˆ†æ¿å—æ‰«æã€‚
"""
import sys
import os
import re
from datetime import datetime, date
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
# å¼ºåˆ¶è®¾ç½® Pandas åç«¯é¿å… Arrow å†…å­˜é”™è¯¯
os.environ["PANDAS_ARROW_NO_EXTENSION"] = "1"
# å¼•å…¥æ ¸å¿ƒç»„ä»¶æ—¶æ·»åŠ å®¹é”™
try:
    import pandas as pd
except (ImportError, MemoryError) as e:
    pd = None
    print(f"Pandas åŠ è½½å¤±è´¥: {e}", file=sys.stderr)

try:
    from config_manager import get_config, update_keys, test_deepseek, test_tavily
except ImportError:
    # é™çº§é…ç½®ç®¡ç†å™¨ï¼ˆæ— é…ç½®åŠŸèƒ½æ—¶ä½¿ç”¨å†…å­˜å­—å…¸ï¼‰
    class MockConfig:
        def __init__(self):
            self.deepseek_api_key = ""
            self.tavily_api_key = ""
    _mock_cfg = MockConfig()
    def get_config(): return _mock_cfg
    def update_keys(**kwargs):
        for k, v in kwargs.items(): setattr(_mock_cfg, k, v)
    def test_deepseek(key): return (False, "config_manager æœªå®ç°")
    def test_tavily(key): return (False, "config_manager æœªå®ç°")

import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# æ ¸å¿ƒç»„ä»¶å®¹é”™å¯¼å…¥
try:
    from universe_cache import UniverseCache
except ImportError:
    class UniverseCache:
        def __init__(self): self.cache = {}
        def get(self, k): return self.cache.get(k)
        def set(self, k, v, ttl=3600): self.cache[k] = v

try:
    from data_engine import DataEngine, normalize_code, normalize_single_stock_payload, standardize_code
except ImportError:
    raise ImportError("è¯·ç¡®ä¿ data_engine.py å­˜åœ¨å¹¶å®ç°æ ¸å¿ƒæ–¹æ³•")

try:
    from tools.connectivity_doctor_v2 import probe_endpoints
except ImportError:
    def probe_endpoints(): return {"status": "connectivity_doctor_v2 æœªåŠ è½½"}

try:
    from market_scanner import MarketScanner, ScanConfig
except ImportError:
    class ScanConfig:
        def __init__(self, target_concepts=None): self.target_concepts = target_concepts or []
    class MarketScanner:
        def __init__(self, engine, cache): self.engine, self.cache = engine, cache
        def scan_cached(self, pool_id, config, cache_ttl=0): return (pd.DataFrame() if pd else [], None)

try:
    from deep_search_agent import DeepSearchAgent
except ImportError:
    class DeepSearchAgent:
        def __init__(self, deepseek_key, tavily_key): self.keys = (deepseek_key, tavily_key)
        def analyze_macro_situation(self): return {"core_logic": "æ¨¡æ‹Ÿå®è§‚åˆ†æ"}

try:
    from radiation_engine import RadiationEngine
except ImportError:
    class RadiationEngine:
        def __init__(self, api_key): self.api_key = api_key
        def infer_opportunities(self, intel):
            return {"core_theme": "æ¨¡æ‹Ÿä¸»çº¿", "strategy_rationale": "æ¨¡æ‹Ÿé€»è¾‘", "target_concepts": []}

try:
    from signal_fuser import SignalFuser
except ImportError:
    class SignalFuser:
        def __init__(self, engine, cache): self.engine, self.cache = engine, cache
        def fuse_signals(self, market_df, macro_report, logic_report, hot_sentiment_stocks):
            return market_df if pd else []

try:
    from slow_factor_engine import SlowFactorEngine
except ImportError:
    class SlowFactorEngine:
        def __init__(self, cache): self.cache = cache
        def enrich_market_df(self, df, engine, macro_report, logic_report, hotlist, as_of=None, topk=150):
            return df if pd else []

try:
    from paper_portfolio import simulate_paper_portfolio
except ImportError:
    def simulate_paper_portfolio(engine, candidates, start, end, top_k, rebalance, initial_cash, stop_loss, take_profit):
        return {"ok": False, "msg": "paper_portfolio æœªå®ç°"}

try:
    from research.decision_engine import build_decision
except ImportError:
    def build_decision(dp):
        return {"decision_card": {"verdict": "WATCH", "horizon": "1m", "data_quality_score": 50, "position_sizing_pct": 0}}

try:
    import ai_advisor
except ImportError:
    class MockAIAdvisor:
        @staticmethod
        def get_ai_strategy(dp, key):
            return {"ai_score": 5.0, "decision": "è§‚æœ›", "setup_logic": "æ¨¡æ‹Ÿé€»è¾‘", "scores": {}}
    ai_advisor = MockAIAdvisor()

try:
    from logging_utils import FetchResult, build_error, make_result
except ImportError:
    class FetchResult:
        def __init__(self, data, source, errors=None, fallback_used=False, cache_hit=False):
            self.data, self.source, self.errors = data, source, errors or []
            self.fallback_used, self.cache_hit = fallback_used, cache_hit
    def build_error(source, error_type, message):
        return {"source": source, "error_type": error_type, "message": message}
    def make_result(data, source, errors=None, fallback_used=False, cache_hit=False):
        return FetchResult(data, source, errors, fallback_used, cache_hit)

# Step4: backtest + weight learning (optional)
try:
    from weight_learner import learn_weights, save_weights, load_weights
    from step4_backtest import run_factor_backtest
except Exception:
    learn_weights = save_weights = load_weights = run_factor_backtest = None

# Optional pandas import to avoid pyarrow MemoryError on constrained hosts
_PD_REF: Optional[Any] = pd
_PD_ERROR: Optional[str] = None if pd else "Pandas not installed or MemoryError"

def _get_pandas():
    return _PD_REF

def _pd_available() -> bool:
    return _PD_REF is not None

def _pd_error_message() -> Optional[str]:
    return _PD_ERROR

def _safe_dataframe(df, **kwargs):
    """Render dataframe defensively to avoid Arrow conversion crashes."""
    pd = _get_pandas()
    if pd is None:
        st.write(df)
        return
    def _sanitize(frame):
        tmp = pd.DataFrame(frame).copy()
        for col in tmp.columns:
            if tmp[col].dtype == "object":
                tmp[col] = tmp[col].replace({"â€”": None, "--": None, "": None}).astype(str).fillna("")
            else:
                tmp[col] = pd.to_numeric(tmp[col], errors="coerce").fillna(0)
        return tmp
    try:
        return st.dataframe(_sanitize(df), **kwargs)
    except Exception as e:
        try:
            return st.dataframe(_sanitize(df).astype(str), **kwargs)
        except Exception:
            st.write("æ•°æ®æ¸²æŸ“å¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹æ•°æ®:")
            st.write(df.head(10))

# ==========================================
# 1. é¡µé¢å…¨å±€é…ç½®
# ==========================================
st.set_page_config(
    page_title="äº”ç»´è¶…è„‘ | ç»ˆæå•†ä¸šç‰ˆ",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥é¡¶çº§é‡‘èç»ˆç«¯ CSS
st.markdown("""
<style>
    /* æˆ˜å¤‡çŠ¶æ€é¢œè‰² */
    .defcon-attack { background-color: #d4edda; color: #155724; padding: 10px; border-left: 5px solid #28a745; }
    .defcon-defense { background-color: #fff3cd; color: #856404; padding: 10px; border-left: 5px solid #ffc107; }
    .defcon-retreat { background-color: #f8d7da; color: #721c24; padding: 10px; border-left: 5px solid #dc3545; }
    
    /* å†³ç­–é«˜äº® */
    .decision-buy { color: #d32f2f; font-weight: 900; font-size: 1.2em; }
    .decision-sell { color: #2e7d32; font-weight: 900; font-size: 1.2em; }
    
    /* å¡ç‰‡æ ·å¼ */
    .metric-card { background-color: #ffffff; padding: 15px; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); margin-bottom: 10px; }
    .logic-box { background-color: #f8f9fa; border-left: 4px solid #4e8cff; padding: 15px; margin-bottom: 10px; border-radius: 4px; }
    
    /* æ ‡ç­¾ */
    .tag-concept { background-color: #e3f2fd; color: #1565c0; padding: 2px 8px; border-radius: 12px; font-size: 0.85em; margin-right: 5px; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. åˆå§‹åŒ–ä¸è¿æ¥
# ==========================================
st.sidebar.title("ğŸ§  äº”ç»´è¶…è„‘ V12.0")
st.sidebar.caption("å…¨èƒ½å•†ä¸šå†³ç­–ç³»ç»Ÿ")

with st.sidebar.expander("ğŸ”‘ ç¥ç»è¿æ¥ (API Keys)", expanded=True):
    cfg = get_config()
    ds_key = st.text_input("DeepSeek Key", value=(cfg.deepseek_api_key or ""), type="password", help="ç”¨äº AI å®¡è®¡/å®è§‚ç ”åˆ¤/è¾å°„æ¨æ¼”")
    tavily_key = st.text_input("Tavily Key (å¯é€‰)", value=(cfg.tavily_api_key or ""), type="password", help="ç”¨äºè”ç½‘æœç´¢ï¼ˆä¸å¡«ä¹Ÿå¯ç¦»çº¿è¿è¡Œï¼‰")

    c1, c2, c3 = st.columns(3)
    if c1.button("ğŸ’¾ ä¿å­˜é…ç½®", width="stretch"):
        update_keys(deepseek_api_key=ds_key, tavily_api_key=tavily_key)
        st.success("å·²ä¿å­˜åˆ°æœ¬åœ°é…ç½®ï¼ˆ.w5brain_config.jsonï¼‰ã€‚å®šæ—¶æŒ‡æŒ¥å¡”ä¹Ÿä¼šè¯»å–åŒä¸€ä»½é…ç½®ã€‚")

    if c2.button("ğŸ”Œ æµ‹è¯•DeepSeek", width="stretch"):
        ok, msg = test_deepseek(ds_key)
        (st.success if ok else st.error)(msg)

    if c3.button("ğŸ”Œ æµ‹è¯•Tavily", width="stretch"):
        ok, msg = test_tavily(tavily_key)
        (st.success if ok else st.warning)(msg)

    # ä¿å­˜åˆ° Sessionï¼ˆç”¨äºæœ¬æ¬¡ä¼šè¯ç«‹å³ç”Ÿæ•ˆï¼‰
    st.session_state["api_key"] = ds_key
    st.session_state["tavily_key"] = tavily_key

offline_mode = st.sidebar.checkbox(
    "ç¦»çº¿æ ·æœ¬æ¨¡å¼ï¼ˆå…è®¸ä½¿ç”¨æœ¬åœ°æ ·æœ¬ fallbackï¼‰",
    value=os.environ.get("ALLOW_OFFLINE_SAMPLES", "").lower() in {"1", "true", "yes", "on"},
    help="é»˜è®¤å…³é—­ã€‚ä»…åœ¨æ— ç½‘åœºæ™¯ä¸‹æ‰‹åŠ¨å‹¾é€‰ï¼Œæ‰ä¼šä½¿ç”¨æœ¬åœ°æ ·æœ¬/å ä½æ•°æ®ã€‚",
)
os.environ["ALLOW_OFFLINE_SAMPLES"] = "1" if offline_mode else "0"
sample_mode = st.sidebar.checkbox("æ ·æœ¬æ¨¡å¼(å…è®¸ sample_cache)", value=False, help="é»˜è®¤å…³é—­ï¼Œå¼€å¯åæ‰å…è®¸è¯»å– sample_cache å…œåº•")
force_refresh = st.sidebar.checkbox("å¼ºåˆ¶åˆ·æ–°", value=False, help="å…³é—­ç¼“å­˜ï¼Œå¼ºåˆ¶æ‹‰å–æœ€æ–°æ•°æ®")
os.environ["ALLOW_SAMPLE_CACHE"] = "1" if sample_mode else "0"
os.environ["FORCE_REFRESH"] = "1" if force_refresh else "0"
st.session_state["offline_mode_flag"] = offline_mode
st.session_state["sample_mode"] = sample_mode
st.session_state["force_refresh"] = force_refresh

with st.sidebar.expander("ğŸ” è¿æ¥è‡ªæ£€", expanded=False):
    if st.button("è¿è¡Œ Connectivity Doctor v2", use_container_width=True):
        results = probe_endpoints()
        st.json(results)

pd_err_msg = _pd_error_message()
if pd_err_msg:
    st.sidebar.warning(
        "pandas æœªåŠ è½½ï¼Œå·²åˆ‡æ¢ä¸ºçº¯ Python è¡¨æ ¼å±•ç¤ºã€‚é”™è¯¯: {}".format(pd_err_msg)
    )

# åˆå§‹åŒ–å¼•æ“ (å•ä¾‹æ¨¡å¼)
if "init_done" not in st.session_state:
    with st.spinner("ç³»ç»Ÿè‡ªæ£€ä¸­..."):
        cache = UniverseCache()
        engine = DataEngine(cache=cache)
        st.session_state["engine"] = engine
        st.session_state["scanner"] = MarketScanner(engine=engine, cache=cache)
        st.session_state["fuser"] = SignalFuser(engine=engine, cache=cache)
        st.session_state["slow_engine"] = SlowFactorEngine(cache)
        st.session_state["init_done"] = True

# Ensure slow_engine exists even if session was created by old versions
if "slow_engine" not in st.session_state:
    try:
        _cache = getattr(st.session_state.get("engine"), "cache", None)
        st.session_state["slow_engine"] = SlowFactorEngine(_cache or UniverseCache())
    except Exception:
        st.session_state["slow_engine"] = SlowFactorEngine(UniverseCache())

# ä¾¿æ·å¼•ç”¨
ENGINE: DataEngine = st.session_state["engine"]
SCANNER: MarketScanner = st.session_state["scanner"]
FUSER: SignalFuser = st.session_state["fuser"]
SLOW: SlowFactorEngine = st.session_state.get("slow_engine")
search_agent = DeepSearchAgent(deepseek_key=ds_key, tavily_key=tavily_key)
rad_engine = RadiationEngine(api_key=ds_key)

# æ¨¡å¼é€‰æ‹©
mode = st.sidebar.radio("ä½œæˆ˜æ¨¡å¼", 
    ["â˜¢ï¸ å¤©ç½‘æœºä¼šé›·è¾¾ (Smart Radar)", "ğŸ” å•è‚¡æ·±åº¦åšå¼ˆ (Deep Game)", "ğŸ“¦ æ¨¡æ‹Ÿä»“ (Paper Portfolio)", "ğŸ“Š ç­–ç•¥å›æµ‹ (Time Machine)"], 
    index=0
)

# ==========================================
# 2.5 å…¼å®¹å·¥å…·å‡½æ•°
# ==========================================

def _fmt_ts(ts_val: float) -> str:
    try:
        return datetime.fromtimestamp(float(ts_val)).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return "-"

def _fmt_val(val, suffix: str = ""):
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return "â€”"
    if isinstance(val, (int, float)):
        return f"{val}{suffix}"
    return str(val).replace("--", "â€”").replace("", "â€”") + suffix

def _normalize_trade_date(val: Any) -> Optional[str]:
    try:
        if isinstance(val, (datetime, date)):
            return val.strftime("%Y-%m-%d")
        s = str(val).strip()
        if not s:
            return None
        if re.fullmatch(r"\d{8}", s):
            return f"{s[:4]}-{s[4:6]}-{s[6:]}"
        if re.fullmatch(r"\d{4}-\d{2}-\d{2}", s):
            return s
        return s.split(" ")[0]
    except Exception:
        return None

def _extract_latest_close(kline_obj) -> Tuple[Optional[float], Optional[str]]:
    """Safely extract the latest close and date from flexible kline payloads."""
    def _as_float(val: Any) -> Optional[float]:
        try:
            f = float(val)
            return f if not np.isnan(f) else None
        except Exception:
            return None

    close_candidates = {"close", "closing", "æ”¶ç›˜", "æ”¶ç›˜ä»·"}
    date_candidates = {"date", "trade_date", "æ—¶é—´", "æ—¥æœŸ", "day"}
    pd = _get_pandas()

    if kline_obj is None:
        return None, None

    # pandas DataFrame path
    if pd is not None and isinstance(kline_obj, pd.DataFrame):
        df = kline_obj
        if df.empty:
            return None, None
        mapping = {str(col).lower(): col for col in df.columns}
        close_col = next((mapping[c] for c in mapping if c in close_candidates), None)
        if close_col is None:
            return None, None
        date_col = next((mapping[c] for c in mapping if c in date_candidates), None)
        df_work = df.dropna(subset=[close_col]) if close_col in df.columns else df
        if df_work.empty:
            return None, None
        if date_col and date_col in df_work.columns:
            try:
                df_work = df_work.sort_values(by=date_col)
            except Exception:
                pass
        latest_row = df_work.iloc[-1]
        return _as_float(latest_row.get(close_col)), _normalize_trade_date(latest_row.get(date_col))

    # list of dicts path
    if isinstance(kline_obj, list):
        for item in reversed(kline_obj):
            if not isinstance(item, dict):
                continue
            item_lower = {str(k).lower(): v for k, v in item.items()}
            close_val = next((item_lower.get(c) for c in close_candidates if c in item_lower), None)
            close_val = _as_float(close_val)
            if close_val is None:
                continue
            date_val = next((item_lower.get(c) for c in date_candidates if c in item_lower), None)
            return close_val, _normalize_trade_date(date_val)

    return None, None

def _render_errors(errors):
    if not errors:
        st.caption("æ— é”™è¯¯")
        return
    for err in errors:
        src = err.get("source", "?")
        typ = err.get("error_type", "?")
        msg = err.get("message", "")
        st.error(f"æ¥æº: {src} | ç±»å‹: {typ} | è¯¦æƒ…: {msg}")

def _safe_fetch(fn, label: str) -> FetchResult:
    try:
        res = fn()
        if isinstance(res, FetchResult):
            return res
        if hasattr(res, "ok") and hasattr(res, "errors"):
            return res
        return make_result({}, source=label, errors=[build_error(label, "invalid", "è¿”å›ç»“æ„é FetchResult")])
    except Exception as e:
        return make_result({}, source=label, fallback_used=True, errors=[build_error(label, "exception", str(e))])

def _safe_holistic(engine, code: str):
    code_std = standardize_code(code)
    try:
        res = engine.single_stock(code_std)
        res = normalize_single_stock_payload(res)
        res["money_flow"] = res.get("money_flow", {})
        return res
    except Exception as e:
        return {
            "code": code_std,
            "market_data": {},
            "identity": {},
            "financial": {},
            "money_flow": {},
            "news_bundle": {},
            "diagnostics": [],
            "evidence_pack": [],
            "advice": {"action": "è§‚æœ›", "evidence": []},
            "_meta": {"error": str(e)},
        }

def _as_dict(val: Optional[dict]) -> dict:
    return val if isinstance(val, dict) else {}

def _errors_count(errs) -> int:
    return len(errs) if isinstance(errs, list) else 0

def _filled_from_meta(meta_obj: Optional[dict]):
    base = _as_dict(meta_obj)
    inner = _as_dict(base.get("meta"))
    return base.get("filled_metrics") or base.get("count") or inner.get("filled_metrics") or inner.get("count")

def _render_meta(meta: Optional[dict]):
    meta = _as_dict(meta)
    src = meta.get("source", "-")
    fb = "æ˜¯" if meta.get("fallback_used") else "å¦"
    cache = "å‘½ä¸­" if meta.get("cache_hit") else "æœªå‘½ä¸­"
    ts_str = _fmt_ts(meta.get("ts"))
    filled = _filled_from_meta(meta)
    st.caption(
        "æ¥æº: {} | fallback: {} | ç¼“å­˜: {} | æ—¶é—´: {} | è¦†ç›–: {}".format(
            src, fb, cache, ts_str, filled if filled is not None else "â€”",
        )
    )

def _minmax_norm(s):
    pd = _get_pandas()
    if pd is None or len(s) == 0:
        return [0.5] * (len(s) if hasattr(s, "__len__") else 0)
    s = pd.to_numeric(s, errors="coerce").fillna(0.0)
    mn, mx = float(s.min()), float(s.max())
    if mx - mn < 1e-9:
        return pd.Series([0.5] * len(s), index=s.index)
    return (s - mn) / (mx - mn)

def compute_entry_scores(df):
    """Compute entry_score for 'build position now' list.

    å•†ç”¨åŒ–é—­ç¯ï¼ˆStep4ï¼‰ï¼š
    - å…ˆç”¨ Smart Radar æ‰«æç§¯ç´¯æ…¢å˜é‡
    - ä½¿ç”¨æƒé‡å­¦ä¹ è¾“å‡º .w5brain_weights.json
    - è¿™é‡Œè‡ªåŠ¨åŠ è½½æƒé‡ï¼ŒæŠŠâ€œæ…¢å˜é‡â€è½¬æˆå¯è¿­ä»£çš„å»ºä»“è¯„åˆ†
    """
    pd = _get_pandas()
    if pd is None or df is None or df.empty:
        return df
    d = df.copy()
    base_col = "fused_score" if "fused_score" in d.columns else "score"
    if base_col not in d.columns:
        d[base_col] = 0.5
    base_norm = _minmax_norm(d[base_col])
    slow = pd.to_numeric(d.get("slow_score", 0.5), errors="coerce").fillna(0.5).clip(0, 1)

    learned = None
    try:
        if load_weights:
            model = load_weights(".w5brain_weights.json")
        else:
            model = None
        if isinstance(model, dict) and model.get("ok"):
            w = model.get("weights") or {}
            mu = model.get("mu") or {}
            sd = model.get("sd") or {}
            def row_score(r):
                s = 0.0
                for k, ww in w.items():
                    x = float(pd.to_numeric(r.get(k, 0.5), errors="coerce") or 0.5)
                    m = float(mu.get(k, 0.0) or 0.0)
                    ss = float(sd.get(k, 1.0) or 1.0)
                    z = (x - m) / (ss if ss != 0 else 1.0)
                    s += float(ww) * float(z)
                # sigmoid to 0~1
                return float(1.0 / (1.0 + np.exp(-2.2 * s)))
            learned = d.apply(row_score, axis=1).clip(0, 1)
            d["learned_score"] = learned.round(4)
    except Exception:
        learned = None

    if learned is not None:
        # blend: fast resonance + slow total + learned
        d["entry_score"] = (0.45 * base_norm + 0.35 * slow + 0.20 * learned).clip(0, 1).round(4)
    else:
        d["entry_score"] = (0.6 * base_norm + 0.4 * slow).clip(0, 1).round(4)

    # build action + sizing (ç®€åŒ–ç‰ˆï¼Œå¯åœ¨ Step5+ å†è¿­ä»£ä¸ºæ›´ç²¾ç»†çš„é£æ§/ä»“ä½ç®—æ³•)
    mp = pd.to_numeric(d.get("market_pricing", 0.5), errors="coerce").fillna(0.5).clip(0,1)
    info = pd.to_numeric(d.get("info_priced_in", 0.5), errors="coerce").fillna(0.5).clip(0,1)
    pct = pd.to_numeric(d.get("pct", 0.0), errors="coerce").fillna(0.0)
    # è¿½é«˜é£é™©ï¼šå•æ—¥æ¶¨å¹…è¿‡å¤§ + é‡æ¯”è¿‡é«˜
    vr = pd.to_numeric(d.get("vol_ratio", 1.0), errors="coerce").fillna(1.0)
    chase_risk = (pct >= 6.0) & (vr >= 1.8)

    def _action(row):
        es = float(row.get("entry_score", 0.0) or 0.0)
        mp_val = float(row.get("market_pricing", 0.5) or 0.5)
        info_val = float(row.get("info_priced_in", 0.5) or 0.5)
        if es >= 0.80 and mp_val >= 0.50 and info_val <= 0.72:
            return "BUILD_NOW"
        if es >= 0.68 and info_val <= 0.78:
            return "WATCH"
        return "AVOID"

    d["build_action"] = d.apply(_action, axis=1)
    d.loc[chase_risk, "build_action"] = "WATCH"

    # ä»“ä½å»ºè®®ï¼š0~12%ï¼ˆå•ç¥¨ï¼‰ï¼Œå¹¶å¯¹æ‹¥æŒ¤åº¦/ä¼°å€¼åšæŠ˜æ‰£
    es = pd.to_numeric(d.get("entry_score", 0.0), errors="coerce").fillna(0.0).clip(0,1)
    pos = (0.02 + es * 0.10) * (0.65 + 0.35 * mp) * (0.85 + 0.15 * (1.0 - info))
    d["position_pct"] = pos.clip(0.01, 0.12).round(4)

    # ç®€æ˜“æ­¢æŸï¼š8%ï¼ˆå¯åœ¨æ¨¡æ‹Ÿä»“é‡Œè‡ªå®šä¹‰ï¼‰
    d["stop_loss_pct"] = 0.08

    return d.sort_values("entry_score", ascending=False)

# ==========================================
# 3. å¯è§†åŒ–ç»˜å›¾ç»„ä»¶
# ==========================================

def plot_kline(code, freq='daily', title="Kçº¿å›¾"):
    """ç»˜åˆ¶ä¸“ä¸š K çº¿å›¾ (æ—¥/å‘¨/æœˆ)"""
    pd = _get_pandas()
    if pd is None:
        st.warning("âš ï¸ Pandas æœªåŠ è½½ï¼Œæ— æ³•ç»˜åˆ¶ K çº¿å›¾")
        return
    try:
        df = ENGINE.get_kline(code, freq=freq, limit=120)
    except Exception as e:
        st.warning(f"âš ï¸ è·å– K çº¿æ•°æ®å¤±è´¥: {e}")
        return
    if df.empty:
        st.warning(f"âš ï¸ {title}: æš‚æ— æ•°æ®")
        return
    
    # è®¡ç®—å‡çº¿ï¼ˆå®¹é”™å¤„ç†ï¼‰
    df['MA5'] = df['close'].rolling(5, min_periods=1).mean()
    df['MA20'] = df['close'].rolling(20, min_periods=1).mean()

    # åˆ›å»ºå­å›¾ (ä¸Šå›¾Kçº¿ï¼Œä¸‹å›¾æˆäº¤é‡)
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, 
                        vertical_spacing=0.03, row_heights=[0.7, 0.3])
    
    # Kçº¿ä¸»å›¾
    fig.add_trace(go.Candlestick(
        x=df['date'], open=df['open'], high=df['high'], low=df['low'], close=df['close'], 
        name='Kçº¿', increasing_line_color='#eb5353', decreasing_line_color='#3bceac'
    ), row=1, col=1)
    
    # å‡çº¿
    fig.add_trace(go.Scatter(x=df['date'], y=df['MA5'], line=dict(color='orange', width=1), name='MA5'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df['date'], y=df['MA20'], line=dict(color='#4e8cff', width=1), name='MA20'), row=1, col=1)
    
    # æˆäº¤é‡
    colors = ['#eb5353' if r.close >= r.open else '#3bceac' for i, r in df.iterrows()]
    fig.add_trace(go.Bar(x=df['date'], y=df['volume'], marker_color=colors, name='æˆäº¤é‡'), row=2, col=1)
    
    # å¸ƒå±€ä¼˜åŒ–
    fig.update_layout(
        xaxis_rangeslider_visible=False, 
        height=500, 
        margin=dict(l=10, r=10, t=30, b=10), 
        template="plotly_white",
        title=dict(text=title, font=dict(size=14))
    )
    st.plotly_chart(fig, use_container_width=True)

def plot_radar(scores: dict):
    """ç»˜åˆ¶å› å­è¯„åˆ†é›·è¾¾å›¾"""
    if not scores: 
        st.warning("æš‚æ— è¯„åˆ†æ•°æ®ï¼Œæ— æ³•ç»˜åˆ¶é›·è¾¾å›¾")
        return
    # è¡¥å…¨ç¼ºå¤±ç»´åº¦çš„è¯„åˆ†
    categories = ['å®è§‚/è¡Œä¸š', 'åŸºæœ¬é¢', 'æŠ€æœ¯é¢', 'èµ„é‡‘é¢', 'æƒ…ç»ªé¢', 'é£é™©æ§åˆ¶']
    values = [
        scores.get('macro_industry', 0), scores.get('fundamental', 0),
        scores.get('technical', 0), scores.get('money_flow', 0),
        scores.get('sentiment', 0), scores.get('risk_control', 0)
    ]
    # é—­åˆé›·è¾¾
    values.append(values[0])
    categories.append(categories[0])
    
    fig = go.Figure(data=go.Scatterpolar(
        r=values, theta=categories, fill='toself', 
        line_color='#4e8cff', fillcolor='rgba(78, 140, 255, 0.3)'
    ))
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 10])), 
        showlegend=False, height=300, 
        margin=dict(t=20, b=20, l=40, r=40)
    )
    st.plotly_chart(fig, use_container_width=True)

# ==========================================
# 4. ä¸»åŠŸèƒ½é€»è¾‘
# ==========================================

# ------------------------------------------------------------------
# æ¨¡å¼ A: å¤©ç½‘æœºä¼šé›·è¾¾ (Smart Radar) - å…¨åŸŸæ‰«æ
# ------------------------------------------------------------------
if mode == "â˜¢ï¸ å¤©ç½‘æœºä¼šé›·è¾¾ (Smart Radar)":
    
    # --- æƒ…æŠ¥ä¸æ¨æ¼” ---
    c_intel, c_logic = st.columns([1, 1])
    with c_intel:
        st.subheader("1. å…¨ç½‘å“¨å…µ (Intelligence)")
        if st.button("ğŸ“¡ å¯åŠ¨å®è§‚æ·±æœ", type="primary"):
            with st.status("æ­£åœ¨æ‰«æå…¨ç½‘å®è§‚ä¸èˆ†æƒ…...", expanded=True):
                try:
                    st.write("æŠ“å–å¸‚åœºçƒ­æ¦œ...")
                    hot_spots = ENGINE.get_market_hot_spots()
                except Exception as e:
                    hot_spots = [f"çƒ­æ¦œè·å–å¤±è´¥: {e}"]
                st.write("åˆ†æå®è§‚å®šè°ƒ...")
                macro_rep = search_agent.analyze_macro_situation()
                st.session_state["macro_report"] = macro_rep
                st.session_state["raw_intel"] = "\n".join(hot_spots) + "\n" + macro_rep.get("core_logic", "")
                st.success("æƒ…æŠ¥æœé›†å®Œæˆ")
                st.rerun()

        if "raw_intel" in st.session_state:
            with st.expander("æŸ¥çœ‹åŸå§‹æƒ…æŠ¥æ± "): st.text(st.session_state["raw_intel"])

    with c_logic:
        st.subheader("2. è¾å°„æ¨æ¼” (Radiation)")
        if st.button("ğŸ§  æ¿€æ´»è¾å°„å¼•æ“", disabled="raw_intel" not in st.session_state):
            with st.spinner("AI æ­£åœ¨æ„å»ºäº§ä¸šé“¾å›¾è°±..."):
                rad_res = rad_engine.infer_opportunities(st.session_state.get("raw_intel", ""))
                st.session_state["rad_res"] = rad_res
    
    if "rad_res" in st.session_state:
        res = st.session_state["rad_res"]
        st.success(f"ğŸ¯ æ ¸å¿ƒä¸»çº¿: {res.get('core_theme')} | æˆ˜ç•¥ç†ç”±: {res.get('strategy_rationale')}")

    # --- æ‰«æä¸å…±æŒ¯ ---
    st.markdown("---")
    st.subheader("3. å®šå‘çˆ†ç ´ä¸å…±æŒ¯ (Blast & Fuse)")
    
    c_scan1, c_scan2 = st.columns([1, 3])
    with c_scan1:
        # å®Œæ•´çš„å…¨åŸŸç­–ç•¥æ± 
        pool_options = {
            "ğŸŒ å…¨Aè‚¡ (æœºä¼šæ€»è§ˆ)": "all_a_shares",
            "ğŸ† æ ¸å¿ƒèµ„äº§ (Top100)": "core_assets_top100",
            "ğŸ¦ æœºæ„é‡ä»“ (Top300)": "institutional_top300",
            "ğŸš€ åˆ›ä¸šæ¿ç‰¹æ”» (30å¼€å¤´)": "growth_gem",
            "ğŸ˜ ä¸»æ¿è“ç­¹ (60/00/002)": "sh_main_board", 
            "âœ¨ å°å¸‚å€¼é€†å‘ (åšå¼ˆ)": "small_cap_contrarian"
        }
        sel_label = st.selectbox("ğŸ¯ é€‰æ‹©æˆ˜ç•¥åº•æ± ", list(pool_options.keys()))
        pool_id = pool_options[sel_label]
        
        top_n = st.slider("æ˜¾ç¤ºæ•°é‡", 10, 200, 50)
        
        if st.button("ğŸš€ å‘å°„ä¿¡å·ç†”æ–­å™¨", type="primary"):
            target_concepts = st.session_state.get("rad_res", {}).get("target_concepts", [])
            
            with st.status("æ‰§è¡Œå¤šç»´æ‰«æ...", expanded=True):
                st.write(f"æ­£åœ¨æ‰«æ {sel_label}...")
                config = ScanConfig(target_concepts=target_concepts)
                try:
                    df_scan, _ = SCANNER.scan_cached(pool_id, config, cache_ttl=0)
                except Exception as e:
                    st.error(f"æ‰«æå¤±è´¥: {e}")
                    df_scan = pd.DataFrame() if _pd_available() else []
                
                st.write("Fuser: æ‰§è¡Œæ—¶é—´è½´å¯¹é½ + å®è§‚å¦å†³...")
                try:
                    df_final = FUSER.fuse_signals(
                        market_df=df_scan,
                        macro_report=st.session_state.get("macro_report", {}),
                        logic_report=st.session_state.get("rad_res", {}),
                        hot_sentiment_stocks=[]
                    )
                except Exception as e:
                    st.warning(f"ä¿¡å·èåˆå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
                    df_final = df_scan

                st.write("SlowFactors: computing policy/demand/substitution/pricing/info...")
                try:
                    df_final = SLOW.enrich_market_df(
                        df_final,
                        engine=ENGINE,
                        macro_report=st.session_state.get("macro_report", {}),
                        logic_report=st.session_state.get("rad_res", {}),
                        hotlist=[],
                        as_of=None,
                        topk=min(150, len(df_final) if df_final is not None else 0)
                    )
                except Exception as _e:
                    st.warning(f"æ…¢å› å­è®¡ç®—å¤±è´¥: {_e}")

                try:
                    df_final = compute_entry_scores(df_final)
                    st.session_state["fused_result"] = df_final
                    st.success("æ‰«æå®Œæˆ")
                except Exception as e:
                    st.error(f"è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")

    with c_scan2:
        if "fused_result" in st.session_state:
            df_res = st.session_state["fused_result"]
            pd = _get_pandas()
            if pd is not None and df_res.empty:
                st.warning("æš‚æ— ç¬¦åˆæ¡ä»¶çš„æ ‡çš„")
            else:
                st.success(f"ğŸ† æœ€ç»ˆå…¥å›´: {len(df_res)} åª")
            
            # æ ¼å¼åŒ–å±•ç¤ºï¼ˆåŠ¨æ€åˆ—ï¼Œé¿å… length mismatchï¼‰
            cols = []
            labels = []
            def add(c, l):
                if pd is not None and c in df_res.columns:
                    cols.append(c)
                    labels.append(l)
            add("code", "ä»£ç ")
            add("name", "åç§°")
            add("sector", "è¡Œä¸š")
            add("close", "ç°ä»·")
            add("score", "é‡åŒ–åˆ†")
            add("fused_score", "âš¡å…±æŒ¯åˆ†")
            add("slow_score", "ğŸ¢æ…¢å˜é‡")
            add("learned_score", "ğŸ§ æƒé‡åˆ†")
            add("fundamental_quality", "ğŸ¦è´¢æŠ¥è´¨")
            add("fundamental_growth", "ğŸ“Šè´¢æŠ¥å¢")
            add("ops_momentum", "ğŸ›°ï¸è¿è¥åŠ¨")
            add("entry_score", "âœ…å»ºä»“åˆ†")
            add("slow_evidence", "è¯æ®(ç®€)")
            if cols:
                disp = df_res[cols].head(top_n).copy()
                disp.columns = labels
                _safe_dataframe(disp, use_container_width=True)
            else:
                _safe_dataframe(df_res.head(top_n), use_container_width=True)

            # æ·±åº¦å®¡è®¡å…¥å£
            st.divider()
            c_audit1, c_audit2 = st.columns([3, 1])
            try:
                code_list = disp["ä»£ç "].head(20).tolist() if cols else df_res["code"].head(20).tolist()
                sel_code = c_audit1.selectbox("ğŸ” é€‰æ‹©æ ‡çš„è¿›è¡Œæ·±åº¦åšå¼ˆ", code_list)
                if c_audit2.button("å‘¼å« AI å®¡è®¡è¯¥è‚¡"):
                    with st.spinner("AI æ­£åœ¨æ’°å†™æ·±åº¦ç ”æŠ¥..."):
                        dp = _safe_holistic(ENGINE, sel_code)
                        dp['radiation_context'] = st.session_state.get("rad_res")
                        report = ai_advisor.get_ai_strategy(dp, ds_key)
                        st.json(report)
            except Exception as e:
                st.warning(f"å®¡è®¡åŠŸèƒ½å¼‚å¸¸: {e}")

# ------------------------------------------------------------------
# æ¨¡å¼ B: å•è‚¡æ·±åº¦åšå¼ˆ (Deep Game) - æ ¸å¿ƒå±•ç¤ºåŒº
# ------------------------------------------------------------------
elif mode == "ğŸ” å•è‚¡æ·±åº¦åšå¼ˆ (Deep Game)":
    st.subheader("ğŸ” å•æ ‡çš„æ˜¾å¾®é•œ (Deep Microscope)")
    
    # è¾“å…¥åŒº
    c_in1, c_in2 = st.columns([3, 1])
    code_input = c_in1.text_input("è¾“å…¥ä»£ç  (å¦‚ 000801)", "000801")
    
    if c_in2.button("ğŸš€ å¯åŠ¨åšå¼ˆ", type="primary"):
        if not ds_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§é…ç½® API Key")
        else:
            with st.spinner("å…¨æ¯æ•°æ®æ‰«æ + AI å¤šé‡äººæ ¼åšå¼ˆä¸­..."):
                dp = _safe_holistic(ENGINE, code_input)
                try:
                    report = ai_advisor.get_ai_strategy(dp, ds_key)
                    st.session_state['report'] = report
                    st.session_state['dp'] = dp
                except Exception as e:
                    st.error(f"AI åˆ†æå¤±è´¥: {e}")

    # ç»“æœå±•ç¤ºåŒº
    if 'report' in st.session_state and 'dp' in st.session_state:
        rep = st.session_state['report']
        dp = st.session_state['dp']
        news_bundle = _as_dict(dp.get("news_bundle"))
        meta_map = _as_dict(dp.get("_meta"))
        quote_meta = _as_dict(meta_map.get("quote"))
        identity_meta = _as_dict(meta_map.get("identity"))
        kline_meta = _as_dict(meta_map.get("kline"))
        fin_meta = _as_dict(meta_map.get("financial"))
        money_meta = _as_dict(meta_map.get("money_flow"))
        alt_meta = _as_dict(meta_map.get("alternative"))
        news_meta = _as_dict(meta_map.get("news_bundle"))
        ann_meta = _as_dict(meta_map.get("announcements"))

        # 1. æ ¸å¿ƒå†³ç­–å¤´ (Header)
        st.markdown("---")
        id_name = _as_dict(dp.get('identity')).get('name') or dp.get('code')
        sector = _as_dict(dp.get('identity')).get('sector', '') or '-'
        st.markdown(f"### {id_name} ({dp.get('code')}) | <span class='tag-concept'>{sector}</span>", unsafe_allow_html=True)

        c_h1, c_h2, c_h3, c_h4 = st.columns(4)
        md = _as_dict(dp.get('market_data'))
        raw_close = md.get('price') if md.get('price') not in (None, "", "--") else md.get('close')
        pct_delta = _fmt_val(md.get('pct') or md.get('pct_chg'), suffix="%")

        def _valid_float(val: Any) -> Optional[float]:
            try:
                f = float(val)
                return f if not np.isnan(f) else None
            except Exception:
                return None

        derived_close, derived_date = (None, None)
        close_for_display = raw_close
        if _valid_float(close_for_display) is None:
            derived_close, derived_date = _extract_latest_close(dp.get('kline_daily') or dp.get('kline'))
            if derived_close is not None:
                close_for_display = derived_close

        c_h1.metric("ç°ä»·", _fmt_val(close_for_display), pct_delta)
        if derived_close is not None:
            latest_date = derived_date or "æœªçŸ¥"
            c_h1.caption(f"éå®æ—¶ï¼šä½¿ç”¨æœ€è¿‘æ”¶ç›˜ä»· {latest_date}")
        elif quote_meta:
            source_badge = quote_meta.get('source') or '-'
            c_h1.caption(f"è¡Œæƒ…æº: {source_badge}")
        c_h2.metric("AI ç»¼åˆè¯„åˆ†", _fmt_val(rep.get('ai_score')))
        st.caption(
            f"è¡Œæƒ…æº: {quote_meta.get('source') or '-'} | Kçº¿æº: {kline_meta.get('source') or '-'} | è´¢æŠ¥æº: {fin_meta.get('source') or '-'} | å…¬å‘Šæº: {ann_meta.get('source') or '-'}"
        )

        # deterministic æŠ•ç ”ç»“è®ºå¡
        try:
            decision_bundle = build_decision(dp)
        except Exception as e:
            st.warning(f"å†³ç­–å¡ç”Ÿæˆå¤±è´¥: {e}")
            decision_bundle = {}
        decision_card = _as_dict(decision_bundle.get("decision_card", {}))
        st.markdown("### ğŸ§­ æŠ•ç ”ç»“è®ºå¡")
        c_dec1, c_dec2, c_dec3, c_dec4 = st.columns([1.4, 1, 1, 1])
        verdict = decision_card.get("verdict decision_card.get("verdict", "WATCH")
        horizon = decision_card.get("horizon", "1m")
        dq_score = decision_card.get("data_quality_score", 0)
        position_pct = decision_card.get("position_sizing_pct", 0)
        c_dec1.metric("ç»“è®º", verdict)
        c_dec2.metric("æŒæœ‰å‘¨æœŸ", horizon)
        c_dec3.metric("æ•°æ®è´¨é‡", f"{dq_score}/100")
        c_dec4.metric("å»ºè®®ä»“ä½", f"{position_pct}%")

        def _render_bullets(label: str, items):
            st.markdown(f"**{label}**")
            items = items or []
            if not items:
                st.caption("insufficient evidence")
                return
            for it in items:
                st.markdown(f"- {it}")

        _render_bullets("æ ¸å¿ƒè®ºæ®", decision_card.get("thesis", []))
        _render_bullets("å…³é”®é£é™©", decision_card.get("risks", []))
        _render_bullets("è§¦å‘æ¡ä»¶", decision_card.get("triggers", []))
        _render_bullets("åè¯æ¸…å•", decision_card.get("disconfirming_checklist", []))

        with st.expander("æ•°æ®è´¨é‡ä¸ç¼ºå£"):
            missing_notes = decision_card.get("missing_notes", []) or ["æ— "]
            for note in missing_notes:
                st.markdown(f"- {note}")
            ev_map = decision_card.get("evidence_map") or {}
            if ev_map:
                st.caption("è¯æ®ç´¢å¼•")
                for key, val in ev_map.items():
                    st.text(f"{key}: {_as_dict(val).get('summary')}")

        # å†³ç­–é«˜äº®
        decision = rep.get('decision', 'è§‚æœ›')
        color_cls = "decision-buy" if "ä¹°" in decision or "æ½œä¼" in decision else "decision-sell" if "å–" in decision or "æ¸…" in decision else ""
        c_h3.markdown(f"**å†³ç­–: <span class='{color_cls}'>{decision}</span>**", unsafe_allow_html=True)
        mc_val = md.get('market_cap')
        mc_display = _fmt_val(mc_val, suffix="äº¿") if mc_val not in (None, "", 0) else "â€”"
        c_h4.metric("å¸‚å€¼", mc_display)

        advice = _as_dict(dp.get("advice"))
        if advice:
            st.info(f"è§„åˆ™å»ºè®®ï¼š{advice.get('action', 'è§‚æœ›')}")
            ev_list = advice.get("evidence") or []
            if isinstance(ev_list, list):
                for ev in ev_list:
                    ev_dict = _as_dict(ev)
                    ref = ev_dict.get("ref") or ""
                    summary = ev_dict.get("summary") or ""
                    url = ev_dict.get("url") or ""
                    prefix = f"[{ref}] " if ref else ""
                    if url:
                        st.markdown(f"- {prefix}[{summary}]({url})")
                    else:
                        st.markdown(f"- {prefix}{summary}")

        with st.expander("ğŸ©º æ•°æ®é“¾è·¯è¯Šæ–­"):
            diag_rows = []
            for key, label, meta in [
                ("quote", "è¡Œæƒ…", quote_meta),
                ("identity", "èº«ä»½", identity_meta),
                ("kline", "Kçº¿", kline_meta),
                ("financial", "è´¢åŠ¡", fin_meta),
                ("money_flow", "èµ„é‡‘", money_meta),
                ("alternative", "æƒ…æŠ¥", alt_meta),
                ("news_bundle", "æƒ…æŠ¥æµ", news_meta),
            ]:
                safe_meta = _as_dict(meta)
                diag_rows.append({
                    "module": label,
                    "source": safe_meta.get("source") or "â€”",
                    "fallback_used": safe_meta.get("fallback_used") or False,
                    "cache_hit": safe_meta.get("cache_hit") or False,
                    "ttl_sec": safe_meta.get("ttl_sec") or "â€”",
                    "retrieved_at": _fmt_ts(safe_meta.get("retrieved_at") or safe_meta.get("ts")),
                    "filled": _filled_from_meta(safe_meta) or "â€”",
                    "errors_count": _errors_count(safe_meta.get("errors")),
                })
            if diag_rows:
                pd = _get_pandas()
                if pd is not None:
                    _safe_dataframe(pd.DataFrame(diag_rows), use_container_width=True)
                else:
                    st.table(diag_rows)
            for label, meta in [
                ("è¡Œæƒ…", quote_meta),
                ("èº«ä»½", identity_meta),
                ("Kçº¿", kline_meta),
                ("è´¢åŠ¡", fin_meta),
                ("èµ„é‡‘", money_meta),
                ("æƒ…æŠ¥", alt_meta),
                ("æƒ…æŠ¥æµ", news_meta),
            ]:
                meta = _as_dict(meta)
                if meta.get("errors"):
                    st.markdown(f"**{label}é”™è¯¯è¯¦æƒ…:**")
                    _render_errors(meta.get("errors"))

        with st.expander("ğŸ è°ƒè¯•/åŸå§‹æ•°æ®", expanded=False):
            st.caption("single_stock payload (normalized)")
            try:
                st.json({k: v for k, v in dp.items() if k != "provider_trace"})
            except Exception as e:
                st.write(f"JSON æ¸²æŸ“å¤±è´¥: {e}")
                st.write(str(dp))
            st.caption("provider_trace")
            try:
                st.json(dp.get("provider_trace"))
            except Exception as e:
                st.write(f"provider_trace æ¸²æŸ“å¤±è´¥: {e}")

        # 2. åˆ†é¡µå±•ç¤º (Tabs)
        tab_dash, tab_kline, tab_logic, tab_fund = st.tabs(["ğŸ“Š æˆ˜æœ¯çœ‹æ¿", "ğŸ“ˆ Kçº¿å›¾è¡¨", "ğŸ§  é€»è¾‘æ‹†è§£", "ğŸ’° è´¢åŠ¡/èµ„é‡‘"])

        # --- Tab 1: æˆ˜æœ¯çœ‹æ¿ (Dashboard) ---
        with tab_dash:
            st.markdown("#### è¡Œæƒ…/èº«ä»½æ¦‚è§ˆ")
            col_q, col_id = st.columns(2)
            with col_q:
                price = md.get('close') or md.get('price')
                pct = md.get('pct') or md.get('pct_chg')
                if price is None:
                    derived_px, derived_dt = _extract_latest_close(dp.get('kline_daily') or dp.get('kline'))
                    price = derived_px
                    if derived_px is not None:
                        st.caption(f"(éå®æ—¶ï¼šä½¿ç”¨æœ€è¿‘æ”¶ç›˜ä»· {derived_dt or 'æœªçŸ¥'})")
                st.metric("ç°ä»·", _fmt_val(price), f"{pct}%" if pct is not None else None)
                st.write(f"æˆäº¤é¢: {_fmt_val(md.get('amount'))} | é‡æ¯”: {_fmt_val(md.get('vol_ratio'))}")
                st.caption(
                    f"è¡Œæƒ…æ¥æº: {quote_meta.get('source') or '-'} | æŠ¥ä»·: {'éå®æ—¶(æ”¶ç›˜ä»·)' if quote_meta.get('latest_price_non_realtime') else 'å®æ—¶'} | æ¨å¯¼: {'æ˜¯' if quote_meta.get('is_derived') else 'å¦'}"
                )
                _render_meta(quote_meta)
                if not quote_meta.get("ok"):
                    _render_errors(quote_meta.get("errors"))
            with col_id:
                st.write(f"è¡Œä¸š: {sector or '-'}")
                concepts = _as_dict(dp.get('identity')).get('concepts') or []
                st.write("æ¦‚å¿µ: " + ("ï¼Œ".join(concepts) if concepts else "-"))
                _render_meta(identity_meta)
                if not identity_meta.get("ok"):
                    _render_errors(identity_meta.get("errors"))

            st.markdown("---")
            # 1. æ ¸å¿ƒç»“è®º (The Setup)
            setup_logic = rep.get('setup_logic', 'æš‚æ— é€»è¾‘')
            st.markdown(f"<div class='logic-box'><b>âš¡ çŸ­çº¿é€»è¾‘ (The Setup)</b><br>{setup_logic}</div>", unsafe_allow_html=True)
            
            c_d1, c_d2 = st.columns([1, 1])
            with c_d1:
                st.markdown("#### å› å­é›·è¾¾è¯„åˆ†")
                plot_radar(rep.get('scores', {}))
                
                # é£é™©æç¤º
                risk_warning = rep.get('risk_warning', 'æš‚æ— é£é™©æç¤º')
                st.warning(f"ğŸ›¡ï¸ **é£é™©è§†è§’**: {risk_warning}")
                catalyst = rep.get('catalyst', 'æš‚æ— å‚¬åŒ–å‰‚')
                st.success(f"ğŸ”¥ **å¼ºå‚¬åŒ–å‰‚**: {catalyst}")

            with c_d2:
                # è¡ŒåŠ¨è®¡åˆ’
                plan = _as_dict(rep.get('action_plan', {}))
                st.markdown("#### ğŸ”« æˆ˜æœ¯è¡ŒåŠ¨è®¡åˆ’
