# -*- coding: utf-8 -*-
"""
alternative_data.py
===================
äº”ç»´è¶…è„‘Â·å¦ç±»æƒ…æŠ¥å±€ (Commercial Pro V9.1 Fix - ä¿®å¤è¡Œä¸šæ¥å£)

ã€ä¿®å¤æ—¥å¿—ã€‘
1. **ä¿®å¤ TypeError**: get_alternative_report ç°åœ¨æ­£ç¡®æ¥æ”¶ 'sector' å‚æ•°ã€‚
2. **åŠŸèƒ½ä¿æŒ**: å®Œæ•´ä¿ç•™ V9.0 çš„ä¸‰çº§æƒ…æŠ¥ç€‘å¸ƒï¼ˆä¸ªè‚¡-è¡Œä¸š-å®è§‚ï¼‰ã€‚
"""

import os
import re
import time
import requests
import datetime as _dt
from typing import Dict, Any, List, Tuple

from logging_utils import make_result, build_error, FetchResult
from universe_cache import UniverseCache
from data_sources.sentiment_eastmoney import (
    fetch_guba_api,
    fetch_guba_html,
    fetch_xueqiu_search,
    sample_sentiment,
)
from data_sources.announcement_eastmoney import fetch_announcements_em, fetch_announcements_tencent, sample_announcements
from data_sources.report_eastmoney import fetch_research_reports_em, fetch_research_reports_alt, sample_reports
from data_sources.hot_eastmoney import fetch_hot_topics_em, fetch_hot_topics_ak, sample_hot_topics

try:
    import akshare as ak
except ImportError:
    ak = None

try:
    import jieba
    import jieba.analyse
except ImportError:
    jieba = None

# ==========================================
# 1. è¯­ä¹‰ä¸å…³é”®è¯åº“
# ==========================================
SENTIMENT_DICT = {
    "pos": {
        "ç‰›", "æ¶¨åœ", "åˆ©å¥½", "çªç ´", "ä½ä¼°", "ä¹°å…¥", "åŠ ä»“", "èµ·é£", "é¾™å¤´", 
        "å¤§è‚‰", "æœºæ„", "ä¸»åŠ›", "çˆ†å‘", "ç¿»å€", "è¶…é¢„æœŸ", "æ»¡ä»“", "åƒè‚‰", 
        "é¥é¥é¢†å…ˆ", "æ ¼å±€", "èµ·çˆ†", "ä¸»å‡æµª", "çº¢ç›˜", "å¤§æ¶¨", "ç¨³äº†", "ç‰›å¸‚",
        "å¢æŒ", "å›è´­", "æ³¨èµ„", "ä¸¾ç‰Œ", "å›½å®¶é˜Ÿ", "ç¤¾ä¿", "å…»è€é‡‘"
    },
    "neg": {
        "è·Œåœ", "åˆ©ç©º", "å‡ºè´§", "åƒåœ¾", "å¥—ç‰¢", "å‰²è‚‰", "è·‘è·¯", "å´©ç›˜", "æš´é›·", 
        "é€€å¸‚", "ç«‹æ¡ˆ", "å‡æŒ", "è¯±å¤š", "éª—å­", "ç”šè‡³", "å¤§è·Œ", "æ ¸æŒ‰é’®",
        "å®Œè›‹", "è¢«å¥—", "å›æ’¤", "è·³æ°´", "ç»¿ç›˜", "å¤§è·Œ", "å‡‰äº†", "ç†Šå¸‚", "é—®è¯¢"
    }
}

# èµ„æœ¬è¿ä½œ (L1)
CAPITAL_KEYWORDS = ["å¢æŒ", "å›è´­", "æ³¨èµ„", "é‡ç»„", "ä¸¾ç‰Œ", "åˆ†çº¢", "è‚¡æƒè½¬è®©", "ä¸»åŠ›", "å¤§å®—äº¤æ˜“", "ç¤¾ä¿", "å¤§åŸºé‡‘"]

# å®è§‚æ”¿ç­– (L3)
POLICY_KEYWORDS = ["ä¸­å¤®", "å›½åŠ¡é™¢", "å¤®è¡Œ", "å‘æ”¹å§”", "è´¢æ”¿éƒ¨", "è¯ç›‘ä¼š", "ä¸“é¡¹å€º", "äº”å¹´è§„åˆ’", "æ–°è´¨ç”Ÿäº§åŠ›", "è‡ªä¸»å¯æ§", "é™å‡†", "é™æ¯", "ä¼šè®®", "ä½ç©ºç»æµ", "äººå·¥æ™ºèƒ½"]

TRASH_WORDS = {
    "ä¸¾æŠ¥", "ç½‘è­¦", "å¾ä¿¡", "å¤‡æ¡ˆ", "è”ç³»æˆ‘ä»¬", "å…³äºæˆ‘ä»¬", "å…è´£å£°æ˜", 
    "éšç§æ”¿ç­–", "é£é™©æç¤º", "å¹¿å‘ŠæœåŠ¡", "åœ°å›¾", "é€šè¡Œè¯", "å¸®åŠ©ä¸­å¿ƒ",
    "è¿æ³•", "ä¸è‰¯ä¿¡æ¯", "å‹æƒ…é“¾æ¥", "åè¯ˆ", "è­¦æ–¹", "å¸‚æ°‘", "åŠé˜»", "é˜²èŒƒ"
}

def _safe_banner(msg: str) -> None:
    try:
        print(msg)
    except UnicodeEncodeError:
        # Windows é»˜è®¤æ§åˆ¶å°ä¸º gbkï¼Œç›´æ¥æ‰“å° emoji ä¼šæŠ›å¼‚å¸¸ï¼Œå¿½ç•¥ä¸å¯ç¼–ç å­—ç¬¦åè¾“å‡º
        print(msg.encode("utf-8", "ignore").decode("utf-8", "ignore"))


class AlternativeDataEngine:
    def __init__(self, cache: UniverseCache | None = None):
        _safe_banner("ğŸ•µï¸ [æƒ…æŠ¥å±€ V9.1] å¯åŠ¨ (å¤©ç½‘æƒ…æŠ¥ç³»ç»Ÿå·²ä¿®å¤)...")
        self.macro_cache = {}
        self.cache = cache or UniverseCache()
        self.sentiment_ttl = 60 * 30
        flag = os.environ.get("ALLOW_OFFLINE_SAMPLES", "").lower()
        self.allow_offline_samples = flag in {"1", "true", "yes", "on"}

    @staticmethod
    def _news_item(
        title: str,
        url: str,
        source: str,
        time_str: str = "",
        summary: str = "",
        raw_excerpt: str | None = None,
    ) -> Dict[str, Any]:
        return {
            "title": title or "",
            "url": url or "",
            "source": source or "",
            "time": time_str or "",
            "summary": summary or (title[:120] if title else ""),
            "raw_excerpt": raw_excerpt or "",
        }

    @staticmethod
    def _news_item(
        title: str,
        url: str,
        source: str,
        time_str: str = "",
        summary: str = "",
        raw_excerpt: str | None = None,
    ) -> Dict[str, Any]:
        return {
            "title": title or "",
            "url": url or "",
            "source": source or "",
            "time": time_str or "",
            "summary": summary or (title[:120] if title else ""),
            "raw_excerpt": raw_excerpt or "",
        }

    def _calculate_sentiment(self, text: str) -> float:
        if not text or not jieba: return 0.0
        words = list(jieba.cut(text))
        score = 0
        for w in words:
            if w in SENTIMENT_DICT["pos"]: score += 1
            elif w in SENTIMENT_DICT["neg"]: score -= 1.5 
        
        normalized_score = score / (len(words) * 0.1 + 1) 
        return max(min(normalized_score, 1.0), -1.0)

    # ------------------------------------------------------------------
    # A. èˆ†æƒ…ç›‘å¬ (Guba)
    # ------------------------------------------------------------------
    def fetch_guba_sentiment(self, symbol: str, limit: int = 20) -> FetchResult:
        """è‚¡å§èˆ†æƒ…ï¼šå¤šæºå…œåº• + ç¼“å­˜ï¼Œé¿å…é˜»å¡ã€‚"""
        cache_key = self.cache.key("sentiment", {"symbol": symbol, "limit": limit})
        cached = self.cache.get(cache_key, ttl=self.sentiment_ttl)
        if cached is not None:
            return make_result(cached, source=str(cached.get("source", "cache")), cache_hit=True)

        providers = [
            ("eastmoney_api", lambda: fetch_guba_api(symbol, limit=limit, timeout=10)),
            ("eastmoney_html", lambda: fetch_guba_html(symbol, limit=limit, timeout=8)),
            ("xueqiu", lambda: fetch_xueqiu_search(symbol, limit=limit, timeout=8)),
        ]

        errors: List[Dict[str, str]] = []
        chosen: Dict[str, Any] | None = None
        source = ""

        for name, fn in providers:
            try:
                data = fn()
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            if data and data.get("sample_posts"):
                chosen = data
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} æ— æœ‰æ•ˆå¸–å­"))

        if not chosen:
            if self.allow_offline_samples:
                chosen = sample_sentiment(symbol)
                source = "sample_cache"
                errors.append(build_error("sample_cache", "fallback", "å¯ç”¨ç¦»çº¿èˆ†æƒ…æ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
            else:
                chosen = {"sample_posts": []}
                source = "empty"
                errors.append(build_error("sample_cache", "disabled", "æœªå‹¾é€‰ç¦»çº¿æ ·æœ¬æ¨¡å¼ï¼Œæœªè¿”å›å ä½æ•°æ®"))

        self.cache.set(cache_key, chosen)
        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)

    def _crawl_guba_html(self, symbol: str) -> Dict[str, Any]:
        url = f"http://guba.eastmoney.com/list,{symbol}.html"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Referer": "http://guba.eastmoney.com/"
        }
        
        try:
            resp = requests.get(url, headers=headers, timeout=4)
            if resp.status_code != 200: return {"score": 0, "hot_words": [], "source": "crawl_403"}
            html = resp.text
        except:
            return {"score": 0, "hot_words": [], "source": "timeout"}

        raw_titles = re.findall(r'href="/news,[\d,]+\.html"[^>]*title="([^"]+)"', html)
        if not raw_titles:
             raw_titles = re.findall(r'class="note"[^>]*>([^<]+)</a>', html)

        valid_titles = []
        for t in raw_titles:
            if any(trash in t for trash in TRASH_WORDS): continue
            if len(t) < 4: continue
            valid_titles.append(t)
        
        clean_titles = list(set(valid_titles))[:25]
        full_text = " ".join(clean_titles)
        
        hot_words = []
        if jieba:
            try: hot_words = jieba.analyse.extract_tags(full_text, topK=5)
            except: pass

        sentiment_score = self._calculate_sentiment(full_text)
        
        return {
            "score": round(sentiment_score, 2),
            "hot_words": hot_words,
            "sample_text": full_text[:80] + "...",
            "source": "direct_crawler"
        }

    # ------------------------------------------------------------------
    # B. æ™ºèƒ½æ–°é—»æŠ“å– (Smart News Waterfall)
    # ------------------------------------------------------------------
    def fetch_smart_news(self, symbol: str, sector: str = "") -> FetchResult:
        """
        ä¸‰çº§æƒ…æŠ¥æŠ“å–ã€‚
        ã€ä¿®å¤ç‚¹ã€‘: å¢åŠ äº† sector å‚æ•°ï¼Œé˜²æ­¢è°ƒç”¨æŠ¥é”™ã€‚
        """
        report = {
            "corporate": [],
            "macro": []
        }
        errors: List[Dict[str, str]] = []
        if ak is None:
            errors.append(build_error("akshare", "missing", "AkShare æœªå®‰è£…"))
            return make_result(report, source="akshare", errors=errors)

        # 1. ç¬¬ä¸€çº§ï¼šä¸ªè‚¡æ–°é—»
        try:
            df = ak.stock_news_em(symbol=symbol)
            if df is not None and not df.empty:
                for _, row in df.head(5).iterrows():
                    title = str(row.get('æ–°é—»æ ‡é¢˜', ''))
                    date = str(row.get('å‘å¸ƒæ—¶é—´', ''))
                    tag = "èµ„è®¯"
                    for kw in CAPITAL_KEYWORDS:
                        if kw in title:
                            tag = "ğŸ”¥èµ„æœ¬è¿ä½œ"
                            break
                    report["corporate"].append({"title": title, "date": date, "tag": tag})
            else:
                errors.append(build_error("akshare", "empty", "å…¬å¸æ–°é—»ä¸ºç©º"))
        except Exception as e:
            errors.append(build_error("akshare", "exception", str(e)))

        # 2. ç¬¬äºŒçº§ï¼šå®è§‚/æ”¿ç­–æ–°é—» (å¿…æŠ“)
        try:
            df_macro = ak.stock_info_global_fianace_news(area="ä¸­å›½")
            if df_macro is not None and not df_macro.empty:
                count = 0
                for _, row in df_macro.iterrows():
                    title = str(row.get('title', ''))
                    pub_time = str(row.get('public_time', ''))
                    if any(kw in title for kw in POLICY_KEYWORDS):
                        report["macro"].append({"title": title, "date": pub_time, "tag": "ğŸ›ï¸å®è§‚æ”¿ç­–"})
                        count += 1
                    if count >= 3: break
            else:
                errors.append(build_error("akshare", "empty", "å®è§‚æ–°é—»ä¸ºç©º"))
        except Exception as e:
            errors.append(build_error("akshare", "exception", str(e)))

        return make_result(report, source="akshare", errors=errors, fallback_used=bool(errors))

    # ------------------------------------------------------------------
    # C. çœŸå®å®è§‚æ•°æ®æŒ‡æ ‡
    # ------------------------------------------------------------------
    def fetch_macro_indexes(self) -> Dict[str, float]:
        if self.macro_cache and (time.time() - self.macro_cache.get('_ts', 0) < 3600*4):
            return self.macro_cache

        print("ğŸŒ [æƒ…æŠ¥å±€] æ­£åœ¨åŒæ­¥å›½å®¶ç»Ÿè®¡å±€æ•°æ®...")
        macro_data = {"cpi_yoy": 0.5, "m2_yoy": 8.0, "cn_10y_bond": 2.3, "market_sentiment": "ä¸­æ€§", "_ts": time.time()}
        
        if ak is None: return macro_data

        try:
            try:
                df_cpi = ak.macro_china_cpi_monthly()
                if not df_cpi.empty:
                    latest = df_cpi.iloc[-1]
                    val = latest.get('cpi') or latest.get('å…¨å›½-åŒæ¯”å¢é•¿', 0)
                    macro_data["cpi_yoy"] = float(val)
            except: pass

            try:
                df_m2 = ak.macro_china_m2_yearly()
                if not df_m2.empty:
                    latest = df_m2.iloc[-1]
                    val = latest.get('m2') or latest.get('åŒæ¯”å¢é•¿', 8.0)
                    macro_data["m2_yoy"] = float(val)
            except: pass

            try:
                df_bond = ak.bond_zh_us_rate()
                if not df_bond.empty:
                    latest = df_bond.iloc[-1]
                    val = latest.get('ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´', 2.3)
                    macro_data["cn_10y_bond"] = float(val)
            except: pass

            cpi = macro_data["cpi_yoy"]
            m2 = macro_data["m2_yoy"]
            if cpi < 0: sent = "é€šç¼©å‹åŠ›(é˜²å¾¡)"
            elif cpi > 3: sent = "é€šèƒ€è¿‡çƒ­(ç´§ç¼©)"
            elif m2 > 10: sent = "æµåŠ¨æ€§å……è£•(åˆ©å¥½)"
            elif m2 < 7: sent = "æµåŠ¨æ€§æ”¶ç´§(åˆ©ç©º)"
            else: sent = "æ¸©å’Œå¤è‹(ä¸­æ€§)"
            
            macro_data["market_sentiment"] = sent
            self.macro_cache = macro_data

        except: pass
        return macro_data

    # ------------------------------------------------------------------
    # D. å…¬å‘Š / ç ”æŠ¥ / çƒ­ç‚¹è¦äº‹
    # ------------------------------------------------------------------
    def fetch_announcements(self, symbol: str, limit: int = 12) -> FetchResult:
        errors: List[Dict[str, str]] = []
        chosen: List[Dict[str, Any]] = []
        source = ""
        providers = [
            ("eastmoney", lambda: fetch_announcements_em(symbol, limit=limit)),
            ("tencent", lambda: fetch_announcements_tencent(symbol, limit=limit)),
        ]

        for name, fn in providers:
            try:
                data = fn()
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            payload_items = data.get("items", []) if isinstance(data, dict) else data
            errors.extend(data.get("errors", []) if isinstance(data, dict) else [])
            if payload_items:
                chosen = payload_items
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} å…¬å‘Šä¸ºç©º"))

        if not chosen:
            if self.allow_offline_samples:
                errors.append(build_error("sample", "fallback", "å¯ç”¨ç¦»çº¿å…¬å‘Šæ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
                chosen = sample_announcements(symbol, limit=limit)
                source = "sample_cache"
            else:
                errors.append(build_error("sample", "disabled", "æœªå‹¾é€‰ç¦»çº¿æ ·æœ¬æ¨¡å¼ï¼Œå…¬å‘Šæœªä½¿ç”¨å ä½æ•°æ®"))
                chosen = []
                source = "empty"

        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)

    def fetch_research_reports(self, symbol: str, limit: int = 12) -> FetchResult:
        errors: List[Dict[str, str]] = []
        chosen: List[Dict[str, Any]] = []
        source = ""
        providers = [
            ("eastmoney", lambda: fetch_research_reports_em(symbol, limit=limit)),
            ("alt", lambda: fetch_research_reports_alt(symbol, limit=limit)),
        ]

        for name, fn in providers:
            try:
                data = fn()
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            payload_items = data.get("items", []) if isinstance(data, dict) else data
            errors.extend(data.get("errors", []) if isinstance(data, dict) else [])
            if payload_items:
                chosen = payload_items
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} ç ”æŠ¥ä¸ºç©º"))

        if not chosen:
            if self.allow_offline_samples:
                errors.append(build_error("sample", "fallback", "å¯ç”¨ç¦»çº¿ç ”æŠ¥æ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
                chosen = sample_reports(symbol, limit=limit)
                source = "sample_cache"
            else:
                errors.append(build_error("sample", "disabled", "æœªå‹¾é€‰ç¦»çº¿æ ·æœ¬æ¨¡å¼ï¼Œç ”æŠ¥æœªä½¿ç”¨å ä½æ•°æ®"))
                chosen = []
                source = "empty"

        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)

    def fetch_hot_topics(self, limit: int = 8) -> FetchResult:
        errors: List[Dict[str, str]] = []
        chosen: List[Dict[str, Any]] = []
        source = ""
        providers = [
            ("eastmoney", lambda: fetch_hot_topics_em(limit=limit)),
            ("akshare", lambda: fetch_hot_topics_ak(limit=limit)),
        ]

        for name, fn in providers:
            try:
                data = fn()
            except Exception as e:  # noqa: BLE001
                errors.append(build_error(name, "exception", str(e)))
                continue
            payload_items = data.get("items", []) if isinstance(data, dict) else data
            errors.extend(data.get("errors", []) if isinstance(data, dict) else [])
            if payload_items:
                chosen = payload_items
                source = name
                break
            errors.append(build_error(name, "empty", f"{name} çƒ­ç‚¹ä¸ºç©º"))

        if not chosen:
            if self.allow_offline_samples:
                errors.append(build_error("sample", "fallback", "å¯ç”¨ç¦»çº¿çƒ­ç‚¹æ ·æœ¬ï¼Œæ•°æ®å¯èƒ½è¿‡æœŸ"))
                chosen = sample_hot_topics(limit=limit)
                source = "sample_cache"
            else:
                errors.append(build_error("sample", "disabled", "æœªå‹¾é€‰ç¦»çº¿æ ·æœ¬æ¨¡å¼ï¼Œçƒ­ç‚¹æœªä½¿ç”¨å ä½æ•°æ®"))
                chosen = []
                source = "empty"

        return make_result(chosen, source=source, errors=errors, fallback_used=len(errors) > 0)

    # ------------------------------------------------------------------
    # æ–°é—»æµèšåˆï¼ˆå…¬å‘Š / ç ”æŠ¥ / çƒ­ç‚¹ / è®ºå› / è§‚ç‚¹ï¼‰
    # ------------------------------------------------------------------
    def get_news_bundle_structured(self, symbol: str, sector: str = "") -> FetchResult:
        errors: List[Dict[str, str]] = []
        bundle = {
            "announcements": [],
            "reports": [],
            "hot_events": [],
            "forums": [],
            "opinions": [],
        }

        def _append_if_valid(category: str, item: Dict[str, Any]):
            url = item.get("url")
            t = item.get("time") or item.get("date")
            if not url or not t:
                errors.append(build_error(category, "invalid", f"{category} ç¼ºå°‘ url/time è¢«è¿‡æ»¤"))
                return
            bundle[category].append(item)

        ann = self.fetch_announcements(symbol)
        rep = self.fetch_research_reports(symbol)
        hot = self.fetch_hot_topics(limit=8)
        senti = self.fetch_guba_sentiment(symbol, limit=12)
        smart_news = self.fetch_smart_news(symbol, sector)

        for src in [ann, rep, hot, senti, smart_news]:
            if not src.ok:
                errors.extend(src.errors)

        # å…¬å‘Š
        for item in (ann.data or []):
            _append_if_valid(
                "announcements",
                self._news_item(
                    title=item.get("title", ""),
                    url=item.get("url", ""),
                    source=f"announcement_{ann.source or 'unknown'}",
                    time_str=str(item.get("date") or item.get("time") or ""),
                    summary=item.get("type") or item.get("title", ""),
                ),
            )

        # ç ”æŠ¥
        for item in (rep.data or []):
            _append_if_valid(
                "reports",
                self._news_item(
                    title=item.get("title", ""),
                    url=item.get("url", ""),
                    source=f"report_{rep.source or 'unknown'}",
                    time_str=str(item.get("date") or ""),
                    summary=f"{item.get('org','')} {item.get('rating','')}".strip(),
                ),
            )

        # çƒ­ç‚¹/è¦äº‹
        for item in (hot.data or []):
            _append_if_valid(
                "hot_events",
                self._news_item(
                    title=item.get("title", ""),
                    url=item.get("url", ""),
                    source=f"hot_{hot.source or 'unknown'}",
                    time_str=str(item.get("time") or item.get("date") or ""),
                    summary=item.get("reason") or item.get("desc") or item.get("title", ""),
                ),
            )

        # è®ºå›å¸–å­
        senti_posts = []
        if isinstance(senti.data, dict):
            senti_posts = senti.data.get("sample_posts") or []
        for item in senti_posts:
            _append_if_valid(
                "forums",
                self._news_item(
                    title=item.get("summary", ""),
                    url=item.get("url", ""),
                    source=item.get("source", senti.source or "forum"),
                    time_str=str(item.get("time") or ""),
                    summary=item.get("summary", "")[:140],
                    raw_excerpt=item.get("summary", ""),
                ),
            )

        # èˆ†æƒ…è§‚ç‚¹/å…¬å¸æ–°é—»
        smart_data = smart_news.data if isinstance(smart_news.data, dict) else {}
        for item in smart_data.get("corporate", []) + smart_data.get("macro", []):
            _append_if_valid(
                "opinions",
                self._news_item(
                    title=item.get("title", ""),
                    url=item.get("url", ""),
                    source=f"smart_news_{smart_news.source or 'unknown'}",
                    time_str=str(item.get("date") or item.get("time") or ""),
                    summary=item.get("tag") or item.get("title", ""),
                ),
            )

        # ç»Ÿè®¡ meta
        filled_metrics = sum(1 for k, v in bundle.items() if v)
        meta = {
            "source": "alternative_data",
            "fallback_used": len(errors) > 0,
            "errors": errors,
            "retrieved_at": _dt.datetime.now().isoformat(timespec="seconds"),
            "count": {k: len(v) for k, v in bundle.items()},
            "filled_metrics": filled_metrics,
        }

        fallback_used = len(errors) > 0 and filled_metrics < 2
        if filled_metrics < 2:
            errors.append(build_error("news_bundle", "insufficient", "è‡³å°‘éœ€è¦ä¸¤ç±»éç©ºæƒ…æŠ¥"))

        return make_result(bundle, source="news_bundle", errors=errors, fallback_used=fallback_used, meta=meta)

    # ------------------------------------------------------------------
    # ä¸»å…¥å£ (ä¿®å¤ç‚¹ï¼šå¢åŠ  sector å‚æ•°)
    # ------------------------------------------------------------------
    def get_alternative_report(self, symbol: str, sector: str = "") -> Dict[str, Any]:
        return self.get_alternative_report_structured(symbol, sector).data

    def get_alternative_report_structured(self, symbol: str, sector: str = "") -> FetchResult:
        """
        è·å–å¦ç±»æƒ…æŠ¥æŠ¥å‘Šã€‚
        :param symbol: è‚¡ç¥¨ä»£ç 
        :param sector: æ‰€å±è¡Œä¸š (æ–°å¢å‚æ•°ï¼Œç”¨äºè¡Œä¸šè¡¥å…¨)
        """
        errors: List[Dict[str, str]] = []

        guba = self.fetch_guba_sentiment(symbol)
        if not guba.ok:
            errors.extend(guba.errors)

        macro = self.fetch_macro_indexes()
        smart_news = self.fetch_smart_news(symbol, sector)
        if not smart_news.ok:
            errors.extend(smart_news.errors)

        announcements = self.fetch_announcements(symbol)
        if not announcements.ok:
            errors.extend(announcements.errors)

        reports = self.fetch_research_reports(symbol)
        if not reports.ok:
            errors.extend(reports.errors)

        hot_topics = self.fetch_hot_topics(limit=8)
        if not hot_topics.ok:
            errors.extend(hot_topics.errors)

        sentiment_data = guba.data if isinstance(guba.data, dict) else {}
        sentiment_block = {
            "sentiment_score": sentiment_data.get("sentiment_score") or sentiment_data.get("score", 0),
            "hot_words": sentiment_data.get("hot_words", []),
            "sample_posts": sentiment_data.get("sample_posts", []),
            "source": guba.source,
            "fallback_used": guba.fallback_used,
        }

        data = {
            "symbol": symbol,
            "retail_sentiment": sentiment_block["sentiment_score"] or 0,
            "hot_words": sentiment_block.get("hot_words", []),
            "macro_environment": macro,
            "alternative_signal": "ä¸­æ€§",
            "sentiment": sentiment_block,
            "raw_guba_sample": sentiment_data.get("sample_text", ""),
            "corporate_news": smart_news.data.get("corporate", []) if isinstance(smart_news.data, dict) else [],
            "macro_news": smart_news.data.get("macro", []) if isinstance(smart_news.data, dict) else [],
            "data_source": guba.data.get("source", "unknown") if isinstance(sentiment_data, dict) else "unknown",
            "announcements": announcements.data if isinstance(announcements.data, list) else [],
            "research_reports": reports.data if isinstance(reports.data, list) else [],
            "hot_topics": hot_topics.data if isinstance(hot_topics.data, list) else [],
            "ann_source": announcements.source,
            "report_source": reports.source,
            "hot_source": hot_topics.source,
        }

        score_val = data["retail_sentiment"]
        if not sentiment_block.get("sample_posts"):
            errors.append(build_error("sentiment", "empty", "èˆ†æƒ…å¸–å­ä¸ºç©ºï¼ˆå·²å°è¯•å¤šæºï¼‰"))

        if score_val > 0.3:
            data["alternative_signal"] = "æƒ…ç»ªè´ªå©ª"
        elif score_val < -0.3:
            data["alternative_signal"] = "æƒ…ç»ªææ…Œ"

        if not data["corporate_news"]:
            errors.append(build_error("akshare", "empty", "å…¬å¸æ–°é—»ç¼ºå¤±"))

        if not data["announcements"]:
            errors.append(build_error("announcement", "empty", "å…¬å‘Šä¸ºç©ºï¼ˆå·²å°è¯•å¤šæºï¼‰"))
        if not data["research_reports"]:
            errors.append(build_error("research", "empty", "ç ”æŠ¥ä¸ºç©ºï¼ˆå·²å°è¯•å¤šæºï¼‰"))
        if not data["hot_topics"]:
            errors.append(build_error("hot", "empty", "çƒ­ç‚¹ä¸ºç©ºï¼ˆå·²å°è¯•å¤šæºï¼‰"))

        return make_result(data, source="alternative_data", errors=errors, fallback_used=bool(errors))