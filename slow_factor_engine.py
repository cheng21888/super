# -*- coding: utf-8 -*-
"""
slow_factor_engine.py
=====================
æŠŠâ€œæ…¢å˜é‡â€å˜æˆã€å¯è®¡ç®—ã€å¯è®°å½•ã€å¯å›æµ‹ã€‘çš„å› å­ï¼Œå¹¶è¿›å…¥è¯„åˆ†ä½“ç³»ã€‚

è®¾è®¡ç›®æ ‡ï¼ˆV1ï¼‰ï¼š
- Policy å¼ºåº¦/æŒç»­æ€§ï¼ˆåŸºäºå®è§‚æˆ˜ç•¥è¾“å‡º + æ—¥åº¦è®°å½•ï¼‰
- Demand éœ€æ±‚ç©ºé—´ï¼ˆåŸºäºè´¢åŠ¡å¢é•¿ + è¡Œä¸šä¸»çº¿åŠ æˆï¼‰
- Substitution å›½äº§æ›¿ä»£/è‡ªä¸»å¯æ§ï¼ˆåŸºäºè¡Œä¸šæ ‡ç­¾ + ç ”å‘å¼ºåº¦ + å…³é”®è¯è¯æ®ï¼‰
- Pricing å¸‚åœºå®šä»·/é¢„æœŸåæ˜ ï¼ˆåŸºäºä¼°å€¼ç›¸å¯¹åˆ†ä½ + ä»·æ ¼ä½ç½®ï¼‰
- Info ä¿¡æ¯é¢æ˜¯å¦å……åˆ†ï¼ˆåŸºäºçƒ­åº¦/æ‹¥æŒ¤åº¦ï¼šæˆäº¤/æ³¢åŠ¨/çƒ­æ¦œï¼‰

âš ï¸ è¯´æ˜ï¼š
1) â€œå¯å›æµ‹â€= åœ¨ä½ å¼€å§‹æ”¶é›†åï¼Œå› å­ä¼šæŒ‰æ—¥è½ç›˜ï¼ˆFactorStoreï¼‰ï¼Œå›æµ‹æ—¶åªè¯»å– <= æ¨¡æ‹Ÿæ—¥æœŸçš„æ•°æ®ï¼Œé¿å…æœªæ¥å‡½æ•°ã€‚
2) å¦‚æœæŸç±»æ•°æ®ç¼ºå¤±ï¼Œä¼šå›é€€åˆ°ä¸­æ€§ 0.5ï¼Œä¸ä¼šè®©ç³»ç»Ÿå´©æ‰ã€‚
"""
from __future__ import annotations

import json
import math
import time
from dataclasses import dataclass
from datetime import datetime, date
from pathlib import Path
from typing import Any, Dict, List, Optional, Iterable, Tuple

import pandas as pd
import numpy as np

from universe_cache import UniverseCache

# ------------------------------ helpers ------------------------------

def _now_date_str() -> str:
    return datetime.now().strftime("%Y-%m-%d")

def _to_date_str(d: Any) -> str:
    if d is None:
        return _now_date_str()
    if isinstance(d, str):
        # keep yyyy-mm-dd
        return d[:10]
    if isinstance(d, datetime):
        return d.strftime("%Y-%m-%d")
    if isinstance(d, date):
        return d.strftime("%Y-%m-%d")
    try:
        return pd.to_datetime(d).strftime("%Y-%m-%d")
    except Exception:
        return _now_date_str()

def _clip01(x: float) -> float:
    try:
        return float(max(0.0, min(1.0, x)))
    except Exception:
        return 0.5

def _safe_float(x: Any, default: float = 0.0) -> float:
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return float(default)
        return float(x)
    except Exception:
        return float(default)

def _sigmoid(x: float) -> float:
    try:
        return 1.0 / (1.0 + math.exp(-x))
    except Exception:
        return 0.5

def _tanh01(x: float, scale: float = 20.0) -> float:
    # map growth% to [0,1], centered at 0
    try:
        return _clip01(0.5 + 0.5 * math.tanh(float(x) / float(scale)))
    except Exception:
        return 0.5

def _contains_any(text: str, kws: Iterable[str]) -> bool:
    if not text:
        return False
    t = str(text)
    return any(kw in t for kw in kws)

# ------------------------------ constants ------------------------------

POLICY_KEYWORDS = [
    "æ”¿ç­–", "å‘æ”¹å§”", "å›½åŠ¡é™¢", "è´¢æ”¿", "å¤®è¡Œ", "é™å‡†", "é™æ¯", "MLF", "é€†å›è´­",
    "ä¸“é¡¹å€º", "å›½å€º", "è¡¥è´´", "è§„åˆ’", "è¯•ç‚¹", "æŒ‡å¯¼æ„è§", "ä¼šè®®", "ç»æµå·¥ä½œä¼šè®®",
    "æ–°è´¨ç”Ÿäº§åŠ›", "äº§ä¸š", "ç¨³å¢é•¿", "æ‰©å†…éœ€"
]

SUBSTITUTION_KEYWORDS = [
    "å›½äº§æ›¿ä»£", "è¿›å£æ›¿ä»£", "è‡ªä¸»å¯æ§", "å›½äº§åŒ–", "ä¿¡åˆ›", "è‡ªä¸»ç ”å‘", "è‡ªä¸»",
    "å¡è„–å­", "æ›¿ä»£", "å»IOE", "å›½äº§èŠ¯ç‰‡", "å›½äº§æ“ä½œç³»ç»Ÿ"
]

# ç²—ç²’åº¦è¡Œä¸šæ ‡ç­¾ï¼ˆå¯æŒ‰éœ€æ‰©å±•ï¼‰
SECTOR_SUBSTITUTION_BONUS = {
    "åŠå¯¼ä½“": 0.85,
    "ä¿¡åˆ›": 0.85,
    "è½¯ä»¶": 0.75,
    "å†›å·¥": 0.75,
    "é«˜ç«¯è£…å¤‡": 0.70,
    "å·¥ä¸šæ¯æœº": 0.80,
    "æ–°èƒ½æº": 0.65,
    "æ±½è½¦": 0.60,
    "åŒ»è¯": 0.55,
}

# ------------------------------ FactorStore ------------------------------

@dataclass
class FactorStoreConfig:
    filename: str = "slow_factors_store.parquet"
    max_rows: int = 400000  # ç®€å•ä¿æŠ¤ï¼šé¿å…æ— é™è†¨èƒ€

class FactorStore:
    """æ—¥åº¦å› å­è½ç›˜ï¼šç”¨äºåç»­æ— æœªæ¥å‡½æ•°å›æµ‹ã€‚"""
    def __init__(self, cache: UniverseCache, cfg: Optional[FactorStoreConfig] = None):
        self.cache = cache
        self.cfg = cfg or FactorStoreConfig()
        self.dir = Path(self.cache.cache_dir) / "factors"
        self.dir.mkdir(parents=True, exist_ok=True)
        self.path_parquet = self.dir / self.cfg.filename
        self.path_csv = self.dir / self.cfg.filename.replace(".parquet", ".csv")

    def _load(self) -> pd.DataFrame:
        if self.path_parquet.exists():
            try:
                return pd.read_parquet(self.path_parquet)
            except Exception:
                pass
        if self.path_csv.exists():
            try:
                return pd.read_csv(self.path_csv)
            except Exception:
                pass
        return pd.DataFrame()

    def _save(self, df: pd.DataFrame) -> None:
        # è£å‰ª
        if len(df) > self.cfg.max_rows:
            df = df.tail(self.cfg.max_rows).copy()
        # å°è¯• parquet
        try:
            df.to_parquet(self.path_parquet, index=False)
            return
        except Exception:
            pass
        # fallback csv
        try:
            df.to_csv(self.path_csv, index=False, encoding="utf-8-sig")
        except Exception:
            # æœ€åæƒ…å†µï¼šä¸å½±å“ä¸»æµç¨‹
            return

    def append_many(self, records: List[Dict[str, Any]]) -> None:
        if not records:
            return
        try:
            new_df = pd.DataFrame(records)
            if new_df.empty:
                return
            df = self._load()
            df = pd.concat([df, new_df], ignore_index=True)
            # å»é‡ï¼šåŒæ—¥åŒè‚¡ä¿ç•™æœ€åä¸€æ¡
            if "date" in df.columns and "code" in df.columns:
                df = df.sort_values(["date", "code"]).drop_duplicates(["date", "code"], keep="last")
            self._save(df)
        except Exception:
            return

    def query_asof(self, codes: List[str], as_of: Any) -> pd.DataFrame:
        """å– <= as_of çš„æœ€æ–°ä¸€æ¡å› å­å¿«ç…§ï¼ˆæŒ‰ codeï¼‰ã€‚"""
        if not codes:
            return pd.DataFrame()
        as_of_str = _to_date_str(as_of)
        df = self._load()
        if df.empty or "date" not in df.columns or "code" not in df.columns:
            return pd.DataFrame()
        try:
            df["date"] = df["date"].astype(str).str.slice(0, 10)
            sub = df[df["code"].isin(codes) & (df["date"] <= as_of_str)].copy()
            if sub.empty:
                return pd.DataFrame()
            sub = sub.sort_values(["code", "date"])
            last = sub.groupby("code").tail(1)
            return last
        except Exception:
            return pd.DataFrame()

    def sector_policy_persistence(self, sector: str, as_of: Any, lookback_days: int = 30) -> float:
        """å¯¹æŒ‡å®šè¡Œä¸šçš„ policy_strength åšæŒ‡æ•°è¡°å‡å‡å€¼ï¼Œä½œä¸ºæŒç»­æ€§ã€‚"""
        sector = (sector or "").strip()
        if not sector:
            return 0.5
        as_of_str = _to_date_str(as_of)
        df = self._load()
        if df.empty:
            return 0.5
        if not {"date","sector","policy_strength"}.issubset(set(df.columns)):
            return 0.5
        try:
            df["date"] = df["date"].astype(str).str.slice(0,10)
            sub = df[(df["sector"].astype(str) == sector) & (df["date"] <= as_of_str)][["date","policy_strength"]].copy()
            if sub.empty:
                return 0.5
            sub = sub.sort_values("date").tail(lookback_days)
            vals = sub["policy_strength"].astype(float).values
            # æŒ‡æ•°è¡°å‡ï¼šè¶Šè¿‘æƒé‡è¶Šé«˜
            n = len(vals)
            w = np.exp(-np.linspace(n-1, 0, n) / max(1.0, n/6.0))
            w = w / (w.sum() + 1e-9)
            return float(np.dot(vals, w))
        except Exception:
            return 0.5

# ------------------------------ SlowFactorEngine ------------------------------

class SlowFactorEngine:
    def __init__(self, cache: UniverseCache):
        self.cache = cache
        self.store = FactorStore(cache)

    # --------- internal scoring blocks ---------

    def _policy_strength(self, sector: str, macro_report: Optional[Dict[str, Any]], alt_report: Optional[Dict[str, Any]]) -> Tuple[float, List[str]]:
        ev: List[str] = []
        sector = sector or ""
        score = 0.5

        if macro_report:
            primary = macro_report.get("primary_sectors") or []
            conf = _safe_float(macro_report.get("confidence", 0.5), 0.5)
            hit = False
            for s in primary:
                if not s:
                    continue
                if (s in sector) or (sector and sector in str(s)):
                    hit = True
                    ev.append(f"å®è§‚ä¸»çº¿å‘½ä¸­: {s} (conf={conf:.2f})")
                    break
            score = 0.40 + (0.50 * conf if hit else 0.15 * conf)
        else:
            # fallback: ä»æ–°é—»æ ‡é¢˜é‡ŒæŠ“æ”¿ç­–è¯å‘½ä¸­
            titles: List[str] = []
            if alt_report:
                for it in (alt_report.get("macro_news") or []):
                    titles.append(str(it.get("title","")))
                for it in (alt_report.get("corporate_news") or []):
                    titles.append(str(it.get("title","")))
            hits = sum(1 for t in titles if _contains_any(t, POLICY_KEYWORDS))
            if hits > 0:
                ev.append(f"æ”¿ç­–æ–°é—»å‘½ä¸­: {hits} æ¡")
            score = _sigmoid((hits - 1.5) / 1.5)  # hits=0 => ~0.27, hits=3 => ~0.73
            score = 0.35 + 0.65 * score

        return _clip01(score), ev

    def _demand_space(self, fin: Dict[str, Any], sector: str, macro_report: Optional[Dict[str, Any]]) -> Tuple[float, List[str]]:
        ev: List[str] = []
        rev = _safe_float(fin.get("revenue_yoy", 0.0), 0.0)
        prof = _safe_float(fin.get("profit_yoy", 0.0), 0.0)
        # éœ€æ±‚ç©ºé—´ï¼šç”¨æ”¶å…¥/åˆ©æ¶¦å¢é€Ÿçš„â€œæ…¢å˜é‡â€proxy
        base = 0.6 * _tanh01(rev, 25.0) + 0.4 * _tanh01(prof, 30.0)
        ev.append(f"è¥æ”¶YoY={rev:.1f}% åˆ©æ¶¦YoY={prof:.1f}%")

        # è¡Œä¸šä¸»çº¿åŠ æˆ
        if macro_report:
            primary = macro_report.get("primary_sectors") or []
            if any((p in (sector or "")) or ((sector or "") and (sector in str(p))) for p in primary if p):
                base = min(1.0, base + 0.10)
                ev.append("è¡Œä¸šå¤„äºå®è§‚ä¸»çº¿ -> éœ€æ±‚ç©ºé—´+0.10")

        return _clip01(base), ev

    def _substitution(self, sector: str, fin: Dict[str, Any], alt_report: Optional[Dict[str, Any]]) -> Tuple[float, List[str]]:
        ev: List[str] = []
        sector = sector or ""
        # è¡Œä¸šæ ‡ç­¾åŸºç¡€åˆ†
        base = 0.45
        for k, v in SECTOR_SUBSTITUTION_BONUS.items():
            if k in sector:
                base = max(base, float(v))
                ev.append(f"è¡Œä¸šæ ‡ç­¾å‘½ä¸­: {k} -> base={base:.2f}")
                break

        # ç ”å‘å¼ºåº¦ï¼ˆå¦‚å¯è·å¾—ï¼‰
        rd_ratio = _safe_float(fin.get("rd_ratio", 0.0), 0.0)  # %
        if rd_ratio > 0:
            # ç ”å‘è´¹ç”¨ç‡ 0~20% æ˜ å°„ 0.45~0.85
            rd_score = _clip01(0.45 + 0.02 * min(20.0, rd_ratio))
            base = 0.6 * base + 0.4 * rd_score
            ev.append(f"ç ”å‘è´¹ç”¨ç‡={rd_ratio:.2f}% -> rd_score={rd_score:.2f}")

        # æ–°é—»å…³é”®è¯è¯æ®
        titles: List[str] = []
        if alt_report:
            for it in (alt_report.get("corporate_news") or []):
                titles.append(str(it.get("title","")))
        hits = sum(1 for t in titles if _contains_any(t, SUBSTITUTION_KEYWORDS))
        if hits > 0:
            bump = min(0.12, 0.05 * hits)
            base = min(1.0, base + bump)
            ev.append(f"å›½äº§æ›¿ä»£å…³é”®è¯å‘½ä¸­: {hits} æ¡ -> +{bump:.2f}")

        return _clip01(base), ev

    def _market_pricing(self, spot: Dict[str, Any], kline_260: Optional[pd.DataFrame], sector_pe_median: Optional[float]) -> Tuple[float, List[str]]:
        ev: List[str] = []
        pe = _safe_float(spot.get("pe", 0.0), 0.0)
        # ä¼°å€¼ç›¸å¯¹ï¼ˆä½ä¼°æ›´å¥½ï¼‰
        val_score = 0.5
        if pe > 0 and sector_pe_median and sector_pe_median > 0:
            rel = pe / sector_pe_median
            # rel<1 ä½ä¼° -> é«˜åˆ†
            val_score = _clip01(1.0 - 0.5 * math.tanh((rel - 1.0) / 0.6))
            ev.append(f"PE={pe:.1f} è¡Œä¸šä¸­ä½PE={sector_pe_median:.1f} rel={rel:.2f}")
        elif pe > 0:
            # æ²¡è¡Œä¸šå‚ç…§ï¼šç”¨é˜ˆå€¼
            val_score = _clip01(1.0 - 0.03 * min(30.0, max(0.0, pe - 10.0)))
            ev.append(f"PE={pe:.1f} (æ— è¡Œä¸šå‚ç…§)")
        else:
            ev.append("PEç¼ºå¤± -> ä¸­æ€§")

        # ä»·æ ¼ä½ç½®ï¼šè¶Šé è¿‘åŒºé—´åº•éƒ¨è¶Šæœ‰èµ”ç‡ï¼ˆè¿‡é«˜=é¢„æœŸå·²æ»¡ï¼‰
        pos_score = 0.5
        if isinstance(kline_260, pd.DataFrame) and not kline_260.empty and "close" in kline_260.columns:
            closes = kline_260["close"].astype(float).values
            lo, hi = float(np.nanmin(closes)), float(np.nanmax(closes))
            last = float(closes[-1])
            if hi > lo:
                pos = (last - lo) / (hi - lo + 1e-9)
                # pos è¶Šä½è¶Šå¥½ï¼špos_score=1-pos
                pos_score = _clip01(1.0 - pos)
                ev.append(f"ä»·æ ¼ä½ç½®pos={pos:.2f} (0ä½ä½-1é«˜ä½)")
        else:
            ev.append("ä»·æ ¼åŒºé—´ç¼ºå¤± -> ä¸­æ€§")

        score = 0.55 * val_score + 0.45 * pos_score
        return _clip01(score), ev

    def _info_priced_in(self, row: Dict[str, Any], hotlist: Optional[List[str]] = None, ranks: Optional[Dict[str, float]] = None) -> Tuple[float, List[str]]:
        """
        è¿”å›â€œä¿¡æ¯æ˜¯å¦å……åˆ†/é¢„æœŸæ˜¯å¦æ‹¥æŒ¤â€çš„ç¨‹åº¦ï¼ˆ0=ä¿¡æ¯ä¸å……åˆ†/æœªæ‹¥æŒ¤ï¼Œ1=é«˜åº¦æ‹¥æŒ¤/å¯èƒ½å·²price-inï¼‰
        """
        ev: List[str] = []
        code = str(row.get("code",""))
        hotlist = hotlist or []
        # rank-basedï¼ˆæ‰¹é‡è®¡ç®—æ›´å‡†ï¼‰
        if ranks and code in ranks:
            priced = _clip01(ranks[code])
            if code in hotlist:
                priced = min(1.0, priced + 0.08)
                ev.append("çƒ­æ¦œå‘½ä¸­ -> æ‹¥æŒ¤åº¦+0.08")
            return priced, ev

        # å•è‚¡fallbackï¼šç”¨é˜ˆå€¼
        vol_ratio = _safe_float(row.get("vol_ratio", 0.0), 0.0)
        pct = abs(_safe_float(row.get("pct", 0.0), 0.0))
        priced = 0.40
        if vol_ratio >= 2.0: priced += 0.20; ev.append(f"é‡æ¯”é«˜({vol_ratio:.2f})")
        if pct >= 6.0: priced += 0.15; ev.append(f"æ¶¨è·Œå¹…æ³¢åŠ¨å¤§(|{pct:.1f}%|)")
        if code in hotlist: priced += 0.10; ev.append("çƒ­æ¦œå‘½ä¸­")
        return _clip01(priced), ev

    # --------- public APIs ---------

    def compute_single(
        self,
        code: str,
        sector: str,
        spot: Dict[str, Any],
        fin: Dict[str, Any],
        kline_260: Optional[pd.DataFrame] = None,
        macro_report: Optional[Dict[str, Any]] = None,
        alt_report: Optional[Dict[str, Any]] = None,
        as_of: Any = None,
        sector_pe_median: Optional[float] = None,
        hotlist: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        as_of_str = _to_date_str(as_of)
        evidence: Dict[str, List[str]] = {}

        pol, ev1 = self._policy_strength(sector, macro_report, alt_report)
        evidence["policy"] = ev1

        # persistence ç”¨ store çš„è¡Œä¸šæ—¶é—´åºåˆ—
        pers = self.store.sector_policy_persistence(sector, as_of_str)
        if pers != 0.5:
            evidence.setdefault("policy", []).append(f"æ”¿ç­–æŒç»­æ€§(æŒ‡æ•°è¡°å‡)={pers:.2f}")

        dem, ev2 = self._demand_space(fin, sector, macro_report)
        evidence["demand"] = ev2

        sub, ev3 = self._substitution(sector, fin, alt_report)
        evidence["substitution"] = ev3

        pricing, ev4 = self._market_pricing(spot, kline_260, sector_pe_median)
        evidence["pricing"] = ev4

        info, ev5 = self._info_priced_in({**spot, "code": code}, hotlist=hotlist)
        evidence["info"] = ev5

        # compositeï¼ˆæ…¢å˜é‡æ€»åˆ†ï¼Œé«˜=æ›´é€‚åˆâ€œç°åœ¨å»ºä»“â€ï¼‰
        # info æ˜¯â€œæ‹¥æŒ¤åº¦â€ï¼Œéœ€è¦åå‘
        slow_score = (
            0.25 * pol +
            0.15 * pers +
            0.20 * dem +
            0.15 * sub +
            0.15 * pricing +
            0.10 * (1.0 - info)
        )
        slow_score = _clip01(slow_score)

        return {
            "version": "slow_factors_v1",
            "as_of": as_of_str,
            "policy_strength": float(pol),
            "policy_persistence": float(pers),
            "demand_space": float(dem),
            "domestic_substitution": float(sub),
            "market_pricing": float(pricing),
            "info_priced_in": float(info),
            "slow_score": float(slow_score),
            "evidence": evidence,
        }

    def enrich_market_df(
        self,
        market_df: pd.DataFrame,
        engine: Any,
        macro_report: Optional[Dict[str, Any]] = None,
        logic_report: Optional[Dict[str, Any]] = None,
        hotlist: Optional[List[str]] = None,
        as_of: Any = None,
        topk: int = 120
    ) -> pd.DataFrame:
        """
        å¯¹å¸‚åœºæ‰«æç»“æœåšæ‰¹é‡æ…¢å˜é‡å¢å¼ºï¼ˆåªå¯¹ topk åšé‡è®¡ç®—ï¼Œå…¶ä½™é»˜è®¤0.5ï¼‰ã€‚
        - å¸‚åœº/æ‹¥æŒ¤åº¦éƒ¨åˆ†ç”¨ rankï¼ˆæ›´ç¨³å®šï¼‰
        - ä»·æ ¼ä½ç½®ç”¨ K çº¿ï¼ˆç›¸å¯¹æ…¢ï¼Œæ§åˆ¶ topkï¼‰
        - è´¢åŠ¡/ç ”å‘ç”¨ç¼“å­˜ï¼ˆ24hï¼‰
        """
        if market_df is None or market_df.empty:
            return market_df

        df = market_df.copy()
        df["slow_score"] = 0.5
        df["policy_strength"] = 0.5
        df["policy_persistence"] = 0.5
        df["demand_space"] = 0.5
        df["domestic_substitution"] = 0.5
        df["market_pricing"] = 0.5
        df["info_priced_in"] = 0.5
        df["slow_evidence"] = ""

        hotlist = hotlist or []
        as_of_str = _to_date_str(as_of)

        # -------- ranks for crowdedness (info) --------
        # ç»¼åˆâ€œçƒ­åº¦/æ‹¥æŒ¤â€proxyï¼šé‡æ¯”ã€æ¶¨è·Œå¹…ç»å¯¹å€¼ã€èµ„é‡‘æµ
        tmp = df.copy()
        if "main_net_inflow" not in tmp.columns:
            tmp["main_net_inflow"] = 0.0
        r_vol = tmp["vol_ratio"].fillna(0).rank(pct=True)
        r_abs = tmp["pct"].fillna(0).abs().rank(pct=True)
        r_flow = tmp["main_net_inflow"].fillna(0).rank(pct=True)
        crowded = (0.45 * r_vol + 0.35 * r_abs + 0.20 * r_flow).clip(0,1)
        ranks = {str(c): float(v) for c, v in zip(tmp["code"].astype(str).tolist(), crowded.tolist())}

        # -------- sector PE median (for pricing) --------
        sector_pe_median_map: Dict[str, float] = {}
        try:
            pe_df = tmp[(tmp["pe"] > 0) & tmp["sector"].notna()][["sector","pe"]].copy()
            if not pe_df.empty:
                sector_pe_median_map = pe_df.groupby("sector")["pe"].median().to_dict()
        except Exception:
            sector_pe_median_map = {}

        # -------- choose heavy calc subset --------
        work = df.sort_values("fused_score" if "fused_score" in df.columns else "score", ascending=False).head(int(topk)).copy()

        records: List[Dict[str, Any]] = []

        for i, row in work.iterrows():
            code = str(row.get("code",""))
            sector = str(row.get("sector",""))
            # spot row is row itself (close/pe/pct/vol_ratio/flow)
            spot = {
                "code": code,
                "close": row.get("close"),
                "pct": row.get("pct"),
                "pe": row.get("pe"),
                "market_cap": row.get("market_cap"),
                "vol_ratio": row.get("vol_ratio"),
                "main_net_inflow": row.get("main_net_inflow", 0.0),
            }
            # financial (cached)
            fin = engine.get_financial_features(code) or {}
            # Kçº¿ï¼ˆç”¨äºä»·æ ¼ä½ç½®ï¼‰
            try:
                k260 = engine.get_kline(code, freq="daily", limit=260)
            except Exception:
                k260 = None

            # policy strength uses macro_report + sector match
            pol, _ = self._policy_strength(sector, macro_report, alt_report=None)
            pers = self.store.sector_policy_persistence(sector, as_of_str)
            dem, _ = self._demand_space(fin, sector, macro_report)
            sub, _ = self._substitution(sector, fin, alt_report=None)
            pricing, _ = self._market_pricing(spot, k260, sector_pe_median_map.get(sector))
            info, ev_info = self._info_priced_in({**spot}, hotlist=hotlist, ranks=ranks)

            # fundamentals & ops (from DataEngine.get_financial_features)
            fq = _clip01(float((fin or {}).get('fundamental_quality', 0.5) or 0.5))
            fg = _clip01(float((fin or {}).get('fundamental_growth', 0.5) or 0.5))
            ops = _clip01(float((fin or {}).get('ops_momentum', 0.5) or 0.5))

            # å•†ç”¨åŒ–ï¼šæŠŠâ€œè´¢æŠ¥è´¨é‡/å¢é•¿/è¿è¥åŠ¨é‡â€çº³å…¥æ…¢å˜é‡ï¼ˆå¯å›æµ‹/å¯è®­ç»ƒï¼‰
            slow_score = (
                0.15 * pol +
                0.10 * pers +
                0.10 * dem +
                0.10 * sub +
                0.10 * pricing +
                0.05 * (1.0 - info) +
                0.20 * fq +
                0.15 * fg +
                0.05 * ops
            )
            slow_score = _clip01(slow_score)

            df.loc[i, "policy_strength"] = pol
            df.loc[i, "policy_persistence"] = pers
            df.loc[i, "demand_space"] = dem
            df.loc[i, "domestic_substitution"] = sub
            df.loc[i, "market_pricing"] = pricing
            df.loc[i, "info_priced_in"] = info
            df.loc[i, "fundamental_quality"] = fq
            df.loc[i, "fundamental_growth"] = fg
            df.loc[i, "ops_momentum"] = ops
            # compatibility aliases
            df.loc[i, "policy_sustain"] = pers
            df.loc[i, "info_sufficiency"] = _clip01(1.0 - info)
            df.loc[i, "slow_score"] = slow_score

            # evidenceï¼ˆçŸ­æ–‡æœ¬ï¼Œä¾¿äº UIï¼‰
            brief = []
            if pol >= 0.62: brief.append("ğŸ›ï¸æ”¿ç­–å¼º")
            if pers >= 0.62: brief.append("â³æŒç»­æ€§å¥½")
            if dem >= 0.62: brief.append("ğŸ“ˆéœ€æ±‚å¼º")
            if sub >= 0.62: brief.append("ğŸ‡¨ğŸ‡³æ›¿ä»£å¼º")
            if pricing >= 0.62: brief.append("ğŸ’å®šä»·å¥½")
            if fq >= 0.62: brief.append("ğŸ¦è´¢æŠ¥å¼º")
            if fg >= 0.62: brief.append("ğŸ“Šæˆé•¿å¼º")
            if ops >= 0.62: brief.append("ğŸ›°ï¸è¿è¥å¼º")
            if info >= 0.65: brief.append("ğŸ”¥æ‹¥æŒ¤")
            if code in hotlist: brief.append("ğŸ“Œçƒ­æ¦œ")
            df.loc[i, "slow_evidence"] = " | ".join(brief[:4])

            records.append({
                "date": as_of_str,
                "code": code,
                "sector": sector,
                "policy_strength": float(pol),
                "policy_persistence": float(pers),
                "demand_space": float(dem),
                "domestic_substitution": float(sub),
                "market_pricing": float(pricing),
                "info_priced_in": float(info),
                "slow_score": float(slow_score),
                "meta": json.dumps({"brief": brief, "macro_conf": _safe_float((macro_report or {}).get("confidence", 0.0), 0.0)}, ensure_ascii=False)
            })

        # è½ç›˜ï¼ˆç”¨äºå¯å›æµ‹ï¼‰
        self.store.append_many(records)

        return df
